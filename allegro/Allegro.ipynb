{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fad2821d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/temporary/anaconda3/envs/torch_mkl/lib/python3.10/site-packages/nequip/__init__.py:20: UserWarning: !! PyTorch version 2.0.0 found. Upstream issues in PyTorch versions 1.13.* and 2.* have been seen to cause unusual performance degredations on some CUDA systems that become worse over time; see https://github.com/mir-group/nequip/discussions/311. The best tested PyTorch version to use with CUDA devices is 1.11; while using other versions if you observe this problem, an unexpected lack of this problem, or other strange behavior, please post in the linked GitHub issue.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# reference example\n",
    "from nequip.data import dataset_from_config\n",
    "from nequip.utils import Config\n",
    "from nequip.utils.misc import get_default_device_name\n",
    "from nequip.utils.config import _GLOBAL_ALL_ASKED_FOR_KEYS\n",
    "\n",
    "from nequip.model import model_from_config\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "default_config = dict(\n",
    "    root=\"./\",\n",
    "    tensorboard=False,\n",
    "    wandb=False,\n",
    "    model_builders=[\n",
    "        \"SimpleIrrepsConfig\",\n",
    "        \"EnergyModel\",\n",
    "        \"PerSpeciesRescale\",\n",
    "        \"StressForceOutput\",\n",
    "        \"RescaleEnergyEtc\",\n",
    "    ],\n",
    "    dataset_statistics_stride=1,\n",
    "    device=get_default_device_name(),\n",
    "    default_dtype=\"float64\",\n",
    "    model_dtype=\"float32\",\n",
    "    allow_tf32=True,\n",
    "    verbose=\"INFO\",\n",
    "    model_debug_mode=False,\n",
    "    equivariance_test=False,\n",
    "    grad_anomaly_mode=False,\n",
    "    gpu_oom_offload=False,\n",
    "    append=False,\n",
    "    warn_unused=False,\n",
    "    _jit_bailout_depth=2,  # avoid 20 iters of pain, see https://github.com/pytorch/pytorch/issues/52286\n",
    "    # Quote from eelison in PyTorch slack:\n",
    "    # https://pytorch.slack.com/archives/CDZD1FANA/p1644259272007529?thread_ts=1644064449.039479&cid=CDZD1FANA\n",
    "    # > Right now the default behavior is to specialize twice on static shapes and then on dynamic shapes.\n",
    "    # > To reduce warmup time you can do something like setFusionStrartegy({{FusionBehavior::DYNAMIC, 3}})\n",
    "    # > ... Although we would wouldn't really expect to recompile a dynamic shape fusion in a model,\n",
    "    # > provided broadcasting patterns remain fixed\n",
    "    # We default to DYNAMIC alone because the number of edges is always dynamic,\n",
    "    # even if the number of atoms is fixed:\n",
    "    _jit_fusion_strategy=[(\"DYNAMIC\", 3)],\n",
    "    # Due to what appear to be ongoing bugs with nvFuser, we default to NNC (fuser1) for now:\n",
    "    # TODO: still default to NNC on CPU regardless even if change this for GPU\n",
    "    # TODO: default for ROCm?\n",
    "    _jit_fuser=\"fuser1\",\n",
    ")\n",
    "\n",
    "# All default_config keys are valid / requested\n",
    "_GLOBAL_ALL_ASKED_FOR_KEYS.update(default_config.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d80fac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtomicData(atom_types=[21, 1], cell=[3, 3], edge_cell_shift=[364, 3], edge_index=[2, 364], forces=[21, 3], pbc=[3], pos=[21, 3], total_energy=[1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config.from_file('./configs/example.yaml', defaults=default_config)\n",
    "    \n",
    "\n",
    "dataset = dataset_from_config(config, prefix=\"dataset\")\n",
    "\n",
    "validation_dataset = None\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87c25eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:* Initialize Output\n",
      "  ...generate file name results/aspirin/example/log\n",
      "  ...open log file results/aspirin/example/log\n",
      "  ...generate file name results/aspirin/example/metrics_epoch.csv\n",
      "  ...open log file results/aspirin/example/metrics_epoch.csv\n",
      "  ...generate file name results/aspirin/example/metrics_initialization.csv\n",
      "  ...open log file results/aspirin/example/metrics_initialization.csv\n",
      "  ...generate file name results/aspirin/example/metrics_batch_train.csv\n",
      "  ...open log file results/aspirin/example/metrics_batch_train.csv\n",
      "  ...generate file name results/aspirin/example/metrics_batch_val.csv\n",
      "  ...open log file results/aspirin/example/metrics_batch_val.csv\n",
      "  ...generate file name results/aspirin/example/best_model.pth\n",
      "  ...generate file name results/aspirin/example/last_model.pth\n",
      "  ...generate file name results/aspirin/example/trainer.pth\n",
      "  ...generate file name results/aspirin/example/config.yaml\n",
      "Torch device: cpu\n",
      "instantiate Loss\n",
      "...Loss_param = dict(\n",
      "...   optional_args = {},\n",
      "...   positional_args = {'coeffs': {'forces': 1.0, 'total_energy': [1.0, 'PerAtomMSELoss']}})\n",
      "instantiate MSELoss\n",
      "...MSELoss_param = dict(\n",
      "...   optional_args = {'size_average': None, 'reduce': None},\n",
      "...   positional_args = {'reduction': 'none'})\n",
      " parsing forces 1.0\n",
      " parsing 1.0 MSELoss\n",
      "instantiate MSELoss\n",
      "...MSELoss_param = dict(\n",
      "...   optional_args = {'size_average': None, 'reduce': None},\n",
      "...   positional_args = {'reduction': 'none'})\n",
      " parsing total_energy [1.0, 'PerAtomMSELoss']\n",
      " parsing 1.0 PerAtomMSELoss\n",
      "create loss instance <class 'nequip.train._loss.PerAtomLoss'>\n",
      "instantiate MSELoss\n",
      "...MSELoss_param = dict(\n",
      "...   optional_args = {'size_average': None, 'reduce': None},\n",
      "...   positional_args = {'reduction': 'none'})\n",
      "Building Allegro model...\n",
      "instantiate OneHotAtomEncoding\n",
      "        all_args :                                           num_types\n",
      "...OneHotAtomEncoding_param = dict(\n",
      "...   optional_args = {'set_features': True, 'num_types': 3},\n",
      "...   positional_args = {'irreps_in': None})\n",
      "instantiate RadialBasisEdgeEncoding\n",
      "        all_args :                                  basis_kwargs.r_max <-                                              r_max\n",
      "        all_args :            basis_kwargs.original_basis_kwargs.r_max <-                                              r_max\n",
      "        all_args :        basis_kwargs.original_basis_kwargs.trainable <-                              BesselBasis_trainable\n",
      "        all_args :                                 cutoff_kwargs.r_max <-                                              r_max\n",
      "        all_args :                                     cutoff_kwargs.p <-                                 PolynomialCutoff_p\n",
      "   optional_args :                                           out_field\n",
      "   optional_args :                                               basis\n",
      "...RadialBasisEdgeEncoding_param = dict(\n",
      "...   optional_args = {'basis': <class 'allegro.nn._norm_basis.NormalizedBasis'>, 'cutoff': <class 'nequip.nn.cutoffs.PolynomialCutoff'>, 'basis_kwargs': {'r_min': 0.0, 'original_basis': <class 'nequip.nn.radial_basis.BesselBasis'>, 'original_basis_kwargs': {'num_basis': 8, 'trainable': True, 'r_max': 6.0}, 'n': 4000, 'norm_basis_mean_shift': True, 'r_max': 6.0}, 'cutoff_kwargs': {'p': 6, 'r_max': 6.0}, 'out_field': 'edge_embedding'},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1o, 'edge_index': None, 'node_attrs': 3x0e, 'node_features': 3x0e}})\n",
      "instantiate SphericalHarmonicEdgeAttrs\n",
      "        all_args :                                      irreps_edge_sh\n",
      "...SphericalHarmonicEdgeAttrs_param = dict(\n",
      "...   optional_args = {'edge_sh_normalization': 'component', 'edge_sh_normalize': True, 'out_field': 'edge_attrs', 'irreps_edge_sh': '1x0e+1x1o+1x2e'},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1o, 'edge_index': None, 'node_attrs': 3x0e, 'node_features': 3x0e, 'edge_embedding': 8x0e, 'edge_cutoff': 1x0e}})\n",
      "instantiate Allegro_Module\n",
      "        all_args :                                           num_types\n",
      "        all_args :                           nonscalars_include_parity\n",
      "        all_args :                                               r_max\n",
      "        all_args :                                       latent_resnet\n",
      "        all_args :                                          num_layers\n",
      "        all_args :                                  embed_initial_edge\n",
      "        all_args :                                  PolynomialCutoff_p\n",
      "        all_args :                              env_embed_multiplicity\n",
      "        all_args :                                   avg_num_neighbors\n",
      "        all_args :           two_body_latent_kwargs.mlp_initialization <-                 two_body_latent_mlp_initialization\n",
      "        all_args :        two_body_latent_kwargs.mlp_latent_dimensions <-              two_body_latent_mlp_latent_dimensions\n",
      "        all_args :             two_body_latent_kwargs.mlp_nonlinearity <-                   two_body_latent_mlp_nonlinearity\n",
      "        all_args :                 env_embed_kwargs.mlp_initialization <-                       env_embed_mlp_initialization\n",
      "        all_args :              env_embed_kwargs.mlp_latent_dimensions <-                    env_embed_mlp_latent_dimensions\n",
      "        all_args :                   env_embed_kwargs.mlp_nonlinearity <-                         env_embed_mlp_nonlinearity\n",
      "        all_args :                    latent_kwargs.mlp_initialization <-                          latent_mlp_initialization\n",
      "        all_args :                 latent_kwargs.mlp_latent_dimensions <-                       latent_mlp_latent_dimensions\n",
      "        all_args :                      latent_kwargs.mlp_nonlinearity <-                            latent_mlp_nonlinearity\n",
      "   optional_args :                                               field\n",
      "   optional_args :                                node_invariant_field\n",
      "   optional_args :                                edge_invariant_field\n",
      "...Allegro_Module_param = dict(\n",
      "...   optional_args = {'avg_num_neighbors': 17.211328506469727, 'r_start_cos_ratio': 0.8, 'PolynomialCutoff_p': 6, 'per_layer_cutoffs': None, 'cutoff_type': 'polynomial', 'field': 'edge_attrs', 'edge_invariant_field': 'edge_embedding', 'node_invariant_field': 'node_attrs', 'env_embed_multiplicity': 64, 'embed_initial_edge': True, 'linear_after_env_embed': False, 'nonscalars_include_parity': True, 'two_body_latent': <class 'allegro.nn._fc.ScalarMLPFunction'>, 'two_body_latent_kwargs': {'mlp_nonlinearity': 'silu', 'mlp_initialization': 'uniform', 'mlp_dropout_p': 0.0, 'mlp_batchnorm': False, 'mlp_latent_dimensions': [128, 256, 512, 1024]}, 'env_embed': <class 'allegro.nn._fc.ScalarMLPFunction'>, 'env_embed_kwargs': {'mlp_nonlinearity': None, 'mlp_initialization': 'uniform', 'mlp_dropout_p': 0.0, 'mlp_batchnorm': False, 'mlp_latent_dimensions': []}, 'latent': <class 'allegro.nn._fc.ScalarMLPFunction'>, 'latent_kwargs': {'mlp_nonlinearity': 'silu', 'mlp_initialization': 'uniform', 'mlp_dropout_p': 0.0, 'mlp_batchnorm': False, 'mlp_latent_dimensions': [1024, 1024, 1024]}, 'latent_resnet': True, 'latent_resnet_update_ratios': None, 'latent_resnet_update_ratios_learnable': False, 'latent_out_field': 'edge_features', 'pad_to_alignment': 1, 'sparse_mode': None, 'r_max': 6.0, 'num_layers': 2, 'num_types': 3},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1o, 'edge_index': None, 'node_attrs': 3x0e, 'node_features': 3x0e, 'edge_embedding': 8x0e, 'edge_cutoff': 1x0e, 'edge_attrs': 1x0e+1x1o+1x2e}})\n",
      "/Users/temporary/Documents/GitHub/pytorch-intel-mps/torch/jit/_check.py:172: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\"The TorchScript type system doesn't support \"\n",
      "instantiate ScalarMLP\n",
      "        all_args :                                  mlp_initialization <-                        edge_eng_mlp_initialization\n",
      "        all_args :                               mlp_latent_dimensions <-                     edge_eng_mlp_latent_dimensions\n",
      "        all_args :                                    mlp_nonlinearity <-                          edge_eng_mlp_nonlinearity\n",
      "   optional_args :                                               field\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   optional_args :                                           out_field\n",
      "   optional_args :                                mlp_output_dimension\n",
      "...ScalarMLP_param = dict(\n",
      "...   optional_args = {'mlp_nonlinearity': None, 'mlp_initialization': 'uniform', 'mlp_dropout_p': 0.0, 'mlp_batchnorm': False, 'field': 'edge_features', 'out_field': 'edge_energy', 'mlp_latent_dimensions': [128], 'mlp_output_dimension': 1},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1o, 'edge_index': None, 'node_attrs': 3x0e, 'node_features': 3x0e, 'edge_embedding': 8x0e, 'edge_cutoff': 1x0e, 'edge_attrs': 1x0e+1x1o+1x2e, 'edge_features': 1024x0e}})\n",
      "instantiate EdgewiseEnergySum\n",
      "        all_args :                                           num_types\n",
      "        all_args :                                   avg_num_neighbors\n",
      "...EdgewiseEnergySum_param = dict(\n",
      "...   optional_args = {'avg_num_neighbors': 17.211328506469727, 'normalize_edge_energy_sum': True, 'per_edge_species_scale': False, 'num_types': 3},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1o, 'edge_index': None, 'node_attrs': 3x0e, 'node_features': 3x0e, 'edge_embedding': 8x0e, 'edge_cutoff': 1x0e, 'edge_attrs': 1x0e+1x1o+1x2e, 'edge_features': 1024x0e, 'edge_energy': 1x0e}})\n",
      "instantiate AtomwiseReduce\n",
      "   optional_args :                                               field\n",
      "   optional_args :                                              reduce\n",
      "   optional_args :                                           out_field\n",
      "...AtomwiseReduce_param = dict(\n",
      "...   optional_args = {'out_field': 'total_energy', 'reduce': 'sum', 'avg_num_atoms': None, 'field': 'atomic_energy'},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1o, 'edge_index': None, 'node_attrs': 3x0e, 'node_features': 3x0e, 'edge_embedding': 8x0e, 'edge_cutoff': 1x0e, 'edge_attrs': 1x0e+1x1o+1x2e, 'edge_features': 1024x0e, 'edge_energy': 1x0e, 'atomic_energy': 1x0e}})\n",
      "Replace string dataset_per_atom_total_energy_mean to -19318.35546875\n",
      "Atomic outputs are scaled by: [H, C, O: None], shifted by [H, C, O: -19318.355469].\n",
      "instantiate PerSpeciesScaleShift\n",
      "        all_args :                                       default_dtype\n",
      "        all_args :                                           num_types\n",
      "        all_args :                                          type_names\n",
      "   optional_args :                          arguments_in_dataset_units\n",
      "   optional_args :                                              scales\n",
      "   optional_args :                                              shifts\n",
      "   optional_args :                                           out_field\n",
      "   optional_args :                                               field\n",
      "...PerSpeciesScaleShift_param = dict(\n",
      "...   optional_args = {'out_field': 'atomic_energy', 'scales_trainable': False, 'shifts_trainable': False, 'default_dtype': 'float32', 'num_types': 3, 'type_names': ['H', 'C', 'O'], 'field': 'atomic_energy', 'shifts': tensor(-19318.3555), 'scales': None, 'arguments_in_dataset_units': True},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1o, 'edge_index': None, 'node_attrs': 3x0e, 'node_features': 3x0e, 'edge_embedding': 8x0e, 'edge_cutoff': 1x0e, 'edge_attrs': 1x0e+1x1o+1x2e, 'edge_features': 1024x0e, 'edge_energy': 1x0e, 'atomic_energy': 1x0e}})\n",
      "Replace string dataset_forces_rms to 31.252248764038086\n",
      "Initially outputs are globally scaled by: 31.252248764038086, total_energy are globally shifted by None.\n",
      "PerSpeciesScaleShift's arguments were in dataset units; rescaling:\n",
      "  Original scales: n/a shifts: [H: -19318.355469, C: -19318.355469, O: -19318.355469]\n",
      "  New scales: n/a shifts: [H: -618.142883, C: -618.142883, O: -618.142883]\n"
     ]
    }
   ],
   "source": [
    "# Trainer\n",
    "from nequip.train.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(model=None, **Config.as_dict(config))\n",
    "\n",
    "# what is this\n",
    "# to update wandb data?\n",
    "config.update(trainer.params)\n",
    "\n",
    "# = Train/test split =\n",
    "trainer.set_dataset(dataset, validation_dataset)\n",
    "\n",
    "# = Build model =\n",
    "final_model = model_from_config(\n",
    "    config=config, initialize=True, dataset=trainer.dataset_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ea3507b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModel(\n",
       "  (model): RescaleOutput(\n",
       "    (model): GradientOutput(\n",
       "      (func): SequentialGraphNetwork(\n",
       "        (one_hot): OneHotAtomEncoding()\n",
       "        (radial_basis): RadialBasisEdgeEncoding(\n",
       "          (basis): NormalizedBasis(\n",
       "            (basis): BesselBasis()\n",
       "          )\n",
       "          (cutoff): PolynomialCutoff()\n",
       "        )\n",
       "        (spharm): SphericalHarmonicEdgeAttrs(\n",
       "          (sh): SphericalHarmonics()\n",
       "        )\n",
       "        (allegro): Allegro_Module(\n",
       "          (latents): ModuleList(\n",
       "            (0-1): 2 x ScalarMLPFunction(\n",
       "              (_forward): RecursiveScriptModule(original_name=GraphModule)\n",
       "            )\n",
       "          )\n",
       "          (env_embed_mlps): ModuleList(\n",
       "            (0-1): 2 x ScalarMLPFunction(\n",
       "              (_forward): RecursiveScriptModule(original_name=GraphModule)\n",
       "            )\n",
       "          )\n",
       "          (tps): ModuleList(\n",
       "            (0-1): 2 x RecursiveScriptModule(original_name=GraphModule)\n",
       "          )\n",
       "          (linears): ModuleList(\n",
       "            (0-1): 2 x RecursiveScriptModule(original_name=GraphModule)\n",
       "          )\n",
       "          (env_linears): ModuleList(\n",
       "            (0-1): 2 x Identity()\n",
       "          )\n",
       "          (_env_weighter): MakeWeightedChannels()\n",
       "          (final_latent): ScalarMLPFunction(\n",
       "            (_forward): RecursiveScriptModule(original_name=GraphModule)\n",
       "          )\n",
       "        )\n",
       "        (edge_eng): ScalarMLP(\n",
       "          (_module): ScalarMLPFunction(\n",
       "            (_forward): RecursiveScriptModule(original_name=GraphModule)\n",
       "          )\n",
       "        )\n",
       "        (edge_eng_sum): EdgewiseEnergySum()\n",
       "        (per_species_rescale): PerSpeciesScaleShift()\n",
       "        (total_energy_sum): AtomwiseReduce()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11a4fb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from e3nn import o3\n",
    "\n",
    "l_max = 2\n",
    "\n",
    "irreps_edge_sh = repr(\n",
    "            o3.Irreps.spherical_harmonics(\n",
    "                l_max, p=(-1)\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4bb8134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1x0e+1x1o+1x2e'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irreps_edge_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96a9dbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "from nequip.data import AtomicData, AtomicDataDict\n",
    "from torch.nn.functional import one_hot\n",
    "from e3nn.nn import FullyConnectedNet\n",
    "    \n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "\n",
    "data = AtomicData.to_AtomicDataDict(dataset[0])\n",
    "\n",
    "\n",
    "\n",
    "# edge length embedding\n",
    "torch.manual_seed(32)\n",
    "\n",
    "num_basis = 8\n",
    "r_max = 5\n",
    "\n",
    "\n",
    "data_my = {key: torch.clone(data[key]) for key in data}\n",
    "data_my = AtomicDataDict.with_edge_vectors(data_my, with_lengths=True)\n",
    "\n",
    "edge_length = data_my['edge_lengths']\n",
    "\n",
    "bessel_weights = (torch.linspace(start=1.0, end=num_basis, steps=num_basis) * math.pi)\n",
    "bessel_weights = nn.Parameter(bessel_weights)\n",
    "\n",
    "edge_length_embedding = 2/r_max*torch.sin(bessel_weights * edge_length.unsqueeze(-1) / r_max)/edge_length.unsqueeze(-1)\n",
    "\n",
    "# cutoff\n",
    "factor = 1/r_max\n",
    "p = 6\n",
    "    \n",
    "x = edge_length * factor\n",
    "\n",
    "cutoff = 1.0\n",
    "cutoff = cutoff - (((p + 1.0) * (p + 2.0) / 2.0) * torch.pow(x, p))\n",
    "cutoff = cutoff + (p * (p + 2.0) * torch.pow(x, p + 1.0))\n",
    "cutoff = cutoff - ((p * (p + 1.0) / 2) * torch.pow(x, p + 2.0))\n",
    "cutoff *= (x < 1.0)\n",
    "\n",
    "cutoff = cutoff.unsqueeze(-1)\n",
    "\n",
    "data_my['edge_embedding'] = edge_length_embedding * cutoff\n",
    "\n",
    "# types embedding\n",
    "num_classes = 3\n",
    "\n",
    "\n",
    "edge_ind = data_my['edge_index']\n",
    "\n",
    "types_embed = one_hot(dataset[0]['atom_types'], num_classes)\n",
    "types_src = types_embed[edge_ind[0]].squeeze(1)\n",
    "types_dst = types_embed[edge_ind[1]].squeeze(1)\n",
    "\n",
    "\n",
    "\n",
    "# latent vector\n",
    "latent_vector = torch.concatenate([types_src, types_dst, edge_length_embedding], dim = 1)\n",
    "\n",
    "# MLP\n",
    "invariant_layers = 2\n",
    "invariant_neurons = 64\n",
    "out_neurons = 32\n",
    "\n",
    "fc = FullyConnectedNet(\n",
    "    [latent_vector.shape[1]]\n",
    "    + invariant_layers * [invariant_neurons]\n",
    "    + [out_neurons],\n",
    "    torch.nn.functional.silu)\n",
    "\n",
    "latent_vector_out = fc(latent_vector)\n",
    "\n",
    "\n",
    "data_my['scalar'] = latent_vector_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c708419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 14])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89c32180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 32])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_vector_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "018f85fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 32])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nequip.nn import AtomwiseLinear\n",
    "from e3nn.o3 import Irreps\n",
    "\n",
    "\n",
    "#data2_my = {key: torch.clone(data_my[key]) for key in data_my}\n",
    "\n",
    "linear1 = o3.Linear('32x0e', '32x0e')\n",
    "\n",
    "weight1 = linear1(latent_vector_out)\n",
    "weight1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67a15d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import math\n",
    "\n",
    "\n",
    "torch.manual_seed(32)\n",
    "\n",
    "\n",
    "l_max = 2\n",
    "irreps_edge_sh = o3.Irreps.spherical_harmonics(2)\n",
    "\n",
    "data2_my = {key: torch.clone(data2_my[key]) for key in data_my}\n",
    "data2_my = AtomicDataDict.with_edge_vectors(data2_my, with_lengths=False)\n",
    "\n",
    "\n",
    "harm_gen = o3.SphericalHarmonics(irreps_edge_sh, True, 'component')\n",
    "\n",
    "edge_vec = data_my['edge_vectors']\n",
    "\n",
    "harm_edge = harm_gen(edge_vec)\n",
    "harm_edge.shape\n",
    "\n",
    "\n",
    "data2_my['edge_features'] = harm_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "716c0240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 32, 9])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from e3nn.o3 import TensorProduct, Linear, FullyConnectedTensorProduct\n",
    "from torch_runstats.scatter import scatter\n",
    "\n",
    "x = data2_my['edge_features']\n",
    "edge_src = data2_my['edge_index'][1]\n",
    "edge_dst = data2_my['edge_index'][0]\n",
    "\n",
    "\n",
    "term_1 = harm_edge\n",
    "edge_features = torch.einsum('ij,ib->ijb', weight1[edge_src], harm_edge[edge_src])\n",
    "\n",
    "# TODO: Check if it really right result\n",
    "edge_features = scatter(edge_features, edge_dst, dim=0, dim_size=len(x))\n",
    "edge_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a3f7edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FullyConnectedTensorProduct(1x0e+1x1o+1x2e x 32x0e+32x1o+32x2o -> 32x0e+32x0o+32x1e+32x1o+32x2e+32x2o | 15360 paths | 15360 weights)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from e3nn.o3 import TensorProduct, Linear, FullyConnectedTensorProduct\n",
    "\n",
    "hidden_layer_irrep = o3.Irreps(\"32x0e + 32x0o + 32x1e + 32x1o + 32x2e + 32x2o\")\n",
    "\n",
    "irrep_in = o3.Irreps(\"1x0e + 1x1o + 1x2e\")\n",
    "irreps_edge = o3.Irreps(\"32x0e + 32x1o + 32x2o\")\n",
    "\n",
    "\n",
    "irreps_mid = []\n",
    "instructions = []\n",
    "\n",
    "# instructions means stuff for multiplicities\n",
    "for i, (_, ir_in) in enumerate(irrep_in):\n",
    "    for j, (mul, ir_edge) in enumerate(irreps_edge):\n",
    "        for ir_out in ir_in * ir_edge:\n",
    "            if ir_out in hidden_layer_irrep:\n",
    "                k = len(irreps_mid)\n",
    "                irreps_mid.append((mul, ir_out))\n",
    "                instructions.append((i, j, k, \"uvu\", True))\n",
    "\n",
    "# We sort the output irreps of the tensor product so that we can simplify them\n",
    "# when they are provided to the second o3.Linear\n",
    "irreps_mid = o3.Irreps(irreps_mid)\n",
    "irreps_mid, p, _ = irreps_mid.sort()\n",
    "\n",
    "fctp = FullyConnectedTensorProduct(\n",
    "            irrep_in,\n",
    "            irreps_edge,\n",
    "            hidden_layer_irrep\n",
    "        )\n",
    "\n",
    "fctp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7197fd59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irrep_in.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0194b2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irreps_edge.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d4dae9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 288])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(edge_features.transpose(2, 1), -2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9df1664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = fctp(harm_edge, edge_features.transpose(2, 1).flatten(-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "69726190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 576])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9e85cd06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 9, 1])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harm_edge.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4de1f8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 9, 32])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(edge_features.transpose(2, 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "693e9072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 32, 9])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0543b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_mkl",
   "language": "python",
   "name": "torch_mkl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
