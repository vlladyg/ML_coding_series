{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fad2821d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/temporary/anaconda3/envs/torch_mkl/lib/python3.10/site-packages/nequip/__init__.py:20: UserWarning: !! PyTorch version 2.0.0 found. Upstream issues in PyTorch versions 1.13.* and 2.* have been seen to cause unusual performance degredations on some CUDA systems that become worse over time; see https://github.com/mir-group/nequip/discussions/311. The best tested PyTorch version to use with CUDA devices is 1.11; while using other versions if you observe this problem, an unexpected lack of this problem, or other strange behavior, please post in the linked GitHub issue.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# reference example\n",
    "from nequip.data import dataset_from_config\n",
    "from nequip.utils import Config\n",
    "from nequip.utils.misc import get_default_device_name\n",
    "from nequip.utils.config import _GLOBAL_ALL_ASKED_FOR_KEYS\n",
    "\n",
    "from nequip.model import model_from_config\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "default_config = dict(\n",
    "    root=\"./\",\n",
    "    tensorboard=False,\n",
    "    wandb=False,\n",
    "    model_builders=[\n",
    "        \"SimpleIrrepsConfig\",\n",
    "        \"EnergyModel\",\n",
    "        \"PerSpeciesRescale\",\n",
    "        \"StressForceOutput\",\n",
    "        \"RescaleEnergyEtc\",\n",
    "    ],\n",
    "    dataset_statistics_stride=1,\n",
    "    device=get_default_device_name(),\n",
    "    default_dtype=\"float64\",\n",
    "    model_dtype=\"float32\",\n",
    "    allow_tf32=True,\n",
    "    verbose=\"INFO\",\n",
    "    model_debug_mode=False,\n",
    "    equivariance_test=False,\n",
    "    grad_anomaly_mode=False,\n",
    "    gpu_oom_offload=False,\n",
    "    append=False,\n",
    "    warn_unused=False,\n",
    "    _jit_bailout_depth=2,  # avoid 20 iters of pain, see https://github.com/pytorch/pytorch/issues/52286\n",
    "    # Quote from eelison in PyTorch slack:\n",
    "    # https://pytorch.slack.com/archives/CDZD1FANA/p1644259272007529?thread_ts=1644064449.039479&cid=CDZD1FANA\n",
    "    # > Right now the default behavior is to specialize twice on static shapes and then on dynamic shapes.\n",
    "    # > To reduce warmup time you can do something like setFusionStrartegy({{FusionBehavior::DYNAMIC, 3}})\n",
    "    # > ... Although we would wouldn't really expect to recompile a dynamic shape fusion in a model,\n",
    "    # > provided broadcasting patterns remain fixed\n",
    "    # We default to DYNAMIC alone because the number of edges is always dynamic,\n",
    "    # even if the number of atoms is fixed:\n",
    "    _jit_fusion_strategy=[(\"DYNAMIC\", 3)],\n",
    "    # Due to what appear to be ongoing bugs with nvFuser, we default to NNC (fuser1) for now:\n",
    "    # TODO: still default to NNC on CPU regardless even if change this for GPU\n",
    "    # TODO: default for ROCm?\n",
    "    _jit_fuser=\"fuser1\",\n",
    ")\n",
    "\n",
    "# All default_config keys are valid / requested\n",
    "_GLOBAL_ALL_ASKED_FOR_KEYS.update(default_config.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e26c68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtomicData(atom_types=[15, 1], cell=[3, 3], edge_cell_shift=[152, 3], edge_index=[2, 152], forces=[15, 3], pbc=[3], pos=[15, 3], total_energy=[1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config.from_file('./configs/example.yaml', defaults=default_config)\n",
    "    \n",
    "\n",
    "dataset = dataset_from_config(config, prefix=\"dataset\")\n",
    "\n",
    "validation_dataset = None\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "618ce480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Torch device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Trainer\n",
    "from nequip.train.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(model=None, **Config.as_dict(config))\n",
    "\n",
    "# what is this\n",
    "# to update wandb data?\n",
    "config.update(trainer.params)\n",
    "\n",
    "# = Train/test split =\n",
    "trainer.set_dataset(dataset, validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bb26c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb0f5eb8250>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from vladimir import GraphModuleMixin\n",
    "from vladimir import OneHotAtomEncoding\n",
    "\n",
    "one_hot = OneHotAtomEncoding(2)\n",
    "\n",
    "from vladimir import AtomwiseLinear\n",
    "from e3nn import o3\n",
    "\n",
    "torch.manual_seed(32)\n",
    "\n",
    "\n",
    "# Linear\n",
    "al = AtomwiseLinear(irreps_in=one_hot.irreps_out, irreps_out=o3.Irreps([(32, (0, 1))]))\n",
    "\n",
    "\n",
    "# Rbe\n",
    "from vladimir import RadialBasisEdgeEncoding\n",
    "from e3nn import o3\n",
    "\n",
    "rbe = RadialBasisEdgeEncoding(basis_kwargs={'r_max': 4}, cutoff_kwargs={'r_max': 4}, irreps_in=al.irreps_out)\n",
    "\n",
    "# SH\n",
    "torch.manual_seed(32)\n",
    "\n",
    "from vladimir import SphericalHarmonicEdgeAttrs\n",
    "\n",
    "sh = SphericalHarmonicEdgeAttrs(2, irreps_in=rbe.irreps_out)\n",
    "\n",
    "\n",
    "# Convolution\n",
    "from vladimir import conv\n",
    "from vladimir import InteractionBlock, ConvNetLayer\n",
    "from e3nn import o3\n",
    "\n",
    "torch.manual_seed(32)\n",
    "\n",
    "\n",
    "avg_num_neighbors = None\n",
    "\n",
    "\n",
    "# 3 conv layers\n",
    "conv1 = ConvNetLayer(irreps_in = sh.irreps_out, \n",
    "                    feature_irreps_hidden = '32x0e+32x1e+32x2e+32x1o+32x2o',\n",
    "                    convolution = InteractionBlock,\n",
    "                    convolution_kwargs={'invariant_layers': 2, \n",
    "                                        'invariant_neurons': 64,\n",
    "                                        'avg_num_neighbors': avg_num_neighbors}\n",
    "                   )\n",
    "\n",
    "\n",
    "conv2 = ConvNetLayer(irreps_in = conv1.irreps_out, \n",
    "                    feature_irreps_hidden = '32x0e+32x1e+32x2e+32x1o+32x2o',\n",
    "                    convolution = InteractionBlock,\n",
    "                    convolution_kwargs={'invariant_layers': 2, \n",
    "                                        'invariant_neurons': 64,\n",
    "                                        'avg_num_neighbors': avg_num_neighbors}\n",
    "                   )\n",
    "\n",
    "conv3 = ConvNetLayer(irreps_in = conv2.irreps_out, \n",
    "                    feature_irreps_hidden = '32x0e+32x0o+32x1e+32x2e+32x1o+32x2o',\n",
    "                    convolution = InteractionBlock,\n",
    "                    convolution_kwargs={'invariant_layers': 2, \n",
    "                                        'invariant_neurons': 64,\n",
    "                                        'avg_num_neighbors': avg_num_neighbors}\n",
    "                   )\n",
    "\n",
    "# Last linear\n",
    "from vladimir import conv\n",
    "from vladimir import AtomwiseLinear\n",
    "from e3nn import o3\n",
    "\n",
    "torch.manual_seed(32)\n",
    "\n",
    "\n",
    "al2 = AtomwiseLinear(irreps_in=conv3.irreps_out, irreps_out=o3.Irreps([(16, (0, 1))]))\n",
    "al3 = AtomwiseLinear(irreps_in=al2.irreps_out, irreps_out=o3.Irreps([(1, (0, 1))]))\n",
    "\n",
    "\n",
    "# Shift and scale\n",
    "from vladimir import PerSpeciesScaleShift\n",
    "\n",
    "torch.manual_seed(32)\n",
    "\n",
    "\n",
    "num_types = 2\n",
    "\n",
    "scales = [-11319.556641, -11319.556641]\n",
    "shifts = [1/30.621034622192383, 1/30.621034622192383]\n",
    "\n",
    "psss = PerSpeciesScaleShift(\n",
    "    field = 'node_features',\n",
    "    type_names = ['H', 'C'],\n",
    "    num_types = num_types,\n",
    "    shifts = shifts,\n",
    "    scales = scales,\n",
    "    arguments_in_dataset_units = True,\n",
    "    scales_trainable = True,\n",
    "    shifts_trainable = True,\n",
    "    irreps_in = al3.irreps_out)\n",
    "\n",
    "# Reduce\n",
    "from vladimir import AtomwiseReduce\n",
    "\n",
    "torch.manual_seed(32)\n",
    "\n",
    "\n",
    "num_types = 2\n",
    "\n",
    "scales = [1., 1.]\n",
    "shifts = [0., 0.]\n",
    "\n",
    "ar = AtomwiseReduce(\n",
    "    field = 'shifted_node_features',\n",
    "    out_field = 'total_energy',\n",
    "    reduce = 'sum',\n",
    "    irreps_in = psss.irreps_out)\n",
    "\n",
    "\n",
    "from vladimir import SequentialGraphNetwork\n",
    "\n",
    "module_list = [one_hot, al,\n",
    "               rbe, sh,\n",
    "               conv1, conv2, conv3,\n",
    "               al2, al3,\n",
    "               psss, ar]\n",
    "\n",
    "graph_func = SequentialGraphNetwork(module_list)\n",
    "\n",
    "from vladimir import StressOutput\n",
    "\n",
    "torch.manual_seed(32)\n",
    "\n",
    "so = StressOutput(graph_func)\n",
    "\n",
    "from vladimir import RescaleOutput\n",
    "\n",
    "torch.manual_seed(32)\n",
    "\n",
    "rescale = RescaleOutput(model = so,\n",
    "        scale_keys = ['pos', 'total_energy', 'forces', 'stress', 'virial'],\n",
    "        shift_keys = ['total_energy'],\n",
    "        scale_by=None,\n",
    "        shift_by=None,\n",
    "        shift_trainable = False,\n",
    "        scale_trainable = False,\n",
    "        irreps_in = so.irreps_in)\n",
    "\n",
    "from vladimir import GraphModel\n",
    "\n",
    "torch.manual_seed(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce689999",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nequip.model._gmm import GraphModel\n",
    "\n",
    "gm = GraphModel(rescale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8c1e943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nequip.nn._graph_model.GraphModel'>\n"
     ]
    }
   ],
   "source": [
    "print(type(gm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54517cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Torch device: cpu\n",
      "Number of weights: 227420\n",
      "Number of trainable weights: 227420\n",
      "! Starting training ...\n",
      "\n",
      "validation\n",
      "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
      "      0     5      1.6e+08     1.67e+07     1.44e+08     3.02e+03     4.09e+03     2.21e+03     3.94e+03     3.07e+03     2.95e+03     5.09e+03     4.02e+03      1.8e+05      1.2e+04\n",
      "\n",
      "\n",
      "  Initialization     #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
      "! Initial Validation          0    2.061    0.005     1.47e+07     1.44e+08     1.59e+08     2.85e+03     3.84e+03     1.98e+03     3.85e+03     2.91e+03     2.59e+03     4.88e+03     3.74e+03      1.8e+05      1.2e+04\n",
      "Wall time: 2.0631081250030547\n",
      "! Best model        0 159085408.000\n",
      "! Stop training: Early stopping: validation_loss is larger than 10000.0\n",
      "Wall time: 2.121133742009988\n",
      "Cumulative wall time: 2.121133742009988\n"
     ]
    }
   ],
   "source": [
    "# Trainer\n",
    "from nequip.train.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(model = gm, **Config.as_dict(config))\n",
    "\n",
    "# what is this\n",
    "# to update wandb data?\n",
    "config.update(trainer.params)\n",
    "\n",
    "# = Train/test split =\n",
    "trainer.set_dataset(dataset, validation_dataset)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c25eab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_mkl",
   "language": "python",
   "name": "torch_mkl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
