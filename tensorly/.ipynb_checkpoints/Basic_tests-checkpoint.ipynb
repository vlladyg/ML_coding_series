{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5dcd9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TuckerTensor(shape=(20, 10), rank=(4, 2))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tltorch import FactorizedTensor\n",
    "\n",
    "shape = (20, 10)\n",
    "\n",
    "#factorized_tensor = FactorizedTensor.new(shape, rank, factorization)\n",
    "\n",
    "tucker_tensor = FactorizedTensor.new(shape, rank=0.5, factorization='tucker')\n",
    "\n",
    "tucker_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "722c814c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "prod() received an invalid combination of arguments - got (out=NoneType, axis=NoneType, ), but expected one of:\n * (*, torch.dtype dtype)\n      didn't match because some of the keywords were incorrect: out, axis\n * (int dim, bool keepdim, *, torch.dtype dtype)\n * (name dim, bool keepdim, *, torch.dtype dtype)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m dense_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mFactorizedTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdense_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactorization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcp_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(cp_tensor)\n",
      "File \u001b[0;32m~/Documents/GitHub/ML_coding_series/torch/tltorch/factorized_tensors/core.py:227\u001b[0m, in \u001b[0;36mFactorizedTensor.new\u001b[0;34m(cls, shape, rank, factorization, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGot factorization=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfactorization\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but expected\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    225\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mone of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_factorizations\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/ML_coding_series/torch/tltorch/factorized_tensors/factorized_tensors.py:97\u001b[0m, in \u001b[0;36mCPTensor.new\u001b[0;34m(cls, shape, rank, device, dtype, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew\u001b[39m(\u001b[38;5;28mcls\u001b[39m, shape, rank, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 97\u001b[0m     rank \u001b[38;5;241m=\u001b[39m \u001b[43mtl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcp_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_cp_rank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# Register the parameters\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     weights \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mempty(rank, device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mdtype))\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_mkl/lib/python3.10/site-packages/tensorly/cp_tensor.py:274\u001b[0m, in \u001b[0;36mvalidate_cp_rank\u001b[0;34m(tensor_shape, rank, rounding)\u001b[0m\n\u001b[1;32m    271\u001b[0m     rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rank, \u001b[38;5;28mfloat\u001b[39m):\n\u001b[0;32m--> 274\u001b[0m     rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(rounding_fun(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_shape\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m rank \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(tensor_shape)))\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rank\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_mkl/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3100\u001b[0m, in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2979\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_prod_dispatcher)\n\u001b[1;32m   2980\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprod\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2981\u001b[0m          initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2982\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2983\u001b[0m \u001b[38;5;124;03m    Return the product of array elements over a given axis.\u001b[39;00m\n\u001b[1;32m   2984\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3098\u001b[0m \u001b[38;5;124;03m    10\u001b[39;00m\n\u001b[1;32m   3099\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprod\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3101\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_mkl/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: prod() received an invalid combination of arguments - got (out=NoneType, axis=NoneType, ), but expected one of:\n * (*, torch.dtype dtype)\n      didn't match because some of the keywords were incorrect: out, axis\n * (int dim, bool keepdim, *, torch.dtype dtype)\n * (name dim, bool keepdim, *, torch.dtype dtype)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "dense_tensor = torch.randn(20, 10)\n",
    "\n",
    "FactorizedTensor.new(dense_tensor, rank=0.1, factorization='CP', out = cp_tensor)\n",
    "\n",
    "print(cp_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb1bf50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p2/mwhbpbfx4dx636dcf50t7_rr0000gn/T/ipykernel_79264/3695535824.py:13: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(cp_tensor)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(CPTensor(shape=(2, 2), rank=3), tensor(0.2627, grad_fn=<SumBackward1>))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tltorch import FactorizedTensor\n",
    "\n",
    "shape = (20, 10)\n",
    "\n",
    "#factorized_tensor = FactorizedTensor.new(shape, rank, factorization)\n",
    "\n",
    "cp_tensor = FactorizedTensor.new(shape, rank=0.5, factorization='CP')\n",
    "\n",
    "cp_tensor.normal_(mean=0, std=0.02)\n",
    "\n",
    "from torch.nn import init\n",
    "\n",
    "init.kaiming_normal(cp_tensor)\n",
    "\n",
    "cp_tensor[:2, :2], cp_tensor[2, 3, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "025d8205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CPTensorized(shape=[16, 21], tensorized_shape=((4, 4), (3, 7)), rank=2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tltorch import TensorizedTensor\n",
    "\n",
    "matrix = torch.ones(16, 21)\n",
    "\n",
    "out_tensor = TensorizedTensor.from_matrix(matrix, (4, 4), (3, 7), rank = 2)\n",
    "\n",
    "out_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b5d7d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/temporary/anaconda3/envs/torch_mkl/lib/python3.10/site-packages/tensorly/tt_tensor.py:239: UserWarning: Determining the tt-rank for the trivial case of a matrix (order 2 tensor) of shape (80, 210), not a higher-order tensor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randn(5, 10, 16, 21)\n",
    "\n",
    "tensorized_tensor = TensorizedTensor.from_tensor(tensor, (5, (4, 4), (3, 7)), rank=0.7, factorization='BlockTT')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fe0490c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p2/mwhbpbfx4dx636dcf50t7_rr0000gn/T/ipykernel_79264/1738940403.py:5: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(ftt)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0076, -0.0009],\n",
       "        [ 0.0138, -0.0018]], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tltorch\n",
    "\n",
    "ftt = tltorch.TensorizedTensor.new((5, (2, 2, 2), (3, 3, 3)), rank=0.5, factorization='BlockTT')\n",
    "\n",
    "init.kaiming_normal(ftt)\n",
    "\n",
    "ftt[2]\n",
    "\n",
    "ftt[0, :2, :2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c908a0",
   "metadata": {},
   "source": [
    "### Tensor Regression Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d210eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tltorch\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d586e255",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (4, 5)\n",
    "output_shape = (6, 2)\n",
    "batch_size = 2\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "x = torch.randn((batch_size,) + input_shape,\n",
    "                dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa396c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor regression layer\n",
    "trl = tltorch.TRL(input_shape, output_shape, rank='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c42206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = trl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3aa408e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c8279b",
   "metadata": {},
   "source": [
    "### Tensorised convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e419ade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tltorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b768764a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 16, 24, 24), (32, 16, 3, 3))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device='cpu'\n",
    "input_channels = 16\n",
    "output_channels = 32\n",
    "kernel_size = 3\n",
    "batch_size = 2\n",
    "size = 24\n",
    "order = 2\n",
    "\n",
    "input_shape = (batch_size, input_channels) + (size, )*order\n",
    "kernel_shape = (output_channels, input_channels) + (kernel_size, )*order\n",
    "\n",
    "input_shape, kernel_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3878a0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.randn(input_shape, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b26d942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch convolution layer\n",
    "conv = torch.nn.Conv2d(input_channels, output_channels, kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df8c23e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tltorch\n",
    "\n",
    "# Tensorized convolution\n",
    "fact_conv = tltorch.FactorizedConv(input_channels, \n",
    "                              output_channels, \n",
    "                              kernel_size,\n",
    "                              order=2,\n",
    "                              rank='same',\n",
    "                              factorization='cp')\n",
    "\n",
    "# Same\n",
    "fact_conv = tltorch.FactorizedConv(input_channels,\n",
    "                                   output_channels,\n",
    "                                   kernel_size=(3, 3),\n",
    "                                   rank='same')\n",
    "\n",
    "# Same but from| convolution\n",
    "fact_conv = tltorch.FactorizedConv.from_conv(conv,\n",
    "                                             rank=0.5,\n",
    "                                             decompose_weights=True,\n",
    "                                             factorization='tucker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db751088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some specific form\n",
    "fact_conv = tltorch.FactorizedConv.from_conv(conv,\n",
    "                                             rank=0.5,\n",
    "                                             factorization='cp',\n",
    "                                             implementation='mobilenet')\n",
    "\n",
    "fact_conv = tltorch.FactorizedConv.from_conv(conv,\n",
    "                                             rank=0.5,\n",
    "                                             factorization='tucker',\n",
    "                                             implementation='factorized')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20b2372",
   "metadata": {},
   "source": [
    "### Tensorized Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48523544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tltorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ff40e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.randn((4, 16), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65bd5d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Linear(in_features=16, out_features = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fa6c806",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_linear = tltorch.FactorizedLinear.from_linear(linear, auto_tensorize=False,\n",
    "                    in_tensorized_features=(4, 4), out_tensorized_features=(2, 5), rank=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f64ec52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 2, 5])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Size([4, 4, 2, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37ea7113",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_linear = tltorch.FactorizedLinear.from_linear(linear,\n",
    "                                                   auto_tensorize=True,\n",
    "                                                   n_tensorized_modes=2,\n",
    "                                                   rank=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b27dfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_linear = tltorch.FactorizedLinear(in_tensorized_features=(4, 4),\n",
    "                                       out_tensorized_features=(2, 5),\n",
    "                                       factorization='tucker', rank=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b0751e",
   "metadata": {},
   "source": [
    "### Tensorized embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "138f2217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tltorch\n",
    "import torch\n",
    "\n",
    "num_embeddings = (10, 10)\n",
    "embedding_dim = (10, 10)\n",
    "\n",
    "# No working\n",
    "#from_embedding = tltorch.FactorizedEmbedding(num_embeddings,\n",
    "#                                             embedding_dim,\n",
    "#                                             auto_tensorize=True,\n",
    "#                                             n_tensorized_modes=3,\n",
    "#                                             rank=0.4)\n",
    "#n, d, m = 3, 5, 7\n",
    "#embedding_layer = torch.nn.Embedding(n, d, max_norm=1.0)\n",
    "\n",
    "#from_embedding = tltorch.FactorizedEmbedding.from_embedding(embedding_layer, auto_tensorize=True,\n",
    "#            factorization='blocktt', n_tensorized_modes=3, rank=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f165b4fc",
   "metadata": {},
   "source": [
    "### Tensor hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "909126f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tltorch\n",
    "trl = tltorch.TRL((10, 10), (10, ), rank='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c221fa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trl = tltorch.tensor_dropout(trl.weight, p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fb55666e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CPTensor(shape=(10, 10, 10), rank=33)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tltorch.remove_tensor_dropout(trl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e464213d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tensors used as indices must be long, int, byte or bool tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m l1_reg \u001b[38;5;241m=\u001b[39m tltorch\u001b[38;5;241m.\u001b[39mtensor_lasso(penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m      2\u001b[0m l1_reg\u001b[38;5;241m.\u001b[39mapply(trl)\n\u001b[0;32m----> 3\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtrl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m loss \u001b[38;5;241m=\u001b[39m my_loss(x) \u001b[38;5;241m+\u001b[39m l1_reg\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m      5\u001b[0m l1_reg\u001b[38;5;241m.\u001b[39mres\n",
      "File \u001b[0;32m~/Documents/GitHub/pytorch-intel-mps/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1536\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1540\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1541\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1542\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1543\u001b[0m     ):\n",
      "File \u001b[0;32m~/Documents/GitHub/ML_coding_series/torch/tltorch/factorized_tensors/core.py:276\u001b[0m, in \u001b[0;36mFactorizedTensor.forward\u001b[0;34m(self, indices, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/ML_coding_series/torch/tltorch/factorized_tensors/factorized_tensors.py:173\u001b[0m, in \u001b[0;36mCPTensor.__getitem__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m tl\u001b[38;5;241m.\u001b[39msum(weights\u001b[38;5;241m*\u001b[39mmixing_factor[index, :])\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m         index_factors\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmixing_factor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(weights, index_factors \u001b[38;5;241m+\u001b[39m factors)\n",
      "\u001b[0;31mIndexError\u001b[0m: tensors used as indices must be long, int, byte or bool tensors"
     ]
    }
   ],
   "source": [
    "l1_reg = tltorch.tensor_lasso(penalty=0.01)\n",
    "l1_reg.apply(trl)\n",
    "x = trl(x)\n",
    "loss = my_loss(x) + l1_reg.loss\n",
    "l1_reg.res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "844ec0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_reg.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a819bcb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0014, grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftt.normal_(0, 0.02)[0][0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adef1192",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_mkl",
   "language": "python",
   "name": "torch_mkl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
