{"cells":[{"cell_type":"markdown","metadata":{"id":"XuXWJLEm2UWS"},"source":["# **CS224W - Colab 2**"]},{"cell_type":"markdown","metadata":{"id":"8gzsP50bF6Gb"},"source":["In Colab 2, we will work to construct our own graph neural network using PyTorch Geometric (PyG) and then apply that model on two Open Graph Benchmark (OGB) datasets. These two datasets will be used to benchmark your model's performance on two different graph-based tasks: 1) node property prediction, predicting properties of single nodes and 2) graph property prediction, predicting properties of entire graphs or subgraphs.\n","\n","First, we will learn how PyTorch Geometric stores graphs as PyTorch tensors.\n","\n","Then, we will load and inspect one of the Open Graph Benchmark (OGB) datasets by using the `ogb` package. OGB is a collection of realistic, large-scale, and diverse benchmark datasets for machine learning on graphs. The `ogb` package not only provides data loaders for each dataset but also model evaluators.\n","\n","Lastly, we will build our own graph neural network using PyTorch Geometric. We will then train and evaluate our model on the OGB node property prediction and graph property prediction tasks.\n","\n","**Note**: Make sure to **sequentially run all the cells in each section**, so that the intermediate variables / packages will carry over to the next cell\n","\n","We recommend you save a copy of this colab in your drive so you don't lose progress!\n","\n","The expected time to finish this Colab is 2 hours. However, debugging training loops can easily take a while. So, don't worry at all if it takes you longer! Have fun and good luck on Colab 2 :)"]},{"cell_type":"markdown","metadata":{"id":"ZGKqVEbbMEzf"},"source":["# Device\n","You might need to use a GPU for this Colab to run quickly.\n","\n","Please click `Runtime` and then `Change runtime type`. Then set the `hardware accelerator` to **GPU**."]},{"cell_type":"markdown","metadata":{"id":"OCK7krJdp4o8"},"source":["# Setup\n","As discussed in Colab 0, the installation of PyG on Colab can be a little bit tricky. First let us check which version of PyTorch you are running"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2vkP8pA1qBE5","executionInfo":{"status":"ok","timestamp":1733204978149,"user_tz":480,"elapsed":4185,"user":{"displayName":"Surya Narayanan Hari","userId":"04330485514801964147"}},"outputId":"d9ca3a9c-86c8-4d05-8b3c-b3c860b314ea","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch has version 2.4.0+cu121\n"]}],"source":["import torch\n","import os\n","print(\"PyTorch has version {}\".format(torch.__version__))"]},{"cell_type":"code","source":["if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  !pip install torch==2.4.0"],"metadata":{"id":"WUo5V7HNSXYm","executionInfo":{"status":"ok","timestamp":1733204983522,"user_tz":480,"elapsed":5375,"user":{"displayName":"Surya Narayanan Hari","userId":"04330485514801964147"}},"outputId":"95900f68-6a36-4b29-fa15-0d0c4d8e6cf8","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.10/dist-packages (2.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (2024.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n","Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.0.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.6.77)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n"]}]},{"cell_type":"markdown","metadata":{"id":"L6d22O6DqGSZ"},"source":["Download the necessary packages for PyG. Make sure that your version of torch matches the output from the cell above. In case of any issues, more information can be found on the [PyG's installation page](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zr8hfxJ-qRg2","executionInfo":{"status":"ok","timestamp":1733205000873,"user_tz":480,"elapsed":17354,"user":{"displayName":"Surya Narayanan Hari","userId":"04330485514801964147"}},"outputId":"5c270d68-6f24-49d0-a879-4745f3c125fb","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://pytorch-geometric.com/whl/torch-2.4.0+cu121.html\n","Requirement already satisfied: torch-scatter in /usr/local/lib/python3.10/dist-packages (2.1.2+pt25cu121)\n","Looking in links: https://pytorch-geometric.com/whl/torch-2.4.0+cu121.html\n","Requirement already satisfied: torch-sparse in /usr/local/lib/python3.10/dist-packages (0.6.18+pt25cu121)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n","Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n","Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.10.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.17.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n","Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n","Requirement already satisfied: ogb in /usr/local/lib/python3.10/dist-packages (1.3.6)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.4.0)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.26.4)\n","Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (4.66.6)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.5.2)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.2.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.16.0)\n","Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.2.3)\n","Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (0.2.2)\n","Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (75.1.0)\n","Requirement already satisfied: littleutils in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (0.2.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (2.32.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2024.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (3.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2024.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (12.1.105)\n","Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.0.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->ogb) (12.6.77)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->ogb) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (2024.8.30)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n"]}],"source":["# Install torch geometric\n","if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  torch_version = str(torch.__version__)\n","  scatter_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n","  sparse_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n","  !pip install torch-scatter -f $scatter_src\n","  !pip install torch-sparse -f $sparse_src\n","  !pip install torch-geometric\n","  !pip install ogb"]},{"cell_type":"markdown","metadata":{"id":"Nwwq0nSdmsOL"},"source":["# 1) PyTorch Geometric (Datasets and Data)\n"]},{"cell_type":"markdown","metadata":{"id":"Sf7vUmdNKCjA"},"source":["PyTorch Geometric has two classes for storing and/or transforming graphs into tensor format. One is `torch_geometric.datasets`, which contains a variety of common graph datasets. Another is `torch_geometric.data`, which provides the data handling of graphs in PyTorch tensors.\n","\n","In this section, we will learn how to use `torch_geometric.datasets` and `torch_geometric.data` together."]},{"cell_type":"markdown","metadata":{"id":"ic-o1P3r6hr2"},"source":["## PyG Datasets\n","\n","The `torch_geometric.datasets` class has many common graph datasets. Here we will explore its usage through one example dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zT5qca3x6XpG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733205015555,"user_tz":480,"elapsed":14685,"user":{"displayName":"Surya Narayanan Hari","userId":"04330485514801964147"}},"outputId":"830c7e40-337b-4b11-dbab-58673069a6de"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_scatter/_scatter_cuda.so: undefined symbol: _ZN2at23SavedTensorDefaultHooks11set_tracingEb\n","  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n","/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_sparse/_spmm_cuda.so: undefined symbol: _ZN2at23SavedTensorDefaultHooks11set_tracingEb\n","  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n","Downloading https://www.chrsmrrs.com/graphkerneldatasets/ENZYMES.zip\n","Processing...\n"]},{"output_type":"stream","name":"stdout","text":["ENZYMES(600)\n"]},{"output_type":"stream","name":"stderr","text":["Done!\n"]}],"source":["from torch_geometric.datasets import TUDataset\n","\n","if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  root = './enzymes'\n","  name = 'ENZYMES'\n","\n","  # The ENZYMES dataset\n","  pyg_dataset= TUDataset(root, name)\n","\n","  # You will find that there are 600 graphs in this dataset\n","  print(pyg_dataset)"]},{"cell_type":"markdown","metadata":{"id":"NLm5vVYMAP2x"},"source":["## Question 1: What is the number of classes and number of features in the ENZYMES dataset?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8iF_Kyqr_JbY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733205015555,"user_tz":480,"elapsed":7,"user":{"displayName":"Surya Narayanan Hari","userId":"04330485514801964147"}},"outputId":"bab06a80-f55c-43a3-9cc7-3d817cd70110"},"outputs":[{"output_type":"stream","name":"stdout","text":["ENZYMES dataset has 6 classes\n","ENZYMES dataset has 3 features\n"]}],"source":["def get_num_classes(pyg_dataset):\n","  # returns the number of classes for that dataset.\n","\n","  return pyg_dataset.num_classes\n","\n","def get_num_features(pyg_dataset):\n","  # returns the number of features for that dataset.\n","\n","  return pyg_dataset.num_features\n","\n","if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  num_classes = get_num_classes(pyg_dataset)\n","  num_features = get_num_features(pyg_dataset)\n","  print(\"{} dataset has {} classes\".format(name, num_classes))\n","  print(\"{} dataset has {} features\".format(name, num_features))"]},{"cell_type":"markdown","metadata":{"id":"rwKbzhHUAckZ"},"source":["## PyG Data\n","\n","Each PyG dataset stores a list of `torch_geometric.data.Data` objects, where each `torch_geometric.data.Data` object represents a graph. We can easily get the `Data` object by indexing into the dataset.\n","\n","For more information such as what is stored in the `Data` object, please refer to the [documentation](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data)."]},{"cell_type":"markdown","metadata":{"id":"7sCV3xJWCddX"},"source":["## Question 2: What is the label of the graph with index 100 in the ENZYMES dataset?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LIis9oTZAfs3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733205015556,"user_tz":480,"elapsed":6,"user":{"displayName":"Surya Narayanan Hari","userId":"04330485514801964147"}},"outputId":"b85392c4-4061-49fb-f0ff-901c000e06f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data(edge_index=[2, 168], x=[37, 3], y=[1])\n","Graph with index 100 has label 4\n"]}],"source":["def get_graph_class(pyg_dataset, idx):\n","  # Get the graph with the given index\n","  graph = pyg_dataset[idx]\n","\n","  # Get the label of the graph\n","  label = graph.y.item()\n","\n","  return label\n","\n","# Here pyg_dataset is a dataset for graph classification\n","if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  graph_0 = pyg_dataset[0]\n","  print(graph_0)\n","  idx = 100\n","  label = get_graph_class(pyg_dataset, idx)\n","  print('Graph with index {} has label {}'.format(idx, label))"]},{"cell_type":"markdown","metadata":{"id":"fKhcVeAhCwoY"},"source":["## Question 3: How many edges does the graph with index 200 have?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f5m2DOfhBtWv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733205015556,"user_tz":480,"elapsed":5,"user":{"displayName":"Surya Narayanan Hari","userId":"04330485514801964147"}},"outputId":"39e903d1-0d93-4256-b612-e4edc5817006"},"outputs":[{"output_type":"stream","name":"stdout","text":["Graph with index 200 has 53 edges\n"]}],"source":["def get_graph_num_edges(pyg_dataset, idx):\n","  # Get the graph with the given index\n","  graph = pyg_dataset[idx]\n","\n","  # Get the edge index\n","  edge_index = graph.edge_index\n","\n","  # Convert the edge index to a set of tuples\n","  edges = set()\n","  for i in range(edge_index.shape[1]):\n","    node1 = edge_index[0, i].item()\n","    node2 = edge_index[1, i].item()\n","    # Add the edge to the set, ensuring we don't count it twice\n","    edges.add(tuple(sorted((node1, node2))))\n","\n","  # The number of edges is the length of the set\n","  num_edges = len(edges)\n","\n","  return num_edges\n","\n","if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  idx = 200\n","  num_edges = get_graph_num_edges(pyg_dataset, idx)\n","  print('Graph with index {} has {} edges'.format(idx, num_edges))"]},{"cell_type":"markdown","metadata":{"id":"AXa7yIG4E0Fp"},"source":["# 2) Open Graph Benchmark (OGB)\n","\n","The Open Graph Benchmark (OGB) is a collection of realistic, large-scale, and diverse benchmark datasets for machine learning on graphs. Its datasets are automatically downloaded, processed, and split using the OGB Data Loader. The model performance can then be evaluated by using the OGB Evaluator in a unified manner."]},{"cell_type":"markdown","metadata":{"id":"HnazPGGAJAZN"},"source":["## Dataset and Data\n","\n","OGB also supports PyG dataset and data classes. Here we take a look on the `ogbn-arxiv` dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gpc6bTm3GF02","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733205031277,"user_tz":480,"elapsed":15724,"user":{"displayName":"Surya Narayanan Hari","userId":"04330485514801964147"}},"outputId":"6caa6c13-5202-42da-da75-23290a75b486"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://snap.stanford.edu/ogb/data/nodeproppred/arxiv.zip\n"]},{"output_type":"stream","name":"stderr","text":["Downloaded 0.08 GB: 100%|██████████| 81/81 [00:01<00:00, 50.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting dataset/arxiv.zip\n"]},{"output_type":"stream","name":"stderr","text":["Processing...\n"]},{"output_type":"stream","name":"stdout","text":["Loading necessary files...\n","This might take a while.\n","Processing graphs...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 1857.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Converting graphs into PyG objects...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 3738.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Saving...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Done!\n","/usr/local/lib/python3.10/dist-packages/ogb/nodeproppred/dataset_pyg.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  self.data, self.slices = torch.load(self.processed_paths[0])\n"]},{"output_type":"stream","name":"stdout","text":["The ogbn-arxiv dataset has 1 graph\n","Data(num_nodes=169343, x=[169343, 128], node_year=[169343, 1], y=[169343, 1], adj_t=[169343, 169343])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch_geometric/utils/sparse.py:277: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n","  adj = torch.sparse_csr_tensor(\n"]}],"source":["import torch_geometric.transforms as T\n","from ogb.nodeproppred import PygNodePropPredDataset\n","\n","if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  dataset_name = 'ogbn-arxiv'\n","  # Load the dataset and transform it to sparse tensor\n","  dataset = PygNodePropPredDataset(name=dataset_name,\n","                                  transform=T.ToSparseTensor())\n","  print('The {} dataset has {} graph'.format(dataset_name, len(dataset)))\n","\n","  # Extract the graph\n","  data = dataset[0]\n","  print(data)"]},{"cell_type":"markdown","metadata":{"id":"Cw0xZJKZI-n3"},"source":["## Question 4: How many features are in the ogbn-arxiv graph?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZP844_nT2ZJl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733205031277,"user_tz":480,"elapsed":6,"user":{"displayName":"Surya Narayanan Hari","userId":"04330485514801964147"}},"outputId":"0a1b8b45-9d74-4ff8-9d3e-c1ce9118854d"},"outputs":[{"output_type":"stream","name":"stdout","text":["The graph has 128 features\n"]}],"source":["def graph_num_features(data):\n","  # returns the number of features in the graph (as an integer).\n","\n","  return data.num_features\n","\n","if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  num_features = graph_num_features(data)\n","  print('The graph has {} features'.format(num_features))"]},{"cell_type":"markdown","metadata":{"id":"9DP_yEQZ0NVW"},"source":["# 3) GNN: Node Property Prediction\n","\n","In this section we will build our first graph neural network using PyTorch Geometric. Then we will apply it to the task of node property prediction (node classification).\n","\n","Specifically, we will use GCN as the foundation for your graph neural network ([Kipf et al. (2017)](https://arxiv.org/pdf/1609.02907.pdf)). To do so, we will work with PyG's built-in `GCNConv` layer."]},{"cell_type":"markdown","metadata":{"id":"O4CcOUEoInjD"},"source":["## Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-DCtgcHpGIpd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733205031277,"user_tz":480,"elapsed":4,"user":{"displayName":"Surya Narayanan Hari","userId":"04330485514801964147"}},"outputId":"b84f5a8e-2cca-4c65-d7c8-5dbb9ca25d9f"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.4.0+cu121\n"]}],"source":["import torch\n","import pandas as pd\n","import torch.nn.functional as F\n","print(torch.__version__)\n","\n","# The PyG built-in GCNConv\n","from torch_geometric.nn import GCNConv\n","\n","import torch_geometric.transforms as T\n","from ogb.nodeproppred import PygNodePropPredDataset, Evaluator"]},{"cell_type":"markdown","metadata":{"id":"0IK9z0wQIwzQ"},"source":["## Load and Preprocess the Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ibJ0ieoIwQM","colab":{"base_uri":"https://localhost:8080/","height":271},"executionInfo":{"status":"error","timestamp":1733205031659,"user_tz":480,"elapsed":384,"user":{"displayName":"Surya Narayanan Hari","userId":"04330485514801964147"}},"outputId":"f9e8a074-0aca-4a0e-a212-87159521db8f"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ogb/nodeproppred/dataset_pyg.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  self.data, self.slices = torch.load(self.processed_paths[0])\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'Tensor' object has no attribute 'to_symmetric'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-e4add20b3b22>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m# Make the adjacency matrix to symmetric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_symmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'to_symmetric'"]}],"source":["if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  dataset_name = 'ogbn-arxiv'\n","  dataset = PygNodePropPredDataset(name=dataset_name,\n","                                  transform=T.ToSparseTensor())\n","  data = dataset[0]\n","\n","  # Make the adjacency matrix to symmetric\n","  data.adj_t = data.adj_t.to_symmetric()\n","\n","  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","  # If you use GPU, the device should be cuda\n","  print('Device: {}'.format(device))\n","\n","  data = data.to(device)\n","  split_idx = dataset.get_idx_split()\n","  train_idx = split_idx['train'].to(device)"]},{"cell_type":"markdown","metadata":{"id":"OgUA815bNJ8w"},"source":["## GCN Model\n","\n","Now we will implement our GCN model!\n","\n","Please follow the figure below to implement the `forward` function.\n","\n","\n","![test](https://drive.google.com/uc?id=128AuYAXNXGg7PIhJJ7e420DoPWKb-RtL)"]},{"cell_type":"markdown","source":["# Graph Convolutional Network (GCN) Implementation\n","\n","This code implements a flexible Graph Convolutional Network with several key architectural features:\n","\n","## Architecture Components\n","1. **Multiple GCN Layers**:\n","   - Configurable number of layers\n","   - Consistent hidden dimension across intermediate layers\n","   - Input and output dimensions can be specified separately\n","\n","2. **Regularization Features**:\n","   - Batch normalization after each hidden layer\n","   - Dropout for preventing overfitting\n","   - ReLU activation between layers\n","\n","3. **Flexibility Options**:\n","   - Can return node embeddings or classification outputs\n","   - Includes parameter reset functionality\n","   - Configurable architecture depth\n","\n","## Processing Flow\n","The network processes graph data through sequential layers of:\n","1. Graph convolution\n","2. Batch normalization\n","3. ReLU activation\n","4. Dropout\n","Finally applying softmax for classification (unless returning embeddings)"],"metadata":{"id":"J82PlLRrWAYe"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"IgspXTYpNJLA"},"outputs":[],"source":["class GCN(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n","                 dropout, return_embeds=False):\n","\n","        super(GCN, self).__init__()\n","\n","        # A list of GCNConv layers\n","        self.convs = torch.nn.ModuleList()\n","        self.convs.append(GCNConv(input_dim, hidden_dim))  # First layer\n","        for _ in range(num_layers - 2):  # Hidden layers\n","            self.convs.append(GCNConv(hidden_dim, hidden_dim))\n","        self.convs.append(GCNConv(hidden_dim, output_dim))  # Last layer\n","\n","        # A list of 1D batch normalization layers\n","        self.bns = torch.nn.ModuleList()\n","        for _ in range(num_layers - 1):\n","            self.bns.append(torch.nn.BatchNorm1d(hidden_dim))\n","\n","        # The log softmax layer\n","        self.softmax = torch.nn.LogSoftmax(dim=-1)\n","\n","        # Probability of an element getting zeroed\n","        self.dropout = dropout\n","\n","        # Skip classification layer and return node embeddings\n","        self.return_embeds = return_embeds\n","\n","    def reset_parameters(self):\n","        for conv in self.convs:\n","            conv.reset_parameters()\n","        for bn in self.bns:\n","            bn.reset_parameters()\n","\n","    def forward(self, x, adj_t):\n","\n","        # First layer\n","        out = self.convs[0](x, adj_t)\n","        out = self.bns[0](out)\n","        out = F.relu(out)\n","        out = F.dropout(out, p=self.dropout, training=self.training)\n","\n","        # Hidden layers\n","        for i in range(1, len(self.convs) - 1):\n","            out = self.convs[i](out, adj_t)\n","            out = self.bns[i](out)\n","            out = F.relu(out)\n","            out = F.dropout(out, p=self.dropout, training=self.training)\n","\n","        # Last layer\n","        out = self.convs[-1](out, adj_t)\n","\n","        # Skip classification layer and return node embeddings\n","        if self.return_embeds:\n","            return out\n","\n","        # Apply log softmax for classification\n","        out = self.softmax(out)\n","\n","        return out"]},{"cell_type":"markdown","source":["# GNN Training Function\n","\n","A streamlined training function for Graph Neural Networks that implements a single training step. The function handles:\n","\n","## Core Components\n","1. **Model State Management**:\n","   - Sets model to training mode\n","   - Handles gradient zeroing and updates\n","\n","2. **Forward Pass Processing**:\n","   - Processes node features and adjacency matrix\n","   - Focuses on specified training indices\n","   - Applies loss function to relevant nodes only\n","\n","3. **Optimization Step**:\n","   - Computes gradients via backpropagation\n","   - Updates model parameters using optimizer\n","   - Returns the computed loss for monitoring\n","\n","This function represents one complete training iteration and is typically called within an epoch loop."],"metadata":{"id":"PrPVcHYkWNTj"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FF1hnHUhO81e"},"outputs":[],"source":["def train(model, data, train_idx, optimizer, loss_fn):\n","    \"\"\"Train the model for one iteration\"\"\"\n","\n","    # Set model to training mode (enables dropout, batch norm, etc.)\n","    model.train()\n","    loss = 0\n","\n","    # Clear accumulated gradients from previous iteration\n","    optimizer.zero_grad()\n","\n","    # Forward pass: compute model predictions\n","    # data.x: node features, data.adj_t: adjacency matrix\n","    out = model(data.x, data.adj_t)\n","\n","    # Calculate loss only on training nodes\n","    # train_idx selects which nodes to use for training\n","    # squeeze() removes extra dimensions from target labels\n","    loss = loss_fn(out[train_idx], data.y[train_idx].squeeze())\n","\n","    # Backward pass: compute gradients\n","    loss.backward()\n","\n","    # Update model parameters using optimizer\n","    optimizer.step()\n","\n","    # Return scalar loss value for monitoring\n","    return loss.item()"]},{"cell_type":"markdown","source":["# GNN Evaluation Function\n","\n","A comprehensive evaluation function for Graph Neural Networks that tests model performance across multiple data splits (train/validation/test). Key features include:\n","\n","## Functionality\n","1. **Performance Evaluation**:\n","   - Runs model in evaluation mode\n","   - Computes predictions for entire dataset\n","   - Calculates accuracy for each data split\n","   \n","2. **Prediction Processing**:\n","   - Uses argmax for class prediction\n","   - Maintains dimension consistency\n","   - Handles batch processing efficiently\n","\n","3. **Results Management**:\n","   - Optional result saving functionality\n","   - Exports predictions to CSV\n","   - Returns accuracies for all splits\n","\n","The function is decorated with `@torch.no_grad()` for memory efficiency during evaluation."],"metadata":{"id":"HJ_tSzpkWXPf"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"aJdlrJQhPBsK"},"outputs":[],"source":["@torch.no_grad()  # Disable gradient computation for efficiency\n","def test(model, data, split_idx, evaluator, save_model_results=False):\n","    \"\"\"Evaluate model performance on train, validation, and test sets\"\"\"\n","\n","    # Set model to evaluation mode (disables dropout, batch norm, etc.)\n","    model.eval()\n","\n","    # Forward pass on full dataset\n","    out = model(data.x, data.adj_t)\n","\n","    # Convert logits to predictions by taking max probability class\n","    # keepdim=True maintains dimension for evaluator compatibility\n","    y_pred = out.argmax(dim=-1, keepdim=True)\n","\n","    # Calculate accuracy on training set\n","    train_acc = evaluator.eval({\n","        'y_true': data.y[split_idx['train']],  # True labels for training nodes\n","        'y_pred': y_pred[split_idx['train']],  # Predicted labels for training nodes\n","    })['acc']\n","\n","    # Calculate accuracy on validation set\n","    valid_acc = evaluator.eval({\n","        'y_true': data.y[split_idx['valid']],  # True labels for validation nodes\n","        'y_pred': y_pred[split_idx['valid']],  # Predicted labels for validation nodes\n","    })['acc']\n","\n","    # Calculate accuracy on test set\n","    test_acc = evaluator.eval({\n","        'y_true': data.y[split_idx['test']],  # True labels for test nodes\n","        'y_pred': y_pred[split_idx['test']],  # Predicted labels for test nodes\n","    })['acc']\n","\n","    # Optionally save model predictions to CSV\n","    if save_model_results:\n","        print(\"Saving Model Predictions\")\n","\n","        # Prepare predictions for saving\n","        data = {\n","            'y_pred': y_pred.view(-1).cpu().detach().numpy()  # Flatten and convert to numpy\n","        }\n","\n","        # Create DataFrame and save to CSV\n","        df = pd.DataFrame(data=data)\n","        df.to_csv('ogbn-arxiv_node.csv', sep=',', index=False)\n","\n","    return train_acc, valid_acc, test_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o7F46xkuLiOL"},"outputs":[],"source":["# Please do not change the args\n","if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  args = {\n","      'device': device,\n","      'num_layers': 3,\n","      'hidden_dim': 256,\n","      'dropout': 0.5,\n","      'lr': 0.01,\n","      'epochs': 100,\n","  }\n","  args"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dT8RyM2cPGxM"},"outputs":[],"source":["if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  model = GCN(data.num_features, args['hidden_dim'],\n","              dataset.num_classes, args['num_layers'],\n","              args['dropout']).to(device)\n","  evaluator = Evaluator(name='ogbn-arxiv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qd5O5cnPPdVF"},"outputs":[],"source":["# Please do not change these args\n","# Training should take <10min using GPU runtime\n","import copy\n","if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  # reset the parameters to initial random value\n","  model.reset_parameters()\n","\n","  optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n","  loss_fn = F.nll_loss\n","\n","  best_model = None\n","  best_valid_acc = 0\n","\n","  for epoch in range(1, 1 + args[\"epochs\"]):\n","    loss = train(model, data, train_idx, optimizer, loss_fn)\n","    result = test(model, data, split_idx, evaluator)\n","    train_acc, valid_acc, test_acc = result\n","    if valid_acc > best_valid_acc:\n","        best_valid_acc = valid_acc\n","        best_model = copy.deepcopy(model)\n","    print(f'Epoch: {epoch:02d}, '\n","          f'Loss: {loss:.4f}, '\n","          f'Train: {100 * train_acc:.2f}%, '\n","          f'Valid: {100 * valid_acc:.2f}% '\n","          f'Test: {100 * test_acc:.2f}%')"]},{"cell_type":"markdown","metadata":{"id":"dQtt-EKA8P4r"},"source":["## Question 5: What are your `best_model` validation and test accuracies?\n","\n","Run the cell below to see the results of your best of model and save your model's predictions to a file named *ogbn-arxiv_node.csv*. You can view this file by clicking on the *Folder* icon on the left side pannel. Report the results on Gradescope."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EqcextqOL2FX"},"outputs":[],"source":["if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  best_result = test(best_model, data, split_idx, evaluator, save_model_results=True)\n","  train_acc, valid_acc, test_acc = best_result\n","  print(f'Best model: '\n","        f'Train: {100 * train_acc:.2f}%, '\n","        f'Valid: {100 * valid_acc:.2f}% '\n","        f'Test: {100 * test_acc:.2f}%')"]},{"cell_type":"markdown","metadata":{"id":"R8pOD6y80TyI"},"source":["# 4) GNN: Graph Property Prediction\n","\n","In this section we will create a graph neural network for graph property prediction (graph classification).\n"]},{"cell_type":"markdown","metadata":{"id":"vRg5VOEdQTa4"},"source":["## Load and preprocess the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LXb-O5QUIgTH"},"outputs":[],"source":["from ogb.graphproppred import PygGraphPropPredDataset, Evaluator\n","from torch_geometric.data import DataLoader\n","from tqdm.notebook import tqdm\n","\n","if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  # Load the dataset\n","  dataset = PygGraphPropPredDataset(name='ogbg-molhiv')\n","\n","  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","  print('Device: {}'.format(device))\n","\n","  split_idx = dataset.get_idx_split()\n","\n","  # Check task type\n","  print('Task type: {}'.format(dataset.task_type))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7cHHbgW1c5hi"},"outputs":[],"source":["# Load the dataset splits into corresponding dataloaders\n","# We will train the graph classification task on a batch of 32 graphs\n","# Shuffle the order of graphs for training set\n","if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  train_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=32, shuffle=True, num_workers=0)\n","  valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=32, shuffle=False, num_workers=0)\n","  test_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=32, shuffle=False, num_workers=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AYrSnOj0Y4DK"},"outputs":[],"source":["if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  # Please do not change the args\n","  args = {\n","      'device': device,\n","      'num_layers': 5,\n","      'hidden_dim': 256,\n","      'dropout': 0.5,\n","      'lr': 0.001,\n","      'epochs': 30,\n","  }\n","  args"]},{"cell_type":"markdown","metadata":{"id":"7WLhguSTeazy"},"source":["## Graph Prediction Model"]},{"cell_type":"markdown","metadata":{"id":"u05Z14TRYPGn"},"source":["### Graph Mini-Batching\n","Before diving into the actual model, we introduce the concept of mini-batching with graphs. In order to parallelize the processing of a mini-batch of graphs, PyG combines the graphs into a single disconnected graph data object (*torch_geometric.data.Batch*). *torch_geometric.data.Batch* inherits from *torch_geometric.data.Data* (introduced earlier) and contains an additional attribute called `batch`.\n","\n","The `batch` attribute is a vector mapping each node to the index of its corresponding graph within the mini-batch:\n","\n","    batch = [0, ..., 0, 1, ..., n - 2, n - 1, ..., n - 1]\n","\n","This attribute is crucial for associating which graph each node belongs to and can be used to e.g. average the node embeddings for each graph individually to compute graph level embeddings.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Pcic9NNU3nGK"},"source":["### Implemention\n","Now, we have all of the tools to implement a GCN Graph Prediction model!  \n","\n","We will reuse the existing GCN model to generate `node_embeddings` and then use  `Global Pooling` over the nodes to create graph level embeddings that can be used to predict properties for the each graph. Remeber that the `batch` attribute will be essential for performining Global Pooling over our mini-batch of graphs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3_Kq3zyjeZ22"},"outputs":[],"source":["from ogb.graphproppred.mol_encoder import AtomEncoder\n","from torch_geometric.nn import global_add_pool, global_mean_pool\n","\n","### GCN to predict graph property\n","class GCN_Graph(torch.nn.Module):\n","    def __init__(self, hidden_dim, output_dim, num_layers, dropout):\n","        super(GCN_Graph, self).__init__()\n","\n","        # Load encoders for Atoms in molecule graphs\n","        self.node_encoder = AtomEncoder(hidden_dim)\n","\n","        # Node embedding model\n","        # Note that the input_dim and output_dim are set to hidden_dim\n","        self.gnn_node = GCN(hidden_dim, hidden_dim,\n","            hidden_dim, num_layers, dropout, return_embeds=True)\n","\n","        # Global mean pooling for graph-level representation\n","        self.pool = global_mean_pool\n","\n","        # Output layer\n","        self.linear = torch.nn.Linear(hidden_dim, output_dim)\n","\n","\n","    def reset_parameters(self):\n","      self.gnn_node.reset_parameters()\n","      self.linear.reset_parameters()\n","\n","    def forward(self, batched_data):\n","        # Input is a mini-batch of graphs (torch_geometric.data.Batch) and\n","        # output is the predicted graph property for each graph.\n","\n","        # Extract important attributes of our mini-batch\n","        x, edge_index, batch = batched_data.x, batched_data.edge_index, batched_data.batch\n","        embed = self.node_encoder(x)\n","\n","        # Generate node embeddings using GCN\n","        out = self.gnn_node(embed, edge_index)\n","\n","        # Aggregate node embeddings to graph-level representation\n","        out = self.pool(out, batch)\n","\n","        # Predict graph property using linear layer\n","        out = self.linear(out)\n","\n","        return out"]},{"cell_type":"markdown","source":["# Batch-wise GNN Training Function\n","\n","A training function designed for handling batched graph data with special considerations for:\n","\n","## Key Features\n","1. **Batch Processing**:\n","   - Iterates through data loader with progress bar\n","   - Handles device (CPU/GPU) transfer\n","   - Skips invalid batches (single node or empty graphs)\n","\n","2. **Label Handling**:\n","   - Manages unlabeled data points\n","   - Uses masking for labeled data only\n","   - Converts labels to appropriate type\n","\n","3. **Training Loop**:\n","   - Standard optimization cycle\n","   - Progress tracking via tqdm\n","   - Graceful handling of edge cases\n","\n","The function is particularly robust for real-world datasets where some graphs may be unlabeled or have special cases requiring different handling."],"metadata":{"id":"_ip41xWZWmhc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FJjnGuMSbjX0"},"outputs":[],"source":["def train(model, device, data_loader, optimizer, loss_fn):\n","    # Train your model by using the given optimizer and loss_fn.\n","    model.train()\n","    loss = 0\n","\n","    for step, batch in enumerate(tqdm(data_loader, desc=\"Iteration\")):\n","      batch = batch.to(device)\n","\n","      if batch.x.shape[0] == 1 or batch.batch[-1] == 0:\n","          pass\n","      else:\n","        ## ignore nan targets (unlabeled) when computing training loss.\n","        is_labeled = batch.y == batch.y\n","\n","        optimizer.zero_grad()  # Reset gradients\n","        out = model(batch)  # Forward pass\n","\n","        # Apply mask for labeled graphs and calculate loss\n","        loss = loss_fn(out[is_labeled], batch.y[is_labeled].type(torch.float32))\n","\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","    return loss.item()"]},{"cell_type":"markdown","source":["# GNN Evaluation Function for Graph-Level Prediction\n","\n","A comprehensive evaluation function for graph-level predictions that includes:\n","\n","## Key Components\n","1. **Prediction Collection**:\n","   - Batch-wise processing with progress tracking\n","   - Handles edge cases (single-node graphs)\n","   - Accumulates predictions and ground truth\n","\n","2. **Data Processing**:\n","   - Memory-efficient evaluation using torch.no_grad()\n","   - Concatenates results across batches\n","   - Converts tensors to numpy arrays\n","\n","3. **Results Management**:\n","   - Optional saving of predictions to CSV\n","   - Structured output format (y_pred | y_true)\n","   - Flexible file naming with save_file parameter\n","\n","The function is designed for evaluation scenarios where model predictions need to be both assessed and potentially stored for later analysis."],"metadata":{"id":"-M7Aep_NWtW5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ztPHXq_Gzn7U"},"outputs":[],"source":["# The evaluation function\n","def eval(model, device, loader, evaluator, save_model_results=False, save_file=None):\n","    model.eval()\n","    y_true = []\n","    y_pred = []\n","\n","    for step, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\n","        batch = batch.to(device)\n","\n","        if batch.x.shape[0] == 1:\n","            pass\n","        else:\n","            with torch.no_grad():\n","                pred = model(batch)\n","\n","            y_true.append(batch.y.view(pred.shape).detach().cpu())\n","            y_pred.append(pred.detach().cpu())\n","\n","    y_true = torch.cat(y_true, dim = 0).numpy()\n","    y_pred = torch.cat(y_pred, dim = 0).numpy()\n","\n","    input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n","\n","    if save_model_results:\n","        print (\"Saving Model Predictions\")\n","\n","        # Create a pandas dataframe with a two columns\n","        # y_pred | y_true\n","        data = {}\n","        data['y_pred'] = y_pred.reshape(-1)\n","        data['y_true'] = y_true.reshape(-1)\n","\n","        df = pd.DataFrame(data=data)\n","        # Save to csv\n","        df.to_csv('ogbg-molhiv_graph_' + save_file + '.csv', sep=',', index=False)\n","\n","    return evaluator.eval(input_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MR1wQ4hMZeMw"},"outputs":[],"source":["if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  model = GCN_Graph(args['hidden_dim'],\n","              dataset.num_tasks, args['num_layers'],\n","              args['dropout']).to(device)\n","  evaluator = Evaluator(name='ogbg-molhiv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qJGTNZiuZy0A"},"outputs":[],"source":["# Please do not change these args\n","# Training should take <10min using GPU runtime\n","import copy\n","\n","if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  model.reset_parameters()\n","\n","  optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n","  loss_fn = torch.nn.BCEWithLogitsLoss()\n","\n","  best_model = None\n","  best_valid_acc = 0\n","\n","  for epoch in range(1, 1 + args[\"epochs\"]):\n","    print('Training...')\n","    loss = train(model, device, train_loader, optimizer, loss_fn)\n","\n","    print('Evaluating...')\n","    train_result = eval(model, device, train_loader, evaluator)\n","    val_result = eval(model, device, valid_loader, evaluator)\n","    test_result = eval(model, device, test_loader, evaluator)\n","\n","    train_acc, valid_acc, test_acc = train_result[dataset.eval_metric], val_result[dataset.eval_metric], test_result[dataset.eval_metric]\n","    if valid_acc > best_valid_acc:\n","        best_valid_acc = valid_acc\n","        best_model = copy.deepcopy(model)\n","    print(f'Epoch: {epoch:02d}, '\n","          f'Loss: {loss:.4f}, '\n","          f'Train: {100 * train_acc:.2f}%, '\n","          f'Valid: {100 * valid_acc:.2f}% '\n","          f'Test: {100 * test_acc:.2f}%')"]},{"cell_type":"markdown","metadata":{"id":"6I17-Qso_n88"},"source":["## Question 6: What are your `best_model` validation and test ROC-AUC scores? (20 points)\n","\n","Run the cell below to see the results of your best of model and save your model's predictions in files named *ogbg-molhiv_graph_[valid,test].csv*. Again, you can view the files by clicking on the *Folder* icon on the left side pannel. Report the results on Gradescope."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oq5QaG21dOOO"},"outputs":[],"source":["if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  train_auroc = eval(best_model, device, train_loader, evaluator)[dataset.eval_metric]\n","  valid_auroc = eval(best_model, device, valid_loader, evaluator, save_model_results=True, save_file=\"valid\")[dataset.eval_metric]\n","  test_auroc  = eval(best_model, device, test_loader, evaluator, save_model_results=True, save_file=\"test\")[dataset.eval_metric]\n","\n","  print(f'Best model: '\n","      f'Train: {100 * train_auroc:.2f}%, '\n","      f'Valid: {100 * valid_auroc:.2f}% '\n","      f'Test: {100 * test_auroc:.2f}%')"]},{"cell_type":"markdown","metadata":{"id":"gBi_t8n0iZ4P"},"source":["## Question 7 (Optional): Experiment with the two other global pooling layers in Pytorch Geometric."]},{"cell_type":"markdown","metadata":{"id":"e7JXsMTBgeOI"},"source":["# Submission\n","\n","To submit Colab 2, please submit to the following assignments on Gradescope:\n","\n","1. \"Colab 2\": submit your answers to the questions in this assignment\n","2. \"Colab 2 Code\": submit your completed *CS224W_Colab_2.ipynb*. From the \"File\" menu select \"Download .ipynb\" to save a local copy of your completed Colab. **PLEASE DO NOT CHANGE THE NAME!** The autograder depends on the .ipynb file being called \"CS224W_Colab_2.ipynb\".\n","\n","Clarrification:\n","- In \"Colab 2 Code\", we grade Q1-Q4 (non-training questions) using autograder.\n","- In \"Colab 2\", we grade Q5-Q6 (training questions), where Q1-Q4 are assigned 0 points."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L3Q5WmndEnAJ"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[{"file_id":"12XGa_nL1v7KUVi2_jsh1FNM1VDg6eo_X","timestamp":1732668650139},{"file_id":"1kH1r6VKWke-Au9c0YPaifDfzlnVW0plW","timestamp":1633632196796},{"file_id":"1NDdKr2sIKct1Rd4Mgb_Pd8ICpMIL3efd","timestamp":1633631941945},{"file_id":"1Jc5CAEGZIvY0vka3mBdf0tqn2TaJr2O1","timestamp":1610408674518},{"file_id":"1gc6u6hItUKY9uJt6GXHaneSYCMaGcxp1","timestamp":1610395347938},{"file_id":"1CqWY4pk7_VFxi8K8v4asr18ed0Hs8FVA","timestamp":1578441204356}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}