{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6d35d75-0a83-48a3-97b3-07411515442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from e3nn.o3 import spherical_harmonics\n",
    "from e3nn.o3 import wigner_3j\n",
    "from torch import Tensor\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d5682ec-579f-4e4f-a03e-d059270c5083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 100, 13])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = torch.randn((10, 100, 3))\n",
    "r_ang = r/torch.linalg.vector_norm(r, dim = -1).unsqueeze(-1)\n",
    "\n",
    "\n",
    "Y_1 = spherical_harmonics('1e', r_ang, normalize = 'component')\n",
    "Y_2 = spherical_harmonics('2e', r_ang, normalize = 'component')\n",
    "Y_3 = spherical_harmonics('2e', r_ang, normalize = 'component')\n",
    "\n",
    "features = torch.concatenate([Y_1, Y_2, Y_3], dim = -1)\n",
    "\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84e0fda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 100, 3]), torch.Size([10, 100, 5]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_1.shape, Y_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84984a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 100, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1a4fccd-d3e3-4fda-bffc-b5c1bc82b095",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1, l2, l3 = 1, 2, 3\n",
    "m1, m2, m3 = l1, l2, l3 # m1 = 0, m2 = 0, m3 = 0\n",
    "C123 = wigner_3j(1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5cc496a-9b93-4e74-85ba-ca1642e5d80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2928)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C123_000 = C123[m1, m2, m3]\n",
    "\n",
    "C123_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4598f711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C123.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "096e842c-9505-4fb0-a35e-5b989f732638",
   "metadata": {},
   "outputs": [],
   "source": [
    "class weigner_3j_img_to_real():\n",
    "\n",
    "\n",
    "    def __init__(self, l):\n",
    "        self.l = l\n",
    "\n",
    "    def __call__(self):\n",
    "        matrix = torch.zeros((2*self.l + 1, 2*self.l + 1), dtype = torch.complex64)\n",
    "\n",
    "        mult = 1\n",
    "        for i in range(2*self.l + 1):\n",
    "            \n",
    "            if i < self.l:\n",
    "                matrix[i, i] = 1.0j/2**(1/2.)\n",
    "                matrix[2*self.l + 1 - i - 1, i] = 1/2**(1/2.)\n",
    "            elif i == self.l:\n",
    "                matrix[i, i] = 1.\n",
    "            else:\n",
    "                matrix[i, i] = (-1.0)*mult/2**(1/2.)\n",
    "                matrix[2*self.l + 1 - i - 1, i] = (-1.0j)*mult/2**(1/2.)\n",
    "                mult *= -1\n",
    "        \n",
    "        return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5841bc65-2103-46f7-8b22-bac392e8a753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000+1.0000j,  0.0000+0.0000j,  0.0000-1.0000j],\n",
       "        [ 0.0000+0.0000j,  1.4142+0.0000j,  0.0000+0.0000j],\n",
       "        [ 1.0000+0.0000j,  0.0000+0.0000j, -1.0000+0.0000j]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weigner_3j_img_to_real(1)()*2**(1/2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65b1c83c-fac0-47f7-8237-623ed87fd857",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def tri_ineq(l1, l2, l3):\n",
    "    print(max([l1, l2, l3]), min([l1 + l2, l2 + l3, l1 + l3]))\n",
    "    return max([l1, l2, l3]) <= min([l1 + l2, l2 + l3, l1 + l3])\n",
    "\n",
    "class order_3_equvariant_tensor():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\" Basically transformation using\n",
    "            C (l1 l2 l3)\n",
    "              (m1 m2 m3)\"\"\"\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def __call__(self, l1, l2, l3, n1, n2, n3):\n",
    "        self.l1 = l1; self.l2 = l2; self.l3 = l3\n",
    "        self.n1 = n1; self.n2 = n2; self.n3 = n3\n",
    "        \n",
    "        weight = torch.zeros([n1, n2, n3])\n",
    "        if tri_ineq(l1, l2, l3):\n",
    "            W = nn.Parameter(nn.init.kaiming_uniform_(weight))\n",
    "            symbol_3j = wigner_3j(1, 2, 3)\n",
    "            return symbol_3j.view(*symbol_3j.shape, 1, 1, 1)*W.view(1, 1, 1, *weight.shape)\n",
    "        else:\n",
    "            return torch.zeros((2*l1 + 1, 2*l2 + 1, 2*l3 + 1, n1, n2, n3))\n",
    "        \n",
    "        \n",
    "class order_2_equivariant_tensor():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Makes the 2nd order tensor in a way that\n",
    "           each lm is multiplied by coefficient c, no angular momentum mixing\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, l1, l2, n1, n2):\n",
    "        self.l1 = l1; self.l2 = l2\n",
    "        self.n1 = n1; self.n2 = n2\n",
    "        \n",
    "        weight = torch.zeros([n1, n2])\n",
    "        if l1 == l2: # same as tri_ineq(l1, l2, 0)\n",
    "            W = nn.Parameter(nn.init.kaiming_uniform_(weight))\n",
    "            return torch.ones((2*l1 + 1, 2*l2 + 1, 1, 1))*W.view(1, 1, *weight.shape)\n",
    "        else:\n",
    "            return torch.zeros((2*l1 + 1, 2*l2 + 1, n1, n2))\n",
    "\n",
    "        \n",
    "class order_2_equivariant_tensor():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Makes the 2nd order tensor in a way that\n",
    "           each lm is multiplied by coefficient c, no angular momentum mixing\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, l1, l2, n1, n2):\n",
    "        self.l1 = l1; self.l2 = l2\n",
    "        self.n1 = n1; self.n2 = n2\n",
    "        \n",
    "        weight = torch.zeros([n1, n2])\n",
    "        if l1 == l2: # same as tri_ineq(l1, l2, 0)\n",
    "            W = nn.Parameter(nn.init.kaiming_uniform_(weight))\n",
    "            return torch.ones((2*l1 + 1, 2*l2 + 1, 1, 1))*W.view(1, 1, *weight.shape)\n",
    "        else:\n",
    "            return torch.zeros((2*l1 + 1, 2*l2 + 1, n1, n2))\n",
    "\n",
    "        \n",
    "class order_1_equivariant_tensor():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Makes the 1nd order tensor in a way that\n",
    "           each lm is multiplied by coefficient c, no angular momentum mixing\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, l1, n1):\n",
    "        self.l1 = l1;\n",
    "        self.n1 = n1;\n",
    "        \n",
    "        weight = torch.zeros([n1])\n",
    "        W = nn.Parameter(nn.init.uniform(weight))\n",
    "        return torch.ones((2*l1 + 1, 1))*W.view(1, *weight.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b288318e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 10])\n",
      "torch.Size([5, 5, 3, 4])\n",
      "torch.Size([5, 5, 3, 4])\n",
      "3 3\n",
      "tensor(7.1833, grad_fn=<SumBackward0>)\n",
      "3 3\n",
      "torch.Size([3, 5, 7, 4, 6, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p2/mwhbpbfx4dx636dcf50t7_rr0000gn/T/ipykernel_68620/1727926539.py:81: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  W = nn.Parameter(nn.init.uniform(weight))\n"
     ]
    }
   ],
   "source": [
    "print(order_1_equivariant_tensor()(2, 3).shape)\n",
    "print(order_1_equivariant_tensor()(2, 10).shape)\n",
    "\n",
    "print(order_2_equivariant_tensor()(2, 2, 3, 4).shape)\n",
    "print(order_2_equivariant_tensor()(2, 2, 3, 4).shape)\n",
    "\n",
    "\n",
    "print(order_3_equvariant_tensor()(1, 2, 3, 4, 6, 8).sum())\n",
    "print(order_3_equvariant_tensor()(1, 2, 3, 4, 6, 8).shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccb3a36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_ineq(0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8346b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 7])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C123.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7823e23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 100, 100, 7])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('iav,ibt,vtr->iabr', Y_1, Y_2, C123).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdb0d2d",
   "metadata": {},
   "source": [
    "### Loading qm9 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50ba7642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference example\n",
    "from nequip.data import dataset_from_config\n",
    "from nequip.utils import Config\n",
    "#from nequip.utils.misc import get_default_device_name\n",
    "#from nequip.utils.config import _GLOBAL_ALL_ASKED_FOR_KEYS\n",
    "\n",
    "from nequip.model import model_from_config\n",
    "\n",
    "\n",
    "default_config = dict(\n",
    "    root=\"./\",\n",
    "    tensorboard=False,\n",
    "    wandb=False,\n",
    "    model_builders=[\n",
    "        \"SimpleIrrepsConfig\",\n",
    "        \"EnergyModel\",\n",
    "        \"PerSpeciesRescale\",\n",
    "        \"StressForceOutput\",\n",
    "        \"RescaleEnergyEtc\",\n",
    "    ],\n",
    "    dataset_statistics_stride=1,\n",
    "    device='cuda',\n",
    "    default_dtype=\"float64\",\n",
    "    model_dtype=\"float32\",\n",
    "    allow_tf32=True,\n",
    "    verbose=\"INFO\",\n",
    "    model_debug_mode=False,\n",
    "    equivariance_test=False,\n",
    "    grad_anomaly_mode=False,\n",
    "    gpu_oom_offload=False,\n",
    "    append=False,\n",
    "    warn_unused=False,\n",
    "    _jit_bailout_depth=2,  # avoid 20 iters of pain, see https://github.com/pytorch/pytorch/issues/52286\n",
    "    # Quote from eelison in PyTorch slack:\n",
    "    # https://pytorch.slack.com/archives/CDZD1FANA/p1644259272007529?thread_ts=1644064449.039479&cid=CDZD1FANA\n",
    "    # > Right now the default behavior is to specialize twice on static shapes and then on dynamic shapes.\n",
    "    # > To reduce warmup time you can do something like setFusionStrartegy({{FusionBehavior::DYNAMIC, 3}})\n",
    "    # > ... Although we would wouldn't really expect to recompile a dynamic shape fusion in a model,\n",
    "    # > provided broadcasting patterns remain fixed\n",
    "    # We default to DYNAMIC alone because the number of edges is always dynamic,\n",
    "    # even if the number of atoms is fixed:\n",
    "    _jit_fusion_strategy=[(\"DYNAMIC\", 3)],\n",
    "    # Due to what appear to be ongoing bugs with nvFuser, we default to NNC (fuser1) for now:\n",
    "    # TODO: still default to NNC on CPU regardless even if change this for GPU\n",
    "    # TODO: default for ROCm?\n",
    "    _jit_fuser=\"fuser1\",\n",
    ")\n",
    "\n",
    "# All default_config keys are valid / requested\n",
    "#_GLOBAL_ALL_ASKED_FOR_KEYS.update(default_config.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d99679c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AtomicData(atom_types=[19, 1], cell=[3, 3], edge_cell_shift=[340, 3], edge_index=[2, 340], pbc=[3], pos=[19, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config.from_file('./configs/example_SpinGNNPlus.yaml', defaults=default_config)\n",
    "    \n",
    "\n",
    "dataset = dataset_from_config(config, prefix=\"dataset\")\n",
    "\n",
    "validation_dataset = None\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3dc2da30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_jit_bailout_depth': 2, '_jit_fusion_strategy': [('DYNAMIC', 3)], '_jit_fuser': 'fuser1', 'root': 'results/qm9', 'tensorboard': False, 'wandb': False, 'model_builders': ['allegro.model.SpinGNNPlus', 'PerSpeciesRescale', 'ParaStressForceSpinForceOutput', 'RescaleEnergyEtc'], 'dataset_statistics_stride': 1, 'device': 'cuda', 'default_dtype': 'float32', 'model_dtype': 'float32', 'allow_tf32': True, 'verbose': 'debug', 'model_debug_mode': False, 'equivariance_test': False, 'grad_anomaly_mode': False, 'gpu_oom_offload': False, 'append': True, 'warn_unused': False, 'run_name': 'example', 'seed': 123456, 'dataset_seed': 123456, 'r_max': 6.0, 'avg_num_neighbors': 'auto', 'BesselBasis_trainable': True, 'PolynomialCutoff_p': 6, 'l_max': 2, 'parity': 'o3_full', 'num_layers': 2, 'env_embed_multiplicity': 64, 'embed_initial_edge': True, 'two_body_latent_mlp_latent_dimensions': [128, 256, 512, 1024], 'two_body_latent_mlp_nonlinearity': 'silu', 'two_body_latent_mlp_initialization': 'uniform', 'latent_mlp_latent_dimensions': [1024, 1024, 1024], 'latent_mlp_nonlinearity': 'silu', 'latent_mlp_initialization': 'uniform', 'latent_resnet': True, 'env_embed_mlp_latent_dimensions': [], 'env_embed_mlp_nonlinearity': None, 'env_embed_mlp_initialization': 'uniform', 'edge_eng_mlp_latent_dimensions': [128], 'edge_eng_mlp_nonlinearity': None, 'edge_eng_mlp_initialization': 'uniform', 'dataset': 'ase', 'dataset_file_name': './data/qm9.xyz', 'ase_args': {'format': 'extxyz'}, 'chemical_symbols': ['H', 'He', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F'], 'wandb_project': 'aspirin', 'n_train': 950, 'n_val': 50, 'batch_size': 5, 'max_epochs': 1000000, 'learning_rate': 0.001, 'train_val_split': 'random', 'shuffle': True, 'metrics_key': 'validation_loss', 'use_ema': True, 'ema_decay': 0.99, 'ema_use_num_updates': True, 'loss_coeffs': {'forces': 1.0, 'total_energy': [1.0, 'PerAtomMSELoss']}, 'optimizer_name': 'Adam', 'optimizer_params': {'amsgrad': False, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0}, 'lr_scheduler_name': 'ReduceLROnPlateau', 'lr_scheduler_patience': 50, 'lr_scheduler_factor': 0.5, 'early_stopping_upper_bounds': {'cumulative_wall': 604800.0}, 'early_stopping_lower_bounds': {'LR': 1e-05}, 'early_stopping_patiences': {'validation_loss': 100}, 'dataset_AtomicData_options': {'r_max': 6.0}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2e10fbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "from nequip.data import AtomicData, AtomicDataDict\n",
    "from torch.nn.functional import one_hot\n",
    "from e3nn.nn import FullyConnectedNet\n",
    "from allegro import with_edge_spin_length\n",
    "from allegro import _keys\n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "data = [AtomicData.to_AtomicDataDict(dataset[i]) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c2ec18ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bf29945a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([494, 1])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 2\n",
    "\n",
    "num_types = len(config['chemical_symbols'])\n",
    "\n",
    "\n",
    "atom_types_embed = data[i]['atom_types'][data[i]['edge_index'][0]]*num_types + data[i]['atom_types'][data[i]['edge_index'][1]]\n",
    "\n",
    "atom_types_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9591ea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nequip.data import AtomicDataDict, AtomicDataset\n",
    "from nequip.nn.embedding import (\n",
    "    OneHotAtomEncoding,\n",
    "    SphericalHarmonicEdgeAttrs,\n",
    "    RadialBasisEdgeEncoding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b5935fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from e3nn import o3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b6c2c373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1x0ee+1x1oe+1x2ee"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o3.Irreps.spherical_harmonics(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3cad5833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([494, 8]) torch.Size([494, 9])\n"
     ]
    }
   ],
   "source": [
    "from nequip.data import AtomicDataDict, AtomicDataset\n",
    "from nequip.nn.embedding import (\n",
    "    OneHotAtomEncoding,\n",
    "    SphericalHarmonicEdgeAttrs,\n",
    "    RadialBasisEdgeEncoding,\n",
    ")\n",
    "from e3nn import o3\n",
    "\n",
    "L = 2\n",
    "\n",
    "irreps_edge_sh = o3.Irreps.spherical_harmonics(L)\n",
    "\n",
    "rbe = RadialBasisEdgeEncoding(basis_kwargs={'r_max': config['r_max'], \n",
    "                                            'num_basis': 8},\n",
    "                              cutoff_kwargs={'r_max': config['r_max']},\n",
    "                              out_field=AtomicDataDict.EDGE_EMBEDDING_KEY,\n",
    "                              )\n",
    "\n",
    "sh = SphericalHarmonicEdgeAttrs(irreps_edge_sh=irreps_edge_sh)\n",
    "\n",
    "data = [rbe(data[i]) for i in range(len(data))]\n",
    "\n",
    "data = [sh(data[i]) for i in range(len(data))]\n",
    "\n",
    "\n",
    "print(data[i]['edge_embedding'].shape, data[i]['edge_attrs'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "910c7aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 494]) torch.Size([494, 3, 4]) torch.Size([494, 9, 4])\n",
      "torch.Size([23, 9, 4])\n"
     ]
    }
   ],
   "source": [
    "from torch_runstats.scatter import scatter\n",
    "\n",
    "N_rad = 8\n",
    "\n",
    "N_spec_rank = 4\n",
    "N_rad_rank = 4\n",
    "\n",
    "Q = data[i]['edge_embedding']\n",
    "\n",
    "A = torch.randn(L + 1, N_spec_rank, num_types**2)\n",
    "B = torch.randn(L + 1, N_rad_rank, N_rad, N_spec_rank)\n",
    "\n",
    "\n",
    "a = A[:, :, atom_types_embed].squeeze(-1)\n",
    "\n",
    "b = torch.einsum('Lrnk,LkE,En->ELr', B, a, Q)\n",
    "\n",
    "Y = data[i]['edge_attrs']\n",
    "\n",
    "#print(data[i]['edge_attrs'][:, slices])\n",
    "F = torch.concat([torch.einsum('Em,En->Emn', Y[:, slices],\n",
    "                               b[:, l]) for l, slices in enumerate(irreps_edge_sh.slices())], dim = -2)\n",
    "\n",
    "print(a.shape, b.shape, F.shape)\n",
    "\n",
    "\n",
    "species = data[i][AtomicDataDict.ATOM_TYPE_KEY].squeeze(-1)\n",
    "edge_center = data[i][AtomicDataDict.EDGE_INDEX_KEY][0]\n",
    "edge_neighbor = data[i][AtomicDataDict.EDGE_INDEX_KEY][1]\n",
    "\n",
    "center_species = species[edge_center]\n",
    "neighbor_species = species[edge_neighbor]\n",
    "\n",
    "F = scatter(F, edge_center, dim=0, dim_size=len(species))\n",
    "\n",
    "print(F.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cea8590",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_mkl",
   "language": "python",
   "name": "torch_mkl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
