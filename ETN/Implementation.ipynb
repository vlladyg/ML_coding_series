{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a6d35d75-0a83-48a3-97b3-07411515442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from e3nn.o3 import spherical_harmonics\n",
    "from e3nn.o3 import wigner_3j\n",
    "from torch import Tensor\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3d5682ec-579f-4e4f-a03e-d059270c5083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 100, 9])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = torch.randn((10, 100, 3))\n",
    "r_ang = r/torch.linalg.vector_norm(r, dim = -1).unsqueeze(-1)\n",
    "\n",
    "\n",
    "Y_1 = spherical_harmonics('0e', r_ang, normalize = 'component')\n",
    "Y_2 = spherical_harmonics('1o', r_ang, normalize = 'component')\n",
    "Y_3 = spherical_harmonics('2e', r_ang, normalize = 'component')\n",
    "\n",
    "features = torch.concatenate([Y_1, Y_2, Y_3], dim = -1)\n",
    "\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "84e0fda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 100, 1]), torch.Size([10, 100, 3]))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_1.shape, Y_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "84984a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 100, 3])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e1a4fccd-d3e3-4fda-bffc-b5c1bc82b095",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1, l2, l3 = 1, 2, 3\n",
    "m1, m2, m3 = l1, l2, l3 # m1 = 0, m2 = 0, m3 = 0\n",
    "C123 = wigner_3j(1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c5cc496a-9b93-4e74-85ba-ca1642e5d80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2928)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C123_000 = C123[m1, m2, m3]\n",
    "\n",
    "C123_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4598f711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 7])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C123.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "096e842c-9505-4fb0-a35e-5b989f732638",
   "metadata": {},
   "outputs": [],
   "source": [
    "class weigner_3j_img_to_real():\n",
    "\n",
    "\n",
    "    def __init__(self, l):\n",
    "        self.l = l\n",
    "\n",
    "    def __call__(self):\n",
    "        matrix = torch.zeros((2*self.l + 1, 2*self.l + 1), dtype = torch.complex64)\n",
    "\n",
    "        mult = 1\n",
    "        for i in range(2*self.l + 1):\n",
    "            \n",
    "            if i < self.l:\n",
    "                matrix[i, i] = 1.0j/2**(1/2.)\n",
    "                matrix[2*self.l + 1 - i - 1, i] = 1/2**(1/2.)\n",
    "            elif i == self.l:\n",
    "                matrix[i, i] = 1.\n",
    "            else:\n",
    "                matrix[i, i] = (-1.0)*mult/2**(1/2.)\n",
    "                matrix[2*self.l + 1 - i - 1, i] = (-1.0j)*mult/2**(1/2.)\n",
    "                mult *= -1\n",
    "        \n",
    "        return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5841bc65-2103-46f7-8b22-bac392e8a753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000+1.0000j,  0.0000+0.0000j,  0.0000-1.0000j],\n",
       "        [ 0.0000+0.0000j,  1.4142+0.0000j,  0.0000+0.0000j],\n",
       "        [ 1.0000+0.0000j,  0.0000+0.0000j, -1.0000+0.0000j]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weigner_3j_img_to_real(1)()*2**(1/2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "65b1c83c-fac0-47f7-8237-623ed87fd857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tri_ineq(l1, l2, l3):\n",
    "    #print(max([l1, l2, l3]), min([l1 + l2, l2 + l3, l1 + l3]))\n",
    "    return max([l1, l2, l3]) <= min([l1 + l2, l2 + l3, l1 + l3])\n",
    "\n",
    "class order_3_equvariant_tensor():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\" Basically transformation using\n",
    "            C (l1 l2 l3)\n",
    "              (m1 m2 m3)\"\"\"\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def __call__(self, l1, l2, l3, n1, n2, n3):\n",
    "        self.l1 = l1; self.l2 = l2; self.l3 = l3\n",
    "        self.n1 = n1; self.n2 = n2; self.n3 = n3\n",
    "        \n",
    "        weight = torch.zeros([n1, n2, n3])\n",
    "        if tri_ineq(l1, l2, l3):\n",
    "            W = nn.Parameter(nn.init.kaiming_uniform_(weight))\n",
    "            symbol_3j = wigner_3j(l1, l2, l3)\n",
    "            return symbol_3j.view(*symbol_3j.shape, 1, 1, 1)*W.view(1, 1, 1, *weight.shape)\n",
    "        else:\n",
    "            return torch.zeros((2*l1 + 1, 2*l2 + 1, 2*l3 + 1, n1, n2, n3))\n",
    "        \n",
    "        \n",
    "class order_2_equivariant_tensor():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Makes the 2nd order tensor in a way that\n",
    "           each lm is multiplied by coefficient c, no angular momentum mixing\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, l1, l2, n1, n2):\n",
    "        self.l1 = l1; self.l2 = l2\n",
    "        self.n1 = n1; self.n2 = n2\n",
    "        \n",
    "        weight = torch.zeros([n1, n2])\n",
    "        if l1 == l2: # same as tri_ineq(l1, l2, 0)\n",
    "            W = nn.Parameter(nn.init.kaiming_uniform_(weight))\n",
    "            return W.view(*weight.shape)\n",
    "        else:\n",
    "            return torch.zeros((n1, n2))\n",
    "\n",
    "        \n",
    "class order_1_equivariant_tensor():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Makes the 1nd order tensor in a way that\n",
    "           each lm is multiplied by coefficient c, no angular momentum mixing\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, l1, n1):\n",
    "        self.l1 = l1;\n",
    "        self.n1 = n1;\n",
    "        \n",
    "        weight = torch.zeros([n1])\n",
    "        W = nn.Parameter(nn.init.uniform(weight))\n",
    "        return torch.ones((2*l1 + 1, 1))*W.view(1, *weight.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b288318e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 10])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([3, 4])\n",
      "tensor(2.2930, grad_fn=<SumBackward0>)\n",
      "torch.Size([3, 5, 7, 4, 6, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p2/mwhbpbfx4dx636dcf50t7_rr0000gn/T/ipykernel_1020/2437360665.py:61: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  W = nn.Parameter(nn.init.uniform(weight))\n"
     ]
    }
   ],
   "source": [
    "print(order_1_equivariant_tensor()(2, 3).shape)\n",
    "print(order_1_equivariant_tensor()(2, 10).shape)\n",
    "\n",
    "print(order_2_equivariant_tensor()(2, 2, 3, 4).shape)\n",
    "print(order_2_equivariant_tensor()(2, 2, 3, 4).shape)\n",
    "\n",
    "\n",
    "print(order_3_equvariant_tensor()(1, 2, 3, 4, 6, 8).sum())\n",
    "print(order_3_equvariant_tensor()(1, 2, 3, 4, 6, 8).shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6d574314",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmax = 3\n",
    "w3j_big = [[[wigner_3j(i, j, k) if tri_ineq(i, j, k) else None for i in range (lmax)] for j in range(lmax)] for k in range(lmax)]\n",
    "\n",
    "\n",
    "#len(w3j_big)/lmax**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ff3d5d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[tensor([[[1.]]]), None, None],\n",
       "  [None, tensor([[[0.5774],\n",
       "            [0.0000],\n",
       "            [0.0000]],\n",
       "   \n",
       "           [[0.0000],\n",
       "            [0.5774],\n",
       "            [0.0000]],\n",
       "   \n",
       "           [[0.0000],\n",
       "            [0.0000],\n",
       "            [0.5774]]]), None],\n",
       "  [None,\n",
       "   None,\n",
       "   tensor([[[0.4472],\n",
       "            [0.0000],\n",
       "            [0.0000],\n",
       "            [0.0000],\n",
       "            [0.0000]],\n",
       "   \n",
       "           [[0.0000],\n",
       "            [0.4472],\n",
       "            [0.0000],\n",
       "            [0.0000],\n",
       "            [0.0000]],\n",
       "   \n",
       "           [[0.0000],\n",
       "            [0.0000],\n",
       "            [0.4472],\n",
       "            [0.0000],\n",
       "            [0.0000]],\n",
       "   \n",
       "           [[0.0000],\n",
       "            [0.0000],\n",
       "            [0.0000],\n",
       "            [0.4472],\n",
       "            [0.0000]],\n",
       "   \n",
       "           [[0.0000],\n",
       "            [0.0000],\n",
       "            [0.0000],\n",
       "            [0.0000],\n",
       "            [0.4472]]])]],\n",
       " [[None,\n",
       "   tensor([[[0.5774, 0.0000, 0.0000]],\n",
       "   \n",
       "           [[0.0000, 0.5774, 0.0000]],\n",
       "   \n",
       "           [[0.0000, 0.0000, 0.5774]]]),\n",
       "   None],\n",
       "  [tensor([[[0.5774, 0.0000, 0.0000],\n",
       "            [0.0000, 0.5774, 0.0000],\n",
       "            [0.0000, 0.0000, 0.5774]]]),\n",
       "   tensor([[[ 0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.4082],\n",
       "            [ 0.0000, -0.4082,  0.0000]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000, -0.4082],\n",
       "            [ 0.0000,  0.0000,  0.0000],\n",
       "            [ 0.4082,  0.0000,  0.0000]],\n",
       "   \n",
       "           [[ 0.0000,  0.4082,  0.0000],\n",
       "            [-0.4082,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000]]]),\n",
       "   tensor([[[ 0.0000,  0.0000,  0.3162],\n",
       "            [ 0.0000,  0.0000,  0.0000],\n",
       "            [ 0.3162,  0.0000,  0.0000]],\n",
       "   \n",
       "           [[ 0.0000,  0.3162,  0.0000],\n",
       "            [ 0.3162,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000]],\n",
       "   \n",
       "           [[-0.1826,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.3651,  0.0000],\n",
       "            [ 0.0000,  0.0000, -0.1826]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.3162],\n",
       "            [ 0.0000,  0.3162,  0.0000]],\n",
       "   \n",
       "           [[-0.3162,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.3162]]])],\n",
       "  [None,\n",
       "   tensor([[[ 0.0000,  0.0000,  0.3162],\n",
       "            [ 0.0000,  0.3162,  0.0000],\n",
       "            [-0.1826,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000],\n",
       "            [-0.3162,  0.0000,  0.0000]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.0000],\n",
       "            [ 0.3162,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.3651,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.3162],\n",
       "            [ 0.0000,  0.0000,  0.0000]],\n",
       "   \n",
       "           [[ 0.3162,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000, -0.1826],\n",
       "            [ 0.0000,  0.3162,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.3162]]]),\n",
       "   tensor([[[ 0.0000,  0.0000,  0.0000],\n",
       "            [-0.1826,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.1826],\n",
       "            [ 0.0000, -0.3651,  0.0000]],\n",
       "   \n",
       "           [[ 0.1826,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.3162],\n",
       "            [ 0.0000, -0.1826,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.1826]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000, -0.3162],\n",
       "            [ 0.0000,  0.0000,  0.0000],\n",
       "            [ 0.3162,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000, -0.1826],\n",
       "            [ 0.0000,  0.1826,  0.0000],\n",
       "            [-0.3162,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000],\n",
       "            [ 0.1826,  0.0000,  0.0000]],\n",
       "   \n",
       "           [[ 0.0000,  0.3651,  0.0000],\n",
       "            [ 0.0000,  0.0000, -0.1826],\n",
       "            [ 0.0000,  0.0000,  0.0000],\n",
       "            [-0.1826,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000]]])]],\n",
       " [[None,\n",
       "   None,\n",
       "   tensor([[[0.4472, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "   \n",
       "           [[0.0000, 0.4472, 0.0000, 0.0000, 0.0000]],\n",
       "   \n",
       "           [[0.0000, 0.0000, 0.4472, 0.0000, 0.0000]],\n",
       "   \n",
       "           [[0.0000, 0.0000, 0.0000, 0.4472, 0.0000]],\n",
       "   \n",
       "           [[0.0000, 0.0000, 0.0000, 0.0000, 0.4472]]])],\n",
       "  [None,\n",
       "   tensor([[[ 0.0000,  0.0000, -0.1826,  0.0000, -0.3162],\n",
       "            [ 0.0000,  0.3162,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.3162,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "   \n",
       "           [[ 0.0000,  0.3162,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.3651,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.3162,  0.0000]],\n",
       "   \n",
       "           [[ 0.3162,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.3162,  0.0000],\n",
       "            [ 0.0000,  0.0000, -0.1826,  0.0000,  0.3162]]]),\n",
       "   tensor([[[ 0.0000,  0.1826,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.3651],\n",
       "            [ 0.0000,  0.0000,  0.0000, -0.1826,  0.0000]],\n",
       "   \n",
       "           [[-0.1826,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.1826,  0.0000],\n",
       "            [ 0.0000,  0.0000, -0.3162,  0.0000, -0.1826]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.0000, -0.3162,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.3162,  0.0000,  0.0000,  0.0000]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.3162,  0.0000, -0.1826],\n",
       "            [ 0.0000, -0.1826,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.1826,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.1826,  0.0000],\n",
       "            [-0.3651,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.1826,  0.0000,  0.0000,  0.0000]]])],\n",
       "  [tensor([[[0.4472, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.4472, 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.4472, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000, 0.4472, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000, 0.0000, 0.4472]]]),\n",
       "   tensor([[[ 0.0000, -0.1826,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.1826,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.3162,  0.0000],\n",
       "            [ 0.0000,  0.0000, -0.3162,  0.0000,  0.1826],\n",
       "            [ 0.0000,  0.0000,  0.0000, -0.1826,  0.0000]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.0000, -0.3651],\n",
       "            [ 0.0000,  0.0000,  0.0000, -0.1826,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.1826,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.3651,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.1826,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.3162,  0.0000,  0.1826],\n",
       "            [ 0.0000, -0.3162,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.1826,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000, -0.1826,  0.0000,  0.0000,  0.0000]]]),\n",
       "   tensor([[[ 0.0000,  0.0000, -0.2390,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.2070,  0.0000],\n",
       "            [-0.2390,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.2070,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.2070,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.1195,  0.0000, -0.2070],\n",
       "            [ 0.0000,  0.1195,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.2070,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000, -0.2070,  0.0000,  0.0000,  0.0000]],\n",
       "   \n",
       "           [[-0.2390,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.1195,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.2390,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.1195,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000, -0.2390]],\n",
       "   \n",
       "           [[ 0.0000,  0.2070,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.2070,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.1195,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.1195,  0.0000,  0.2070],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.2070,  0.0000]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000, -0.2070,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000, -0.2390],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.2070,  0.0000],\n",
       "            [ 0.0000,  0.0000, -0.2390,  0.0000,  0.0000]]])]]]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3j_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "223decbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250047"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9261*27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccb3a36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_ineq(0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8346b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 7])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C123.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdb0d2d",
   "metadata": {},
   "source": [
    "### Loading qm9 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50ba7642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference example\n",
    "from nequip.data import dataset_from_config\n",
    "from nequip.utils import Config\n",
    "#from nequip.utils.misc import get_default_device_name\n",
    "#from nequip.utils.config import _GLOBAL_ALL_ASKED_FOR_KEYS\n",
    "\n",
    "from nequip.model import model_from_config\n",
    "\n",
    "\n",
    "default_config = dict(\n",
    "    root=\"./\",\n",
    "    tensorboard=False,\n",
    "    wandb=False,\n",
    "    model_builders=[\n",
    "        \"SimpleIrrepsConfig\",\n",
    "        \"EnergyModel\",\n",
    "        \"PerSpeciesRescale\",\n",
    "        \"StressForceOutput\",\n",
    "        \"RescaleEnergyEtc\",\n",
    "    ],\n",
    "    dataset_statistics_stride=1,\n",
    "    device='cuda',\n",
    "    default_dtype=\"float64\",\n",
    "    model_dtype=\"float32\",\n",
    "    allow_tf32=True,\n",
    "    verbose=\"INFO\",\n",
    "    model_debug_mode=False,\n",
    "    equivariance_test=False,\n",
    "    grad_anomaly_mode=False,\n",
    "    gpu_oom_offload=False,\n",
    "    append=False,\n",
    "    warn_unused=False,\n",
    "    _jit_bailout_depth=2,  # avoid 20 iters of pain, see https://github.com/pytorch/pytorch/issues/52286\n",
    "    # Quote from eelison in PyTorch slack:\n",
    "    # https://pytorch.slack.com/archives/CDZD1FANA/p1644259272007529?thread_ts=1644064449.039479&cid=CDZD1FANA\n",
    "    # > Right now the default behavior is to specialize twice on static shapes and then on dynamic shapes.\n",
    "    # > To reduce warmup time you can do something like setFusionStrartegy({{FusionBehavior::DYNAMIC, 3}})\n",
    "    # > ... Although we would wouldn't really expect to recompile a dynamic shape fusion in a model,\n",
    "    # > provided broadcasting patterns remain fixed\n",
    "    # We default to DYNAMIC alone because the number of edges is always dynamic,\n",
    "    # even if the number of atoms is fixed:\n",
    "    _jit_fusion_strategy=[(\"DYNAMIC\", 3)],\n",
    "    # Due to what appear to be ongoing bugs with nvFuser, we default to NNC (fuser1) for now:\n",
    "    # TODO: still default to NNC on CPU regardless even if change this for GPU\n",
    "    # TODO: default for ROCm?\n",
    "    _jit_fuser=\"fuser1\",\n",
    ")\n",
    "\n",
    "# All default_config keys are valid / requested\n",
    "#_GLOBAL_ALL_ASKED_FOR_KEYS.update(default_config.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d99679c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config.from_file('./configs/example_SpinGNNPlus.yaml', defaults=default_config)\n",
    "    \n",
    "\n",
    "dataset = dataset_from_config(config, prefix=\"dataset\")\n",
    "\n",
    "validation_dataset = None\n",
    "\n",
    "dataset.type_mapper.num_types\n",
    "\n",
    "config['num_types'] = dataset.type_mapper.num_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e10fbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "from nequip.data import AtomicData, AtomicDataDict\n",
    "from torch.nn.functional import one_hot\n",
    "from e3nn.nn import FullyConnectedNet\n",
    "from allegro import with_edge_spin_length\n",
    "from allegro import _keys\n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "data = [AtomicData.to_AtomicDataDict(dataset[i]) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2ec18ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "018da129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['edge_index', 'pos', 'cell', 'pbc', 'edge_cell_shift', 'atom_types']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[i].keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf29945a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([494, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 2\n",
    "\n",
    "num_types = len(config['chemical_symbols'])\n",
    "\n",
    "\n",
    "atom_types_embed = data[i]['atom_types'][data[i]['edge_index'][0]]*num_types + data[i]['atom_types'][data[i]['edge_index'][1]]\n",
    "\n",
    "atom_types_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9591ea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nequip.data import AtomicDataDict, AtomicDataset\n",
    "from nequip.nn.embedding import (\n",
    "    OneHotAtomEncoding,\n",
    "    SphericalHarmonicEdgeAttrs,\n",
    "    RadialBasisEdgeEncoding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5935fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from e3nn import o3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6c2c373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1x0ee+1x1oe+1x2ee"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o3.Irreps.spherical_harmonics(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3cad5833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([494, 8]) torch.Size([494, 9])\n"
     ]
    }
   ],
   "source": [
    "from nequip.data import AtomicDataDict, AtomicDataset\n",
    "from nequip.nn.embedding import (\n",
    "    OneHotAtomEncoding,\n",
    "    SphericalHarmonicEdgeAttrs,\n",
    "    RadialBasisEdgeEncoding,\n",
    ")\n",
    "from e3nn import o3\n",
    "\n",
    "L = 2\n",
    "\n",
    "irreps_edge_sh = o3.Irreps.spherical_harmonics(L)\n",
    "\n",
    "rbe = RadialBasisEdgeEncoding(basis_kwargs={'r_max': config['r_max'], \n",
    "                                            'num_basis': 8},\n",
    "                              cutoff_kwargs={'r_max': config['r_max']},\n",
    "                              out_field=AtomicDataDict.EDGE_EMBEDDING_KEY,\n",
    "                              )\n",
    "\n",
    "sh = SphericalHarmonicEdgeAttrs(irreps_edge_sh=irreps_edge_sh)\n",
    "\n",
    "data = [rbe(data[i]) for i in range(len(data))]\n",
    "\n",
    "data = [sh(data[i]) for i in range(len(data))]\n",
    "\n",
    "\n",
    "print(data[i]['edge_embedding'].shape, data[i]['edge_attrs'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9efd0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['edge_index', 'pos', 'cell', 'pbc', 'edge_cell_shift', 'atom_types', 'edge_vectors', 'edge_lengths', 'edge_embedding', 'edge_cutoff', 'edge_attrs'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbb5715",
   "metadata": {},
   "source": [
    "## Feature Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "910c7aac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 494]) torch.Size([494, 3, 4]) torch.Size([494, 9, 4])\n",
      "torch.Size([23, 9, 4])\n"
     ]
    }
   ],
   "source": [
    "from torch_runstats.scatter import scatter\n",
    "\n",
    "N_rad = 8\n",
    "\n",
    "N_spec_rank = 4\n",
    "N_rad_rank = 4\n",
    "\n",
    "Q = data[i]['edge_embedding']\n",
    "\n",
    "A = torch.randn(L + 1, N_spec_rank, num_types**2)\n",
    "B = torch.randn(L + 1, N_rad_rank, N_rad, N_spec_rank)\n",
    "\n",
    "\n",
    "a = A[:, :, atom_types_embed].squeeze(-1)\n",
    "\n",
    "b = torch.einsum('Lrnk,LkE,En->ELr', B, a, Q)\n",
    "\n",
    "Y = data[i]['edge_attrs']\n",
    "\n",
    "#print(data[i]['edge_attrs'][:, slices])\n",
    "F = torch.concat([torch.einsum('Em,En->Emn', Y[:, slices],\n",
    "                               b[:, l]) for l, slices in enumerate(irreps_edge_sh.slices())], dim = -2)\n",
    "\n",
    "print(a.shape, b.shape, F.shape)\n",
    "\n",
    "\n",
    "species = data[i][AtomicDataDict.ATOM_TYPE_KEY].squeeze(-1)\n",
    "edge_center = data[i][AtomicDataDict.EDGE_INDEX_KEY][0]\n",
    "edge_neighbor = data[i][AtomicDataDict.EDGE_INDEX_KEY][1]\n",
    "\n",
    "center_species = species[edge_center]\n",
    "neighbor_species = species[edge_neighbor]\n",
    "\n",
    "F = scatter(F, edge_center, dim=0, dim_size=len(species))\n",
    "\n",
    "print(F.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e317052e",
   "metadata": {},
   "source": [
    "### Order 2 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9cea8590",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = 4\n",
    "n2 = 32\n",
    "L1 = L2 = range(L + 1)\n",
    "\n",
    "u_in = F.clone()\n",
    "T_2 = [order_2_equivariant_tensor()(l, l, n1, n2) for l in L1]\n",
    "\n",
    "\n",
    "u_out = torch.zeros((u_in.shape[0], u_in.shape[1], n2))\n",
    "for i, slices in enumerate(irreps_edge_sh.slices()):\n",
    "    u_out[:, slices, :] = torch.einsum('ij,Nmi->Nmj', T_2[i], u_in[:, slices, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9901d2a",
   "metadata": {},
   "source": [
    "### Order 3 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30d0a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n3 = 32\n",
    "L3 = range(L + 1)\n",
    "\n",
    "T_3 = [[[order_3_equvariant_tensor()(l3, l1, l2, n3, n1, n2) for l2 in L2] for l1 in L1] for l3 in L3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61d10c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-63.2352, grad_fn=<MinBackward1>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_in = u_out\n",
    "\n",
    "#T_2_tmp = torch.zeros((u_in.shape[0], u_in.shape[1], n2))\n",
    "\n",
    "T_2_tmp = [[None for l1 in L1] for l3 in L3]\n",
    "\n",
    "u_out = torch.zeros((u_in.shape[0], u_in.shape[1], n3))\n",
    "\n",
    "\n",
    "v = F.clone()\n",
    "for l2, slices in enumerate(irreps_edge_sh.slices()):\n",
    "    if l2 == 0:\n",
    "        for l3 in L3:\n",
    "            for l1 in L1:\n",
    "                T_2_tmp[l3][l1] = torch.einsum('abcijk,Nck->Nabij', T_3[l3][l1][l2], u_in[:, slices, :])\n",
    "    else:\n",
    "        for l3 in L3:\n",
    "            for l1 in L1:\n",
    "                T_2_tmp[l3][l1] += torch.einsum('abcijk,Nck->Nabij', T_3[l3][l1][l2], u_in[:, slices, :])\n",
    "    \n",
    "    \n",
    "for l3 in L3:    \n",
    "    for l1, slices in enumerate(irreps_edge_sh.slices()):\n",
    "        u_out[:, irreps_edge_sh.slices()[l3], :] += torch.einsum('Nabij,Nbj->Nai', T_2_tmp[l3][l1], v[:, slices, :])\n",
    "        \n",
    "        \n",
    "u_out.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fc2cce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(51.1680, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_out.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cdd85c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 9, 32])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6be116a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4300, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([ T_2[i][j].max() for i in [0, 1, 2] for j in [0, 1, 2] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4374b9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_2[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85f0d658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 9, 32])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3033c5b8",
   "metadata": {},
   "source": [
    "### Equivariance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ebf78042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1x0ee+1x1oe+1x2ee\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0796)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([[1, 12, 34]]*10)\n",
    "\n",
    "edge_vec_plus = x / torch.linalg.norm(x, dim = 1).unsqueeze(-1)\n",
    "edge_vec_minus = -x / torch.linalg.norm(x, dim = 1).unsqueeze(-1)\n",
    "\n",
    "irreps_sh = o3.Irreps('1x0e + 1x1o + 1x2e') #o3.Irreps.spherical_harmonics(lmax=2)\n",
    "irreps_sh_r = o3.Irreps('1x1o')\n",
    "print(irreps_sh)\n",
    "\n",
    "\n",
    "alpha, beta, gamma = o3.rand_angles(100)\n",
    "\n",
    "rot_matrix = irreps_sh.D_from_angles(alpha[0], beta[0], gamma[0])\n",
    "rot_matrix_r = irreps_sh_r.D_from_angles(alpha[0], beta[0], gamma[0])\n",
    "\n",
    "\n",
    "sh_plus = o3.spherical_harmonics(irreps_sh, edge_vec_plus, normalize=True)\n",
    "\n",
    "sh_plus_of_rot =  o3.spherical_harmonics(irreps_sh, edge_vec_plus @ rot_matrix_r, \n",
    "                                        normalize=True)\n",
    "\n",
    "sh_plus_rot = o3.spherical_harmonics(irreps_sh, edge_vec_plus, \n",
    "                                        normalize=True) @ rot_matrix\n",
    "\n",
    "sh_plus_of_rot_rot = o3.spherical_harmonics(irreps_sh, edge_vec_plus @ rot_matrix_r, \n",
    "                                        normalize=True) @ rot_matrix.T\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sh_minus = o3.spherical_harmonics(irreps_sh, edge_vec_minus, normalize=True)\n",
    "# normalize=True ensure that x is divided by |x| before computing the sh\n",
    "\n",
    "sh_plus.pow(2).mean()  # should be close to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1585ddf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2821, -0.4627,  0.1386, -0.0735,  0.1557, -0.2935, -0.2393, -0.0466,\n",
       "        -0.4776])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sh_plus_rot[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f02e0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2821,  0.0135,  0.1626,  0.4606,  0.0286,  0.0101, -0.2107,  0.3426,\n",
      "         0.4850])\n",
      "tensor([ 0.2821,  0.0135,  0.1626,  0.4606,  0.0286,  0.0101, -0.2107,  0.3426,\n",
      "         0.4850])\n"
     ]
    }
   ],
   "source": [
    "print(sh_plus[0])\n",
    "\n",
    "print(sh_plus_of_rot_rot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f5912c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage_0(data, i):\n",
    "    \n",
    "\n",
    "    from nequip.data import AtomicDataDict, AtomicDataset\n",
    "    from nequip.nn.embedding import (\n",
    "        OneHotAtomEncoding,\n",
    "        SphericalHarmonicEdgeAttrs,\n",
    "        RadialBasisEdgeEncoding,\n",
    "    )\n",
    "    from e3nn import o3\n",
    "\n",
    "    \n",
    "    #torch.manual_seed(32)\n",
    "    \n",
    "    L = 2\n",
    "\n",
    "    irreps_edge_sh = o3.Irreps.spherical_harmonics(L)\n",
    "    print(irreps_edge_sh)\n",
    "    \n",
    "    rbe = RadialBasisEdgeEncoding(basis_kwargs={'r_max': config['r_max'], \n",
    "                                                'num_basis': 8},\n",
    "                                  cutoff_kwargs={'r_max': config['r_max']},\n",
    "                                  out_field=AtomicDataDict.EDGE_EMBEDDING_KEY,\n",
    "                                  )\n",
    "\n",
    "    sh = SphericalHarmonicEdgeAttrs(irreps_edge_sh=irreps_edge_sh)\n",
    "\n",
    "    data = [rbe(data[i]) for i in range(len(data))]\n",
    "\n",
    "    data = [sh(data[i]) for i in range(len(data))]\n",
    "\n",
    "\n",
    "    #print(data[i]['edge_embedding'].shape, data[i]['edge_attrs'].shape)\n",
    "    \n",
    "    \n",
    "    from torch_runstats.scatter import scatter\n",
    "\n",
    "    N_rad = 8\n",
    "\n",
    "    N_spec_rank = 4\n",
    "    N_rad_rank = 4\n",
    "\n",
    "    Q = data[i]['edge_embedding']\n",
    "\n",
    "    A = torch.randn(L + 1, N_spec_rank, num_types**2)\n",
    "    B = torch.randn(L + 1, N_rad_rank, N_rad, N_spec_rank)\n",
    "\n",
    "\n",
    "    a = A[:, :, atom_types_embed].squeeze(-1)\n",
    "\n",
    "    b = torch.einsum('Lrnk,LkE,En->ELr', B, a, Q)\n",
    "\n",
    "    #print(data[i]['pos'][2])\n",
    "    Y = data[i]['edge_attrs']\n",
    "    #print(Y[2])\n",
    "    #print(data[i]['edge_attrs'][:, slices])\n",
    "    F = torch.concat([torch.einsum('Em,En->Emn', Y[:, slices],\n",
    "                                   b[:, l]) for l, slices in enumerate(irreps_edge_sh.slices())], dim = -2)\n",
    "    \n",
    "    print(F[2, :, 0])\n",
    "    #F = Y.unsqueeze(-1)\n",
    "    #print(a.shape, b.shape, F.shape)\n",
    "\n",
    "\n",
    "    species = data[i][AtomicDataDict.ATOM_TYPE_KEY].squeeze(-1)\n",
    "    edge_center = data[i][AtomicDataDict.EDGE_INDEX_KEY][0]\n",
    "    edge_neighbor = data[i][AtomicDataDict.EDGE_INDEX_KEY][1]\n",
    "\n",
    "    center_species = species[edge_center]\n",
    "    neighbor_species = species[edge_neighbor]\n",
    "\n",
    "    F = scatter(F, edge_center, dim=0, dim_size=len(species))\n",
    "\n",
    "    #return F\n",
    "    \n",
    "    return data[i]['edge_attrs'].unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "65864472",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "from nequip.data import AtomicData, AtomicDataDict\n",
    "from torch.nn.functional import one_hot\n",
    "from e3nn.nn import FullyConnectedNet\n",
    "from allegro import with_edge_spin_length\n",
    "from allegro import _keys\n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "data = [AtomicData.to_AtomicDataDict(dataset[i]) for i in range(10)]\n",
    "\n",
    "\n",
    "import copy\n",
    "\n",
    "data_new = [{key: torch.clone(el[key]) for key in el} for el in data]\n",
    "\n",
    "irreps_sh = o3.Irreps('1x0e + 1x1o + 1x2e') #o3.Irreps.spherical_harmonics(lmax=2)\n",
    "irreps_sh_r = o3.Irreps('1x1o')\n",
    "\n",
    "alpha, beta, gamma = o3.rand_angles(100)\n",
    "\n",
    "rot_matrix = irreps_sh.D_from_angles(alpha[0], beta[0], gamma[0])\n",
    "rot_matrix_r = irreps_sh_r.D_from_angles(alpha[0], beta[0], gamma[0])\n",
    "\n",
    "\n",
    "for i, el in enumerate(data_new):\n",
    "    data_new[i]['pos'] = data_new[i]['pos'] @ rot_matrix_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b08f7af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edge_index': tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "           2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,\n",
       "           3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,\n",
       "           4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "           4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "           5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "           6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "           7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,\n",
       "           8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,\n",
       "           9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10,\n",
       "          10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "          11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "          11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "          12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "          13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "          14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15,\n",
       "          15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16,\n",
       "          16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "          16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "          18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19,\n",
       "          19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20,\n",
       "          20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "          20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "          21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
       "          22, 22, 22, 22, 22, 22, 22, 22],\n",
       "         [10,  1,  2,  3,  4,  5,  6,  7,  9, 22, 21, 12, 13, 14, 15, 16, 17, 18,\n",
       "          19, 20, 11,  8,  7,  6,  4,  3,  2, 11,  5, 21, 16, 13, 14, 15, 17, 18,\n",
       "          19, 20,  0, 10, 12, 22,  9,  9, 22, 10,  1,  3,  4,  5,  6, 20,  7, 19,\n",
       "          11, 21, 12, 13, 14, 15, 16,  8, 17,  0, 18, 18, 17, 16, 15, 14, 13, 12,\n",
       "          21, 22, 10,  8,  7,  6,  5,  4,  2,  1,  9, 11, 20, 19,  0,  0, 10,  1,\n",
       "           2,  3,  5,  6,  7,  8,  9, 21, 12, 13, 14, 16, 17, 18, 19, 20, 11, 22,\n",
       "          15,  9, 22, 10,  1,  2,  3,  4,  6, 20,  7, 19, 11, 21, 12, 13, 14, 15,\n",
       "          16,  8, 17,  0, 18, 18, 17, 16, 15, 14, 13, 12, 21, 22, 10,  8,  7,  5,\n",
       "           4,  3,  2,  1,  9,  0, 11, 20, 19,  0, 20, 19, 18, 17, 16, 15, 14, 13,\n",
       "          12, 22,  9,  8,  6,  5,  3,  2,  1, 10, 21,  4,  1,  2,  3,  4,  5,  6,\n",
       "           7, 22, 21, 12, 13, 14, 15, 16, 17, 18, 19, 20, 10, 19,  1,  2,  3,  4,\n",
       "          22,  5,  6,  7, 11, 21, 12, 13, 14, 15, 16, 17, 18, 20,  0, 20, 22, 19,\n",
       "          18, 17, 16, 15,  0, 13, 12, 21, 11, 14,  7,  6,  5,  4,  3,  2,  1,  9,\n",
       "           6,  5,  4,  2,  1, 10,  3,  9, 21,  0, 19, 18, 17, 20, 15, 14, 13, 12,\n",
       "          16,  7, 10,  1,  2,  3,  4,  5,  6,  8, 14, 11, 21, 13, 22, 15, 16, 17,\n",
       "          18,  9,  0, 20, 19, 10,  0, 20, 19, 18, 17, 16, 15, 14, 12, 21, 11,  9,\n",
       "           8,  7,  6,  3,  2,  1, 22,  5,  4,  9, 22, 10,  1,  2,  3,  4,  5,  6,\n",
       "          20,  7, 19, 11, 21, 12, 13, 15, 16,  8, 17,  0, 18, 18, 17, 16, 14, 13,\n",
       "          12, 21, 22, 10,  8,  7,  6,  5,  4,  3,  2,  1,  9, 11, 20, 19,  0,  0,\n",
       "          10,  1,  2,  3,  5,  6,  7,  8,  9, 11, 12, 13, 14, 15, 17, 18, 19, 20,\n",
       "          21, 22,  4,  0, 10,  1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 21, 12, 13,\n",
       "          14, 15, 16, 18, 22, 19, 20,  1, 20, 19, 17, 16, 15, 14, 13, 12, 21, 11,\n",
       "           9,  8,  7,  6,  5,  4,  3,  2, 10, 22,  0,  0, 10,  1,  2,  3,  4,  5,\n",
       "           6,  7,  8, 22,  9, 21, 12, 13, 14, 15, 16, 17, 18, 11, 20, 10,  1,  2,\n",
       "           3,  4,  5,  6,  7,  8,  9, 11, 21, 12, 13, 14, 15, 16, 17, 18, 19,  0,\n",
       "          22, 20, 22,  0, 19, 18, 17, 16, 15, 13, 12, 11, 14,  8, 10,  9,  2,  3,\n",
       "           4,  1,  5,  6,  7,  9,  2,  3,  4,  5,  6,  7,  8,  1,  0, 12, 13, 14,\n",
       "          15, 16, 17, 18, 19, 20, 10, 21]]),\n",
       " 'pos': tensor([[ 3.0330, -0.3989,  0.0723],\n",
       "         [ 1.6285, -0.6667, -0.4800],\n",
       "         [ 0.4985,  0.2813,  0.0045],\n",
       "         [ 0.3942,  0.2849,  1.5397],\n",
       "         [ 0.7374,  1.7084, -0.5226],\n",
       "         [-0.8299, -0.2898, -0.5970],\n",
       "         [-1.0544, -1.6124, -0.1851],\n",
       "         [-2.0520,  0.5469, -0.2694],\n",
       "         [-3.0069,  0.0736,  0.3021],\n",
       "         [ 3.3933,  0.6075, -0.1634],\n",
       "         [ 3.0778, -0.5248,  1.1581],\n",
       "         [ 3.7444, -1.1067, -0.3648],\n",
       "         [ 1.6632, -0.6168, -1.5770],\n",
       "         [ 1.3358, -1.6906, -0.2305],\n",
       "         [ 1.3107,  0.6661,  1.9976],\n",
       "         [-0.4283,  0.9232,  1.8822],\n",
       "         [ 0.2138, -0.7255,  1.9152],\n",
       "         [ 0.6883,  1.7459, -1.6172],\n",
       "         [ 0.0125,  2.4256, -0.1257],\n",
       "         [ 1.7270,  2.0665, -0.2265],\n",
       "         [-0.7262, -0.2496, -1.6984],\n",
       "         [-1.9349, -1.6112,  0.2238],\n",
       "         [-2.0457,  1.6037, -0.5955]]),\n",
       " 'cell': tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]),\n",
       " 'pbc': tensor([False, False, False]),\n",
       " 'edge_cell_shift': tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]),\n",
       " 'atom_types': tensor([[5],\n",
       "         [5],\n",
       "         [5],\n",
       "         [5],\n",
       "         [5],\n",
       "         [5],\n",
       "         [7],\n",
       "         [5],\n",
       "         [7],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]])}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0b4bc72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1x0ee+1x1oe+1x2ee\n",
      "tensor([ 0.7256, -1.0742,  0.2883, -0.0287, -0.0502,  0.5037,  0.4641,  0.0135,\n",
      "         0.9378], grad_fn=<SelectBackward0>)\n",
      "1x0ee+1x1oe+1x2ee\n",
      "tensor([ 0.2077, -0.4409,  0.1223,  0.1349, -0.0132, -0.0120, -0.0117,  0.0037,\n",
      "        -0.0196], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "F = stage_0(data, 2)\n",
    "\n",
    "F_new = stage_0(data_new, 2)\n",
    "\n",
    "#F = data[2]['edge_attrs'].unsqueeze(-1)\n",
    "#F_new = data_new[2]['edge_attrs'].unsqueeze(-1)\n",
    "\n",
    "F_new_rot = torch.einsum('Njn,jk->Nkn', F_new, rot_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a0a722e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(F, F_new_rot, atol=1e-03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1315e1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  0.0709, -0.1992,  1.7191,  0.1573, -0.0182, -1.0737, -0.4422,\n",
       "         1.9044])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "706870e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  0.0709, -0.1992,  1.7191,  0.1573, -0.0182, -1.0737, -0.4422,\n",
       "         1.9044])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_new_rot[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "42f6446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage_1(F):\n",
    "    \n",
    "    #torch.manual_seed(32)\n",
    "    \n",
    "    n1 = 4\n",
    "    n2 = 32\n",
    "    L1 = L2 = range(L + 1)\n",
    "\n",
    "    u_in = F.clone()\n",
    "    T_2 = [order_2_equivariant_tensor()(l, l, n1, n2) for l in L1]\n",
    "\n",
    "\n",
    "    u_out = torch.zeros((u_in.shape[0], u_in.shape[1], n2))\n",
    "    for i, slices in enumerate(irreps_edge_sh.slices()):\n",
    "        u_out[:, slices, :] = torch.einsum('ij,Nmi->Nmj', T_2[i], u_in[:, slices, :])\n",
    "        \n",
    "    return u_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "18aefcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_out = stage_1(F)\n",
    "\n",
    "u_out_new = stage_1(F_new)\n",
    "\n",
    "u_out_new_rot = torch.einsum('Njn,jk->Nkn', u_out_new, rot_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9d5f76f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(u_out, u_out_new_rot, atol=1e-03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "1889bfc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(3 - 2, 0, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "08375d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage_2(u_in, F):\n",
    "    \n",
    "    torch.manual_seed(32)\n",
    "    \n",
    "    n1 = 4\n",
    "    n2 = 32\n",
    "    L1 = L2 = range(L + 1)\n",
    "    \n",
    "    n3 = 32\n",
    "    L3 = range(L + 1)\n",
    "\n",
    "    T_3 = [[[order_3_equvariant_tensor()(l3, l1, l2, n3, n1, n2) for l2 in L2] for l1 in L1] for l3 in L3]\n",
    "\n",
    "    #T_2_tmp = torch.zeros((u_in.shape[0], u_in.shape[1], n2))\n",
    "\n",
    "    T_2_tmp = [[None for l1 in L1] for l3 in L3]\n",
    "\n",
    "    u_out = torch.zeros((u_in.shape[0], u_in.shape[1], n3))\n",
    "\n",
    "\n",
    "    v = F.clone()\n",
    "    for l2, slices in enumerate(irreps_edge_sh.slices()):\n",
    "        if l2 == 0:\n",
    "            for l3 in L3:\n",
    "                for l1 in L1:\n",
    "                    T_2_tmp[l3][l1] = torch.einsum('abcijk,Nck->Nabij', T_3[l3][l1][l2], u_in[:, slices, :])\n",
    "        else:\n",
    "            for l3 in L3:\n",
    "                for l1 in L1:\n",
    "                    T_2_tmp[l3][l1] += torch.einsum('abcijk,Nck->Nabij', T_3[l3][l1][l2], u_in[:, slices, :])\n",
    "\n",
    "\n",
    "    for l3 in L3:    \n",
    "        for l1, slices in enumerate(irreps_edge_sh.slices()):\n",
    "            u_out[:, irreps_edge_sh.slices()[l3], :] += torch.einsum('Nabij,Nbj->Nai', T_2_tmp[l3][l1], v[:, slices, :])\n",
    "\n",
    "            \n",
    "    return u_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c3d8fe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_out_2 = stage_2(u_out, F)\n",
    "\n",
    "u_out_2_new = stage_2(u_out_new, F_new)\n",
    "\n",
    "u_out_2_new_rot = torch.einsum('Njn,jk->Nkn', u_out_2_new, rot_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0e979ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(u_out_2, u_out_2_new_rot, atol=1e-03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a7b4a2",
   "metadata": {},
   "source": [
    "### Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "73216f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tri_ineq(l1, l2, l3):\n",
    "    #print(max([l1, l2, l3]), min([l1 + l2, l2 + l3, l1 + l3]))\n",
    "    return max([l1, l2, l3]) <= min([l1 + l2, l2 + l3, l1 + l3])\n",
    "\n",
    "class order_3_equvariant_tensor():\n",
    "    \n",
    "    def __init__(self, l1, l2, l3, n1, n2, n3):\n",
    "        \"\"\" Basically transformation using\n",
    "            C (l1 l2 l3)\n",
    "              (m1 m2 m3)\"\"\"\n",
    "        self.l1 = l1; self.l2 = l2; self.l3 = l3\n",
    "        self.n1 = n1; self.n2 = n2; self.n3 = n3\n",
    "    \n",
    "        weight = torch.zeros([n1, n2, n3])\n",
    "        self.weight = nn.Parameter(nn.init.kaiming_uniform_(weight))\n",
    "        \n",
    "        \n",
    "        self.symbol_3j = wigner_3j(l1, l2, l3)\n",
    "        \n",
    "        \n",
    "    def __call__(self):\n",
    "        \n",
    "        if tri_ineq(l1, l2, l3):\n",
    "            return self.symbol_3j.view(*symbol_3j.shape, 1, 1, 1)*self.weight.view(1, 1, 1, *weight.shape)\n",
    "        else:\n",
    "            return torch.zeros((2*l1 + 1, 2*l2 + 1, 2*l3 + 1, n1, n2, n3))\n",
    "        \n",
    "        \n",
    "def contract_2_tensors(tensor_1, tensor_2):\n",
    "    weight_new = (tensor_1.weight.flatten(end_dim = -2) @ tensor_2.weight.flatten(start_dim = 1)).view(tensor_1.n1, tensor_1.n2, tensor_2.n2,\n",
    "                                                                                                       tensor_2.n3)\n",
    "    \n",
    "    \n",
    "    return weight_new, tensor_1.symbol_3j, tensor_2.symbol_3j\n",
    "    \n",
    "        \n",
    "class order_2_equivariant_tensor():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Makes the 2nd order tensor in a way that\n",
    "           each lm is multiplied by coefficient c, no angular momentum mixing\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, l1, l2, n1, n2):\n",
    "        self.l1 = l1; self.l2 = l2\n",
    "        self.n1 = n1; self.n2 = n2\n",
    "        \n",
    "        weight = torch.zeros([n1, n2])\n",
    "        if l1 == l2: # same as tri_ineq(l1, l2, 0)\n",
    "            W = nn.Parameter(nn.init.kaiming_uniform_(weight))\n",
    "            return W.view(*weight.shape)\n",
    "        else:\n",
    "            return torch.zeros((n1, n2))\n",
    "\n",
    "        \n",
    "class order_1_equivariant_tensor():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Makes the 1nd order tensor in a way that\n",
    "           each lm is multiplied by coefficient c, no angular momentum mixing\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, l1, n1):\n",
    "        self.l1 = l1;\n",
    "        self.n1 = n1;\n",
    "        \n",
    "        weight = torch.zeros([n1])\n",
    "        W = nn.Parameter(nn.init.uniform(weight))\n",
    "        return torch.ones((2*l1 + 1, 1))*W.view(1, *weight.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a5ab629f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 8, 8])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_1 = order_3_equvariant_tensor(0, 0, 0, 4, 8, 32)\n",
    "tensor_2 = order_3_equvariant_tensor(0, 0, 0, 32, 8, 8)\n",
    "\n",
    "tensor_4th_order_weight = contract_2_tensors(tensor_1, tensor_2)[0]\n",
    "\n",
    "tensor_4th_order_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "af401041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([max([l1, l2, l3]) <= min([l1 + l2, l2 + l3, l1 + l3]) for l1 in range(10) for l2 in range(10) for l3 in range(10)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d851f285",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LiftingKernelBase' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mInterpolativeLiftingKernel\u001b[39;00m(\u001b[43mLiftingKernelBase\u001b[49m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, group, kernel_size, in_channels, out_channels):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(group, kernel_size, in_channels, out_channels)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LiftingKernelBase' is not defined"
     ]
    }
   ],
   "source": [
    "class InterpolativeLiftingKernel(LiftingKernelBase):\n",
    "\n",
    "    def __init__(self, group, kernel_size, in_channels, out_channels):\n",
    "        super().__init__(group, kernel_size, in_channels, out_channels)\n",
    "\n",
    "        # Create and initialise a set of weights, we will interpolate these\n",
    "        # to create our transformed spatial kernels.\n",
    "        self.weight = torch.nn.Parameter(torch.zeros((\n",
    "            self.out_channels,\n",
    "            self.in_channels,\n",
    "            self.kernel_size,\n",
    "            self.kernel_size\n",
    "        ), device=self.group.identity.device))\n",
    "\n",
    "        # Initialize weights using kaiming uniform intialisation.\n",
    "        torch.nn.init.kaiming_uniform_(self.weight.data, a=math.sqrt(5))\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\" Sample convolution kernels for a given number of group elements\n",
    "\n",
    "        should return:\n",
    "        :return kernels: filter bank extending over all input channels,\n",
    "            containing kernels transformed for all output group elements.\n",
    "        \"\"\"\n",
    "        # First, we fold the output channel dim into the input channel dim;\n",
    "        # this allows us to transform the entire filter bank in one go using the\n",
    "        # torch grid_sample function.\n",
    "\n",
    "        ## YOUR CODE STARTS HERE ##\n",
    "        weight = self.weight.view(\n",
    "            self.out_channels * self.in_channels,\n",
    "            self.kernel_size,\n",
    "            self.kernel_size\n",
    "        )\n",
    "        ## AND ENDS HERE ##\n",
    "\n",
    "        # Sample the transformed kernels.\n",
    "        transformed_weight = []\n",
    "        for spatial_grid_idx in range(self.group.elements().numel()):\n",
    "            transformed_weight.append(\n",
    "                bilinear_interpolation(weight, self.transformed_grid_R2[:, spatial_grid_idx, :, :])\n",
    "            )\n",
    "        transformed_weight = torch.stack(transformed_weight)\n",
    "\n",
    "        # Separate input and output channels.\n",
    "        transformed_weight = transformed_weight.view(\n",
    "            self.group.elements().numel(),\n",
    "            self.out_channels,\n",
    "            self.in_channels,\n",
    "            self.kernel_size,\n",
    "            self.kernel_size\n",
    "        )\n",
    "\n",
    "        # Put out channel dimension before group dimension. We do this\n",
    "        # to be able to use pytorched Conv2D. Details below!\n",
    "        transformed_weight = transformed_weight.transpose(0, 1)\n",
    "\n",
    "        return transformed_weight\n",
    "\n",
    "\n",
    "class LiftingConvolution(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, group, in_channels, out_channels, kernel_size, padding):\n",
    "        super().__init__()\n",
    "\n",
    "        self.kernel = InterpolativeLiftingKernel(\n",
    "            group=group,\n",
    "            kernel_size=kernel_size,\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels\n",
    "        )\n",
    "\n",
    "        self.padding = padding\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" Perform lifting convolution\n",
    "\n",
    "        @param x: Input sample [batch_dim, in_channels, spatial_dim_1,\n",
    "            spatial_dim_2]\n",
    "        @return: Function on a homogeneous space of the group\n",
    "            [batch_dim, out_channels, num_group_elements, spatial_dim_1,\n",
    "            spatial_dim_2]\n",
    "        \"\"\"\n",
    "\n",
    "        # Obtain convolution kernels transformed under the group.\n",
    "\n",
    "        ## YOUR CODE STARTS HERE ##\n",
    "        conv_kernels = self.kernel.sample()\n",
    "        ## AND ENDS HERE ##\n",
    "\n",
    "        # Apply lifting convolution. Note that using a reshape we can fold the\n",
    "        # group dimension of the kernel into the output channel dimension. We\n",
    "        # treat every transformed kernel as an additional output channel. This\n",
    "        # way we can use pytorch's conv2d function!\n",
    "\n",
    "        # Question: Do you see why we (can) do this?\n",
    "\n",
    "        ## YOUR CODE STARTS HERE ##\n",
    "        x = torch.nn.functional.conv2d(\n",
    "            input=x,\n",
    "            weight=conv_kernels.reshape(\n",
    "                self.kernel.out_channels * self.kernel.group.elements().numel(),\n",
    "                self.kernel.in_channels,\n",
    "                self.kernel.kernel_size,\n",
    "                self.kernel.kernel_size\n",
    "            ),\n",
    "            padding=self.padding\n",
    "        )\n",
    "        ## AND ENDS HERE ##\n",
    "\n",
    "        # Reshape [batch_dim, in_channels * num_group_elements, spatial_dim_1,\n",
    "        # spatial_dim_2] into [batch_dim, in_channels, num_group_elements,\n",
    "        # spatial_dim_1, spatial_dim_2], separating channel and group\n",
    "        # dimensions.\n",
    "        x = x.view(\n",
    "            -1,\n",
    "            self.kernel.out_channels,\n",
    "            self.kernel.group.elements().numel(),\n",
    "            x.shape[-1],\n",
    "            x.shape[-2]\n",
    "        )\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f1fea33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.bias = bias\n",
    "        self.weight = torch.nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        if bias:\n",
    "            self.bias = torch.nn.Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = torch.nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            torch.nn.init.uniform_(self.bias, -bound, bound)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x, y = input.shape\n",
    "        if y != self.in_features:\n",
    "            print(f'Wrong Input Features. Please use tensor with {self.in_features} Input Features')\n",
    "            return 0\n",
    "        output = input.matmul(weight.t())\n",
    "        if bias is not None:\n",
    "            output += bias\n",
    "        ret = output\n",
    "        return ret\n",
    "    \n",
    "    def extra_repr(self):\n",
    "        return 'in_features={}, out_features={}, bias={}'.format(\n",
    "            self.in_features, self.out_features, self.bias is not None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "05568db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from nequip.data import AtomicDataDict, AtomicDataset\n",
    "from nequip.nn.embedding import (\n",
    "    OneHotAtomEncoding,\n",
    "    SphericalHarmonicEdgeAttrs,\n",
    "    RadialBasisEdgeEncoding,\n",
    ")\n",
    "from e3nn import o3\n",
    "\n",
    "\n",
    "class NodeAttrLayer(nn.Module):\n",
    "    def __init__(self, num_types, lmax, r_max, Nc, N_rad, N_rank_spec):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        # parameters of the system\n",
    "        self.num_types = num_types # number of types\n",
    "        self.lmax = lmax # maximum spherical harmonic\n",
    "        self.r_max = r_max # radial cutoff\n",
    "        \n",
    "        \n",
    "        # Parameters of the network\n",
    "        self.Nc = Nc # number of output features\n",
    "        self.N_rad = N_rad # number of radial basis functions\n",
    "        self.N_rank_spec = N_rank_spec # encoding of species after one_hot\n",
    "        \n",
    "        # tensors for atomic features encoding\n",
    "        self.A = torch.nn.Parameter(torch.Tensor(lmax + 1, N_rank_spec, num_types**2))\n",
    "        self.B =  torch.nn.Parameter(torch.Tensor(lmax + 1, Nc, N_rad, N_rank_spec))\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def forward(self, data: AtomicDataDict.Type) -> AtomicDataDict.Type:\n",
    "        \n",
    "        \n",
    "        # Generating radial and spherical basis functions\n",
    "        irreps_edge_sh = o3.Irreps.spherical_harmonics(self.lmax)\n",
    "        rbe = RadialBasisEdgeEncoding(basis_kwargs={'r_max': self.r_max, \n",
    "                                                    'num_basis': self.N_rad},\n",
    "                                      cutoff_kwargs={'r_max': self.r_max},\n",
    "                                      out_field=AtomicDataDict.EDGE_EMBEDDING_KEY,\n",
    "                                      )\n",
    "        sh = SphericalHarmonicEdgeAttrs(irreps_edge_sh=irreps_edge_sh)\n",
    "\n",
    "        data = rbe(data)\n",
    "        data = sh(data)\n",
    "\n",
    "        # Creating flattened square matrix of pair types\n",
    "        species = data[AtomicDataDict.ATOM_TYPE_KEY].squeeze(-1)\n",
    "        edge_center = data[AtomicDataDict.EDGE_INDEX_KEY][0]\n",
    "        edge_neighbor = data[AtomicDataDict.EDGE_INDEX_KEY][1]\n",
    "        \n",
    "        atom_types_embed = species[edge_center]*num_types + species[edge_neighbor]\n",
    "    \n",
    "        \n",
    "        # Algo from ETN paper to gen F (notation preserved)\n",
    "        Q = data['edge_embedding']\n",
    "        a = self.A[:, :, atom_types_embed].squeeze(-1)\n",
    "        b = torch.einsum('Lrnk,LkE,En->ELr', self.B, a, Q)\n",
    "\n",
    "        Y = data['edge_attrs']\n",
    "    \n",
    "        F = torch.concat([torch.einsum('Em,En->Emn', Y[:, slices],\n",
    "                                       b[:, l]) for l, slices in enumerate(irreps_edge_sh.slices())], dim = -2)\n",
    "\n",
    "        \n",
    "        # Passing massage to the node creating node feature\n",
    "        data['node_attrs'] = scatter(F, edge_center, dim=0, dim_size=len(species))\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        #torch.nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        torch.nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))\n",
    "        torch.nn.init.kaiming_uniform_(self.B, a=math.sqrt(5))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d7c9b500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o3.Irreps.spherical_harmonics(2, p = -1).lmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2cbe4aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nc = 6\n",
    "N_rad = 8\n",
    "N_rank_spec = 4\n",
    "\n",
    "\n",
    "nal = NodeAttrLayer(num_types = config['num_types'], \n",
    "                    lmax = config['l_max'], \n",
    "                    r_max = config['r_max'], \n",
    "                    Nc = Nc,\n",
    "                    N_rad = N_rad,\n",
    "                    N_rank_spec = N_rank_spec)\n",
    "\n",
    "\n",
    "data_new = nal(data[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d43cc28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 9, 6])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new['node_attrs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c6b0da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class ETN(nn.Module):\n",
    "    def __init__(self, lmax, d, Nc, rank,\n",
    "                 num_types, N_rad, N_rank_spec):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        # Hyperparameters\n",
    "        self.lmax = lmax\n",
    "        \n",
    "        self.d = d\n",
    "        \n",
    "        self.Nc = Nc\n",
    "        self.rank = rank\n",
    "    \n",
    "    \n",
    "        # Parameters of the system\n",
    "        self.num_types = num_types # number of types\n",
    "        self.N_rad = N_rad # number of radial basis functions\n",
    "        self.N_rank_spec = N_rank_spec # encoding of species after one_hot \n",
    "        \n",
    " \n",
    "        # tensors for atomic features encoding\n",
    "        A = torch.nn.Parameter(torch.Tensor(lmax + 1, Nc, num_types**2))\n",
    "        B =  torch.nn.Parameter(torch.Tensor(lmax + 1, Nc, N_rad, N_rank_spec))\n",
    "        \n",
    "        L = range(lmax + 1)\n",
    "        # order 2 tensors of first and last branch of ETN\n",
    "        T2_ETN = [[order_2_equivariant_tensor()(l, l, Nc, rank[i]) for l in L],\n",
    "                  [order_2_equivariant_tensor()(l, l, Nc, rank[-1]) for l in L]]\n",
    "        \n",
    "        \n",
    "        # order 3 tensors\n",
    "        self.T3 = [[[[order_3_equvariant_tensor()(l3, l1, l2, rank[i+1], rank[i], Nc) for l2 in L] for l1 in L] for l3 in L] for i in range(d-1)]\n",
    "    \n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def forward(self, data: AtomicDataDict.Type) -> AtomicDataDict.Type:\n",
    "        pass\n",
    "    \n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        #torch.nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d3cfebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import logging\n",
    "\n",
    "from e3nn import o3\n",
    "\n",
    "from nequip.data import AtomicDataDict, AtomicDataset\n",
    "\n",
    "from nequip.nn import SequentialGraphNetwork, AtomwiseReduce\n",
    "from nequip.nn.radial_basis import BesselBasis\n",
    "\n",
    "from nequip.nn.embedding import (\n",
    "    OneHotAtomEncoding,\n",
    "    SphericalHarmonicEdgeAttrs,\n",
    "    RadialBasisEdgeEncoding,\n",
    ")\n",
    "\n",
    "from allegro.nn import (\n",
    "    NormalizedBasis,\n",
    "    EdgewiseEnergySum,\n",
    "    EdgewiseEnergySumBQ,\n",
    "    EdgewiseEnergySumJ,\n",
    "    EdgewiseEnergySumA,\n",
    "    EdgewiseEnergySumTENN,\n",
    "    EdgewiseSpinSum,\n",
    "    AtomwiseReduceSpinGNNPlus,\n",
    "    Allegro_Module,\n",
    "    Allegro_Module_MSENN,\n",
    "    Allegro_Module_TENN,\n",
    "    ScalarMLP,\n",
    ")\n",
    "#from allegro._keys import EDGE_FEATURES, EDGE_ENERGY, EDGE_SPIN, EDGE_SPIN_DISTANCE_EMBEDDING, EDGE_J\n",
    "#from allegro._keys import EDGE_ENERGY_SEGNN\n",
    "from allegro._keys import *\n",
    "from allegro import RadialBasisSpinDistanceEncoding, SphericalHarmonicEdgeAttrsTENN\n",
    "\n",
    "\n",
    "from nequip.model import builder_utils\n",
    "\n",
    "\n",
    "def SpinGNNPlus(config, initialize: bool, dataset: Optional[AtomicDataset] = None):\n",
    "    logging.debug(\"Building Allegro model...\")\n",
    "\n",
    "    # Handle avg num neighbors auto\n",
    "    builder_utils.add_avg_num_neighbors(\n",
    "        config=config, initialize=initialize, dataset=dataset\n",
    "    )\n",
    "\n",
    "    # Handle simple irreps\n",
    "    if \"l_max\" in config:\n",
    "        l_max = int(config[\"l_max\"])\n",
    "        parity_setting = config[\"parity\"]\n",
    "        assert parity_setting in (\"o3_full\", \"o3_restricted\", \"so3\")\n",
    "        irreps_edge_sh = repr(\n",
    "            o3.Irreps.spherical_harmonics(\n",
    "                l_max, p=(1 if parity_setting == \"so3\" else -1)\n",
    "            )\n",
    "        )\n",
    "        nonscalars_include_parity = parity_setting == \"o3_full\"\n",
    "        # check consistant\n",
    "        assert config.get(\"irreps_edge_sh\", irreps_edge_sh) == irreps_edge_sh\n",
    "        assert (\n",
    "            config.get(\"nonscalars_include_parity\", nonscalars_include_parity)\n",
    "            == nonscalars_include_parity\n",
    "        )\n",
    "        config[\"irreps_edge_sh\"] = irreps_edge_sh\n",
    "        config[\"nonscalars_include_parity\"] = nonscalars_include_parity\n",
    "\n",
    "    # Handle simple irreps\n",
    "    if \"l_max\" in config:\n",
    "        l_max = int(config[\"l_max\"])\n",
    "        parity_setting = config[\"parity\"]\n",
    "        assert parity_setting in (\"o3_full\", \"o3_restricted\", \"so3\")\n",
    "        irreps_edge_sh_TENN = repr(\n",
    "            o3.Irreps.spherical_harmonics(\n",
    "                l_max, p=1, t = -1\n",
    "            ) \n",
    "        )\n",
    "        nonscalars_include_parity = parity_setting == \"o3_full\"\n",
    "        # check consistant\n",
    "        config[\"irreps_edge_sh_TENN\"] =  irreps_edge_sh_TENN\n",
    "        assert config.get(\"irreps_edge_sh_TENN\", irreps_edge_sh_TENN) == irreps_edge_sh_TENN\n",
    "        assert (\n",
    "            config.get(\"nonscalars_include_parity\", nonscalars_include_parity)\n",
    "            == nonscalars_include_parity\n",
    "        )\n",
    "\n",
    "\n",
    "    #print(config)\n",
    "    layers = {\n",
    "        # -- Encode --\n",
    "        # Get various edge invariants\n",
    "        \"one_hot\": OneHotAtomEncoding,\n",
    "        \"radial_basis\": (\n",
    "            RadialBasisEdgeEncoding,\n",
    "            dict(\n",
    "                basis=(\n",
    "                    NormalizedBasis\n",
    "                    if config.get(\"normalize_basis\", True)\n",
    "                    else BesselBasis\n",
    "                ),\n",
    "                out_field=AtomicDataDict.EDGE_EMBEDDING_KEY,\n",
    "            ),\n",
    "        ),\n",
    "        # Get edge nonscalars\n",
    "        \"spharm\": SphericalHarmonicEdgeAttrs,\n",
    "        # The HEGNN allegro model:\n",
    "        \"allegro_MSENN\": (\n",
    "            Allegro_Module_MSENN,\n",
    "            dict(\n",
    "                field=AtomicDataDict.EDGE_ATTRS_KEY,  # initial input is the edge SH\n",
    "                edge_invariant_field=AtomicDataDict.EDGE_EMBEDDING_KEY,\n",
    "                node_invariant_field=AtomicDataDict.NODE_ATTRS_KEY,\n",
    "            ),\n",
    "        ),\n",
    "        \"edge_eng\": (\n",
    "            ScalarMLP,\n",
    "            dict(field=EDGE_FEATURES, out_field=EDGE_ENERGY, mlp_output_dimension=1),\n",
    "        ),\n",
    "        \"edge_K\": (\n",
    "            ScalarMLP,\n",
    "            dict(field=EDGE_FEATURES, out_field=EDGE_K, \n",
    "                 mlp_latent_dimensions = [], mlp_output_dimension=1),\n",
    "        ),\n",
    "        # Sum edgewise energies -> per-atom energies:\n",
    "        \"edge_eng_sum\": EdgewiseEnergySum,\n",
    "        # encoding spin distance\n",
    "        \"spin_basis\": (\n",
    "            RadialBasisSpinDistanceEncoding,\n",
    "            dict(\n",
    "                basis=(\n",
    "                    NormalizedBasis\n",
    "                    if config.get(\"normalize_basis\", True)\n",
    "                    else BesselBasis\n",
    "                ),\n",
    "                out_field=EDGE_SPIN_DISTANCE_EMBEDDING,\n",
    "            ),\n",
    "        ),\n",
    "        # Sum biquadratic edgewise terms -> per-atom energies of biquadratic terms:\n",
    "        \"edge_eng_sum_BQ\": EdgewiseEnergySumBQ,\n",
    "        # Sum edgewise exchange terms -> per-atom energies of exchange terms:\n",
    "        \"edge_eng_sum_J\": EdgewiseEnergySumJ,\n",
    "        # Sum onsite spin terms -> per-atom energies of onsite spin terms:\n",
    "        \"edge_eng_sum_A\": EdgewiseEnergySumA,\n",
    "        # Get edge nonscalars\n",
    "        \"spharm_TENN\": SphericalHarmonicEdgeAttrsTENN,\n",
    "        # The TENN allegro model:\n",
    "        \"allegro_TENN\": (\n",
    "            Allegro_Module_TENN,\n",
    "            dict(\n",
    "                field=AtomicDataDict.EDGE_ATTRS_KEY,  # initial input is the edge SH\n",
    "                edge_invariant_field=AtomicDataDict.EDGE_EMBEDDING_KEY,\n",
    "                node_invariant_field=AtomicDataDict.NODE_ATTRS_KEY,\n",
    "            ),\n",
    "        ),\n",
    "        \"edge_eng_TENN\": (\n",
    "            ScalarMLP,\n",
    "            dict(field=EDGE_FEATURES, out_field=EDGE_ENERGY_TENN, \n",
    "                 mlp_latent_dimensions = [], mlp_output_dimension=1),\n",
    "        ),\n",
    "        \"edge_spin\": (\n",
    "            ScalarMLP,\n",
    "            dict(field=EDGE_FEATURES, out_field=EDGE_SPIN, \n",
    "                 mlp_latent_dimensions = [], mlp_output_dimension=1),\n",
    "        ),\n",
    "        # Sum SEGNN energy sum\n",
    "        \"edge_eng_sum_TENN\": EdgewiseEnergySumTENN,\n",
    "        # Sum spins -> per-atom spins\n",
    "        \"edge_spin_sum\": EdgewiseSpinSum,\n",
    "        \n",
    "        # Sum system energy:\n",
    "        \"total_energy_sum\": (\n",
    "            AtomwiseReduceSpinGNNPlus,\n",
    "            dict(\n",
    "                reduce=\"sum\",\n",
    "                field_eng=AtomicDataDict.PER_ATOM_ENERGY_KEY,\n",
    "                field_BQ=PER_ATOM_ENERGY_BQ,\n",
    "                field_J=PER_ATOM_ENERGY_J,\n",
    "                field_A=PER_ATOM_ENERGY_A,\n",
    "                field_TENN=PER_ATOM_ENERGY_TENN,\n",
    "                out_field=AtomicDataDict.TOTAL_ENERGY_KEY,\n",
    "            ),\n",
    "        ),\n",
    "    }\n",
    "    #print(config[\"edge_eng\"])\n",
    "    model = SequentialGraphNetwork.from_parameters(shared_params=config, layers=layers)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c73a310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = AtomicData.to_AtomicDataDict(dataset[0])\n",
    "data0[AtomicDataDict.NODE_SPIN] = torch.randn_like(data0['pos'], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a16f88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_mkl",
   "language": "python",
   "name": "torch_mkl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
