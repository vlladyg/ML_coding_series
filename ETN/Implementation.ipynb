{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a6d35d75-0a83-48a3-97b3-07411515442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from e3nn.o3 import spherical_harmonics\n",
    "from e3nn.o3 import wigner_3j\n",
    "from torch import Tensor\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3d5682ec-579f-4e4f-a03e-d059270c5083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 100, 9])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = torch.randn((10, 100, 3))\n",
    "r_ang = r/torch.linalg.vector_norm(r, dim = -1).unsqueeze(-1)\n",
    "\n",
    "\n",
    "Y_1 = spherical_harmonics('0e', r_ang, normalize = 'component')\n",
    "Y_2 = spherical_harmonics('1o', r_ang, normalize = 'component')\n",
    "Y_3 = spherical_harmonics('2e', r_ang, normalize = 'component')\n",
    "\n",
    "features = torch.concatenate([Y_1, Y_2, Y_3], dim = -1)\n",
    "\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "84e0fda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 100, 1]), torch.Size([10, 100, 3]))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_1.shape, Y_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "84984a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 100, 3])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e1a4fccd-d3e3-4fda-bffc-b5c1bc82b095",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1, l2, l3 = 1, 2, 3\n",
    "m1, m2, m3 = l1, l2, l3 # m1 = 0, m2 = 0, m3 = 0\n",
    "C123 = wigner_3j(1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c5cc496a-9b93-4e74-85ba-ca1642e5d80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2928)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C123_000 = C123[m1, m2, m3]\n",
    "\n",
    "C123_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4598f711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 7])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C123.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "096e842c-9505-4fb0-a35e-5b989f732638",
   "metadata": {},
   "outputs": [],
   "source": [
    "class weigner_3j_img_to_real():\n",
    "\n",
    "\n",
    "    def __init__(self, l):\n",
    "        self.l = l\n",
    "\n",
    "    def __call__(self):\n",
    "        matrix = torch.zeros((2*self.l + 1, 2*self.l + 1), dtype = torch.complex64)\n",
    "\n",
    "        mult = 1\n",
    "        for i in range(2*self.l + 1):\n",
    "            \n",
    "            if i < self.l:\n",
    "                matrix[i, i] = 1.0j/2**(1/2.)\n",
    "                matrix[2*self.l + 1 - i - 1, i] = 1/2**(1/2.)\n",
    "            elif i == self.l:\n",
    "                matrix[i, i] = 1.\n",
    "            else:\n",
    "                matrix[i, i] = (-1.0)*mult/2**(1/2.)\n",
    "                matrix[2*self.l + 1 - i - 1, i] = (-1.0j)*mult/2**(1/2.)\n",
    "                mult *= -1\n",
    "        \n",
    "        return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5841bc65-2103-46f7-8b22-bac392e8a753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000+1.0000j,  0.0000+0.0000j,  0.0000-1.0000j],\n",
       "        [ 0.0000+0.0000j,  1.4142+0.0000j,  0.0000+0.0000j],\n",
       "        [ 1.0000+0.0000j,  0.0000+0.0000j, -1.0000+0.0000j]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weigner_3j_img_to_real(1)()*2**(1/2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "65b1c83c-fac0-47f7-8237-623ed87fd857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tri_ineq(l1, l2, l3):\n",
    "    #print(max([l1, l2, l3]), min([l1 + l2, l2 + l3, l1 + l3]))\n",
    "    return max([l1, l2, l3]) <= min([l1 + l2, l2 + l3, l1 + l3])\n",
    "\n",
    "class order_3_equvariant_tensor():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\" Basically transformation using\n",
    "            C (l1 l2 l3)\n",
    "              (m1 m2 m3)\"\"\"\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def __call__(self, l1, l2, l3, n1, n2, n3):\n",
    "        self.l1 = l1; self.l2 = l2; self.l3 = l3\n",
    "        self.n1 = n1; self.n2 = n2; self.n3 = n3\n",
    "        \n",
    "        weight = torch.zeros([n1, n2, n3])\n",
    "        if tri_ineq(l1, l2, l3):\n",
    "            W = nn.Parameter(nn.init.kaiming_uniform_(weight))\n",
    "            symbol_3j = wigner_3j(l1, l2, l3)\n",
    "            return symbol_3j.view(*symbol_3j.shape, 1, 1, 1)*W.view(1, 1, 1, *weight.shape)\n",
    "        else:\n",
    "            return torch.zeros((2*l1 + 1, 2*l2 + 1, 2*l3 + 1, n1, n2, n3))\n",
    "        \n",
    "        \n",
    "class order_2_equivariant_tensor():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Makes the 2nd order tensor in a way that\n",
    "           each lm is multiplied by coefficient c, no angular momentum mixing\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, l1, l2, n1, n2):\n",
    "        self.l1 = l1; self.l2 = l2\n",
    "        self.n1 = n1; self.n2 = n2\n",
    "        \n",
    "        weight = torch.zeros([n1, n2])\n",
    "        if l1 == l2: # same as tri_ineq(l1, l2, 0)\n",
    "            W = nn.Parameter(nn.init.kaiming_uniform_(weight))\n",
    "            return W.view(*weight.shape)\n",
    "        else:\n",
    "            return torch.zeros((n1, n2))\n",
    "\n",
    "        \n",
    "class order_1_equivariant_tensor():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Makes the 1nd order tensor in a way that\n",
    "           each lm is multiplied by coefficient c, no angular momentum mixing\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, l1, n1):\n",
    "        self.l1 = l1;\n",
    "        self.n1 = n1;\n",
    "        \n",
    "        weight = torch.zeros([n1])\n",
    "        W = nn.Parameter(nn.init.uniform(weight))\n",
    "        return torch.ones((2*l1 + 1, 1))*W.view(1, *weight.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b288318e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 10])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([3, 4])\n",
      "tensor(-11.5623, grad_fn=<SumBackward0>)\n",
      "torch.Size([3, 5, 7, 4, 6, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p2/mwhbpbfx4dx636dcf50t7_rr0000gn/T/ipykernel_1568/2437360665.py:61: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  W = nn.Parameter(nn.init.uniform(weight))\n"
     ]
    }
   ],
   "source": [
    "print(order_1_equivariant_tensor()(2, 3).shape)\n",
    "print(order_1_equivariant_tensor()(2, 10).shape)\n",
    "\n",
    "print(order_2_equivariant_tensor()(2, 2, 3, 4).shape)\n",
    "print(order_2_equivariant_tensor()(2, 2, 3, 4).shape)\n",
    "\n",
    "\n",
    "print(order_3_equvariant_tensor()(1, 2, 3, 4, 6, 8).sum())\n",
    "print(order_3_equvariant_tensor()(1, 2, 3, 4, 6, 8).shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6d574314",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmax = 3\n",
    "w3j_big = [[[wigner_3j(i, j, k) if tri_ineq(i, j, k) else None for i in range (lmax)] for j in range(lmax)] for k in range(lmax)]\n",
    "\n",
    "\n",
    "#len(w3j_big)/lmax**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ff3d5d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[tensor([[[1.]]]), None, None],\n",
       "  [None, tensor([[[0.5774],\n",
       "            [0.0000],\n",
       "            [0.0000]],\n",
       "   \n",
       "           [[0.0000],\n",
       "            [0.5774],\n",
       "            [0.0000]],\n",
       "   \n",
       "           [[0.0000],\n",
       "            [0.0000],\n",
       "            [0.5774]]]), None],\n",
       "  [None,\n",
       "   None,\n",
       "   tensor([[[0.4472],\n",
       "            [0.0000],\n",
       "            [0.0000],\n",
       "            [0.0000],\n",
       "            [0.0000]],\n",
       "   \n",
       "           [[0.0000],\n",
       "            [0.4472],\n",
       "            [0.0000],\n",
       "            [0.0000],\n",
       "            [0.0000]],\n",
       "   \n",
       "           [[0.0000],\n",
       "            [0.0000],\n",
       "            [0.4472],\n",
       "            [0.0000],\n",
       "            [0.0000]],\n",
       "   \n",
       "           [[0.0000],\n",
       "            [0.0000],\n",
       "            [0.0000],\n",
       "            [0.4472],\n",
       "            [0.0000]],\n",
       "   \n",
       "           [[0.0000],\n",
       "            [0.0000],\n",
       "            [0.0000],\n",
       "            [0.0000],\n",
       "            [0.4472]]])]],\n",
       " [[None,\n",
       "   tensor([[[0.5774, 0.0000, 0.0000]],\n",
       "   \n",
       "           [[0.0000, 0.5774, 0.0000]],\n",
       "   \n",
       "           [[0.0000, 0.0000, 0.5774]]]),\n",
       "   None],\n",
       "  [tensor([[[0.5774, 0.0000, 0.0000],\n",
       "            [0.0000, 0.5774, 0.0000],\n",
       "            [0.0000, 0.0000, 0.5774]]]),\n",
       "   tensor([[[ 0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.4082],\n",
       "            [ 0.0000, -0.4082,  0.0000]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000, -0.4082],\n",
       "            [ 0.0000,  0.0000,  0.0000],\n",
       "            [ 0.4082,  0.0000,  0.0000]],\n",
       "   \n",
       "           [[ 0.0000,  0.4082,  0.0000],\n",
       "            [-0.4082,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000]]]),\n",
       "   tensor([[[ 0.0000,  0.0000,  0.3162],\n",
       "            [ 0.0000,  0.0000,  0.0000],\n",
       "            [ 0.3162,  0.0000,  0.0000]],\n",
       "   \n",
       "           [[ 0.0000,  0.3162,  0.0000],\n",
       "            [ 0.3162,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000]],\n",
       "   \n",
       "           [[-0.1826,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.3651,  0.0000],\n",
       "            [ 0.0000,  0.0000, -0.1826]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.3162],\n",
       "            [ 0.0000,  0.3162,  0.0000]],\n",
       "   \n",
       "           [[-0.3162,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.3162]]])],\n",
       "  [None,\n",
       "   tensor([[[ 0.0000,  0.0000,  0.3162],\n",
       "            [ 0.0000,  0.3162,  0.0000],\n",
       "            [-0.1826,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000],\n",
       "            [-0.3162,  0.0000,  0.0000]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.0000],\n",
       "            [ 0.3162,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.3651,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.3162],\n",
       "            [ 0.0000,  0.0000,  0.0000]],\n",
       "   \n",
       "           [[ 0.3162,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000, -0.1826],\n",
       "            [ 0.0000,  0.3162,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.3162]]]),\n",
       "   tensor([[[ 0.0000,  0.0000,  0.0000],\n",
       "            [-0.1826,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.1826],\n",
       "            [ 0.0000, -0.3651,  0.0000]],\n",
       "   \n",
       "           [[ 0.1826,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.3162],\n",
       "            [ 0.0000, -0.1826,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.1826]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000, -0.3162],\n",
       "            [ 0.0000,  0.0000,  0.0000],\n",
       "            [ 0.3162,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000, -0.1826],\n",
       "            [ 0.0000,  0.1826,  0.0000],\n",
       "            [-0.3162,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000],\n",
       "            [ 0.1826,  0.0000,  0.0000]],\n",
       "   \n",
       "           [[ 0.0000,  0.3651,  0.0000],\n",
       "            [ 0.0000,  0.0000, -0.1826],\n",
       "            [ 0.0000,  0.0000,  0.0000],\n",
       "            [-0.1826,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000]]])]],\n",
       " [[None,\n",
       "   None,\n",
       "   tensor([[[0.4472, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "   \n",
       "           [[0.0000, 0.4472, 0.0000, 0.0000, 0.0000]],\n",
       "   \n",
       "           [[0.0000, 0.0000, 0.4472, 0.0000, 0.0000]],\n",
       "   \n",
       "           [[0.0000, 0.0000, 0.0000, 0.4472, 0.0000]],\n",
       "   \n",
       "           [[0.0000, 0.0000, 0.0000, 0.0000, 0.4472]]])],\n",
       "  [None,\n",
       "   tensor([[[ 0.0000,  0.0000, -0.1826,  0.0000, -0.3162],\n",
       "            [ 0.0000,  0.3162,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.3162,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "   \n",
       "           [[ 0.0000,  0.3162,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.3651,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.3162,  0.0000]],\n",
       "   \n",
       "           [[ 0.3162,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.3162,  0.0000],\n",
       "            [ 0.0000,  0.0000, -0.1826,  0.0000,  0.3162]]]),\n",
       "   tensor([[[ 0.0000,  0.1826,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.3651],\n",
       "            [ 0.0000,  0.0000,  0.0000, -0.1826,  0.0000]],\n",
       "   \n",
       "           [[-0.1826,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.1826,  0.0000],\n",
       "            [ 0.0000,  0.0000, -0.3162,  0.0000, -0.1826]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.0000, -0.3162,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.3162,  0.0000,  0.0000,  0.0000]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.3162,  0.0000, -0.1826],\n",
       "            [ 0.0000, -0.1826,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.1826,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.1826,  0.0000],\n",
       "            [-0.3651,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.1826,  0.0000,  0.0000,  0.0000]]])],\n",
       "  [tensor([[[0.4472, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.4472, 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.4472, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000, 0.4472, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000, 0.0000, 0.4472]]]),\n",
       "   tensor([[[ 0.0000, -0.1826,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.1826,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.3162,  0.0000],\n",
       "            [ 0.0000,  0.0000, -0.3162,  0.0000,  0.1826],\n",
       "            [ 0.0000,  0.0000,  0.0000, -0.1826,  0.0000]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.0000, -0.3651],\n",
       "            [ 0.0000,  0.0000,  0.0000, -0.1826,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.1826,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.3651,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.1826,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.3162,  0.0000,  0.1826],\n",
       "            [ 0.0000, -0.3162,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.1826,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000, -0.1826,  0.0000,  0.0000,  0.0000]]]),\n",
       "   tensor([[[ 0.0000,  0.0000, -0.2390,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.2070,  0.0000],\n",
       "            [-0.2390,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.2070,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.2070,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.1195,  0.0000, -0.2070],\n",
       "            [ 0.0000,  0.1195,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.2070,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000, -0.2070,  0.0000,  0.0000,  0.0000]],\n",
       "   \n",
       "           [[-0.2390,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.1195,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.2390,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.1195,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000, -0.2390]],\n",
       "   \n",
       "           [[ 0.0000,  0.2070,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.2070,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.1195,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.1195,  0.0000,  0.2070],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.2070,  0.0000]],\n",
       "   \n",
       "           [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000, -0.2070,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.0000, -0.2390],\n",
       "            [ 0.0000,  0.0000,  0.0000,  0.2070,  0.0000],\n",
       "            [ 0.0000,  0.0000, -0.2390,  0.0000,  0.0000]]])]]]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3j_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "223decbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250047"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9261*27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ccb3a36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_ineq(0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b8346b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 7])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C123.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdb0d2d",
   "metadata": {},
   "source": [
    "### Loading qm9 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "50ba7642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference example\n",
    "from nequip.data import dataset_from_config\n",
    "from nequip.utils import Config\n",
    "#from nequip.utils.misc import get_default_device_name\n",
    "#from nequip.utils.config import _GLOBAL_ALL_ASKED_FOR_KEYS\n",
    "\n",
    "from nequip.model import model_from_config\n",
    "\n",
    "\n",
    "default_config = dict(\n",
    "    root=\"./\",\n",
    "    tensorboard=False,\n",
    "    wandb=False,\n",
    "    model_builders=[\n",
    "        \"SimpleIrrepsConfig\",\n",
    "        \"EnergyModel\",\n",
    "        \"PerSpeciesRescale\",\n",
    "        \"StressForceOutput\",\n",
    "        \"RescaleEnergyEtc\",\n",
    "    ],\n",
    "    dataset_statistics_stride=1,\n",
    "    device='cuda',\n",
    "    default_dtype=\"float64\",\n",
    "    model_dtype=\"float32\",\n",
    "    allow_tf32=True,\n",
    "    verbose=\"INFO\",\n",
    "    model_debug_mode=False,\n",
    "    equivariance_test=False,\n",
    "    grad_anomaly_mode=False,\n",
    "    gpu_oom_offload=False,\n",
    "    append=False,\n",
    "    warn_unused=False,\n",
    "    _jit_bailout_depth=2,  # avoid 20 iters of pain, see https://github.com/pytorch/pytorch/issues/52286\n",
    "    # Quote from eelison in PyTorch slack:\n",
    "    # https://pytorch.slack.com/archives/CDZD1FANA/p1644259272007529?thread_ts=1644064449.039479&cid=CDZD1FANA\n",
    "    # > Right now the default behavior is to specialize twice on static shapes and then on dynamic shapes.\n",
    "    # > To reduce warmup time you can do something like setFusionStrartegy({{FusionBehavior::DYNAMIC, 3}})\n",
    "    # > ... Although we would wouldn't really expect to recompile a dynamic shape fusion in a model,\n",
    "    # > provided broadcasting patterns remain fixed\n",
    "    # We default to DYNAMIC alone because the number of edges is always dynamic,\n",
    "    # even if the number of atoms is fixed:\n",
    "    _jit_fusion_strategy=[(\"DYNAMIC\", 3)],\n",
    "    # Due to what appear to be ongoing bugs with nvFuser, we default to NNC (fuser1) for now:\n",
    "    # TODO: still default to NNC on CPU regardless even if change this for GPU\n",
    "    # TODO: default for ROCm?\n",
    "    _jit_fuser=\"fuser1\",\n",
    ")\n",
    "\n",
    "# All default_config keys are valid / requested\n",
    "#_GLOBAL_ALL_ASKED_FOR_KEYS.update(default_config.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d99679c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config.from_file('./configs/example_ETN.yaml', defaults=default_config)\n",
    "    \n",
    "\n",
    "dataset = dataset_from_config(config, prefix=\"dataset\")\n",
    "\n",
    "validation_dataset = None\n",
    "\n",
    "dataset.type_mapper.num_types\n",
    "\n",
    "config['num_types'] = dataset.type_mapper.num_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2e10fbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "from nequip.data import AtomicData, AtomicDataDict\n",
    "from torch.nn.functional import one_hot\n",
    "from e3nn.nn import FullyConnectedNet\n",
    "from allegro import with_edge_spin_length\n",
    "from allegro import _keys\n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "data = [AtomicData.to_AtomicDataDict(dataset[i]) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c2ec18ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bf29945a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([368, 1])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 2\n",
    "\n",
    "num_types = config['num_types']\n",
    "\n",
    "\n",
    "atom_types_embed = data[i]['atom_types'][data[i]['edge_index'][0]]*num_types + data[i]['atom_types'][data[i]['edge_index'][1]]\n",
    "\n",
    "atom_types_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9591ea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nequip.data import AtomicDataDict, AtomicDataset\n",
    "from nequip.nn.embedding import (\n",
    "    OneHotAtomEncoding,\n",
    "    SphericalHarmonicEdgeAttrs,\n",
    "    RadialBasisEdgeEncoding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b5935fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from e3nn import o3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b6c2c373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1x0ee+1x1oe+1x2ee"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o3.Irreps.spherical_harmonics(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3cad5833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([368, 8]) torch.Size([368, 9])\n"
     ]
    }
   ],
   "source": [
    "from nequip.data import AtomicDataDict, AtomicDataset\n",
    "from nequip.nn.embedding import (\n",
    "    OneHotAtomEncoding,\n",
    "    SphericalHarmonicEdgeAttrs,\n",
    "    RadialBasisEdgeEncoding,\n",
    ")\n",
    "from e3nn import o3\n",
    "\n",
    "L = 2\n",
    "\n",
    "irreps_edge_sh = o3.Irreps.spherical_harmonics(L)\n",
    "\n",
    "rbe = RadialBasisEdgeEncoding(basis_kwargs={'r_max': config['r_max'], \n",
    "                                            'num_basis': 8},\n",
    "                              cutoff_kwargs={'r_max': config['r_max']},\n",
    "                              out_field=AtomicDataDict.EDGE_EMBEDDING_KEY,\n",
    "                              )\n",
    "\n",
    "sh = SphericalHarmonicEdgeAttrs(irreps_edge_sh=irreps_edge_sh)\n",
    "\n",
    "data = [rbe(data[i]) for i in range(len(data))]\n",
    "\n",
    "data = [sh(data[i]) for i in range(len(data))]\n",
    "\n",
    "\n",
    "print(data[i]['edge_embedding'].shape, data[i]['edge_attrs'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f9efd0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['edge_index', 'pos', 'edge_cell_shift', 'total_energy', 'cell', 'pbc', 'forces', 'atom_types', 'edge_vectors', 'edge_lengths', 'edge_embedding', 'edge_cutoff', 'edge_attrs'])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbb5715",
   "metadata": {},
   "source": [
    "## Feature Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "910c7aac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 368]) torch.Size([368, 3, 4]) torch.Size([368, 9, 4])\n",
      "torch.Size([21, 9, 4])\n"
     ]
    }
   ],
   "source": [
    "from torch_runstats.scatter import scatter\n",
    "\n",
    "N_rad = 8\n",
    "\n",
    "N_spec_rank = 4\n",
    "N_rad_rank = 4\n",
    "\n",
    "Q = data[i]['edge_embedding']\n",
    "\n",
    "A = torch.randn(L + 1, N_spec_rank, num_types**2)\n",
    "B = torch.randn(L + 1, N_rad_rank, N_rad, N_spec_rank)\n",
    "\n",
    "\n",
    "a = A[:, :, atom_types_embed].squeeze(-1)\n",
    "\n",
    "b = torch.einsum('Lrnk,LkE,En->ELr', B, a, Q)\n",
    "\n",
    "Y = data[i]['edge_attrs']\n",
    "\n",
    "#print(data[i]['edge_attrs'][:, slices])\n",
    "F = torch.concat([torch.einsum('Em,En->Emn', Y[:, slices],\n",
    "                               b[:, l]) for l, slices in enumerate(irreps_edge_sh.slices())], dim = -2)\n",
    "\n",
    "print(a.shape, b.shape, F.shape)\n",
    "\n",
    "\n",
    "species = data[i][AtomicDataDict.ATOM_TYPE_KEY].squeeze(-1)\n",
    "edge_center = data[i][AtomicDataDict.EDGE_INDEX_KEY][0]\n",
    "edge_neighbor = data[i][AtomicDataDict.EDGE_INDEX_KEY][1]\n",
    "\n",
    "center_species = species[edge_center]\n",
    "neighbor_species = species[edge_neighbor]\n",
    "\n",
    "F = scatter(F, edge_center, dim=0, dim_size=len(species))\n",
    "\n",
    "print(F.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e317052e",
   "metadata": {},
   "source": [
    "### Order 2 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9cea8590",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = 4\n",
    "n2 = 32\n",
    "L1 = L2 = range(L + 1)\n",
    "\n",
    "u_in = F.clone()\n",
    "T_2 = [order_2_equivariant_tensor()(l, l, n1, n2) for l in L1]\n",
    "\n",
    "\n",
    "u_out = torch.zeros((u_in.shape[0], u_in.shape[1], n2))\n",
    "for i, slices in enumerate(irreps_edge_sh.slices()):\n",
    "    u_out[:, slices, :] = torch.einsum('ij,Nmi->Nmj', T_2[i], u_in[:, slices, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9901d2a",
   "metadata": {},
   "source": [
    "### Order 3 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "30d0a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n3 = 32\n",
    "L3 = range(L + 1)\n",
    "\n",
    "T_3 = [[[order_3_equvariant_tensor()(l3, l1, l2, n3, n1, n2) for l2 in L2] for l1 in L1] for l3 in L3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "61d10c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-23.5623, grad_fn=<MinBackward1>)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_in = u_out\n",
    "\n",
    "#T_2_tmp = torch.zeros((u_in.shape[0], u_in.shape[1], n2))\n",
    "\n",
    "T_2_tmp = [[None for l1 in L1] for l3 in L3]\n",
    "\n",
    "u_out = torch.zeros((u_in.shape[0], u_in.shape[1], n3))\n",
    "\n",
    "\n",
    "v = F.clone()\n",
    "for l2, slices in enumerate(irreps_edge_sh.slices()):\n",
    "    if l2 == 0:\n",
    "        for l3 in L3:\n",
    "            for l1 in L1:\n",
    "                T_2_tmp[l3][l1] = torch.einsum('abcijk,Nck->Nabij', T_3[l3][l1][l2], u_in[:, slices, :])\n",
    "    else:\n",
    "        for l3 in L3:\n",
    "            for l1 in L1:\n",
    "                T_2_tmp[l3][l1] += torch.einsum('abcijk,Nck->Nabij', T_3[l3][l1][l2], u_in[:, slices, :])\n",
    "    \n",
    "    \n",
    "for l3 in L3:    \n",
    "    for l1, slices in enumerate(irreps_edge_sh.slices()):\n",
    "        u_out[:, irreps_edge_sh.slices()[l3], :] += torch.einsum('Nabij,Nbj->Nai', T_2_tmp[l3][l1], v[:, slices, :])\n",
    "        \n",
    "        \n",
    "u_out.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3fc2cce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(19.3212, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_out.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "4cdd85c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 9, 32])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e6be116a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4326, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([ T_2[i][j].max() for i in [0, 1, 2] for j in [0, 1, 2] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4374b9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_2[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "85f0d658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 9, 32])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3033c5b8",
   "metadata": {},
   "source": [
    "### Equivariance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ebf78042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1x0ee+1x1oe+1x2ee\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0796)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([[1, 12, 34]]*10)\n",
    "\n",
    "edge_vec_plus = x / torch.linalg.norm(x, dim = 1).unsqueeze(-1)\n",
    "edge_vec_minus = -x / torch.linalg.norm(x, dim = 1).unsqueeze(-1)\n",
    "\n",
    "irreps_sh = o3.Irreps('1x0e + 1x1o + 1x2e') #o3.Irreps.spherical_harmonics(lmax=2)\n",
    "irreps_sh_r = o3.Irreps('1x1o')\n",
    "print(irreps_sh)\n",
    "\n",
    "\n",
    "alpha, beta, gamma = o3.rand_angles(100)\n",
    "\n",
    "rot_matrix = irreps_sh.D_from_angles(alpha[0], beta[0], gamma[0])\n",
    "rot_matrix_r = irreps_sh_r.D_from_angles(alpha[0], beta[0], gamma[0])\n",
    "\n",
    "\n",
    "sh_plus = o3.spherical_harmonics(irreps_sh, edge_vec_plus, normalize=True)\n",
    "\n",
    "sh_plus_of_rot =  o3.spherical_harmonics(irreps_sh, edge_vec_plus @ rot_matrix_r, \n",
    "                                        normalize=True)\n",
    "\n",
    "sh_plus_rot = o3.spherical_harmonics(irreps_sh, edge_vec_plus, \n",
    "                                        normalize=True) @ rot_matrix\n",
    "\n",
    "sh_plus_of_rot_rot = o3.spherical_harmonics(irreps_sh, edge_vec_plus @ rot_matrix_r, \n",
    "                                        normalize=True) @ rot_matrix.T\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sh_minus = o3.spherical_harmonics(irreps_sh, edge_vec_minus, normalize=True)\n",
    "# normalize=True ensure that x is divided by |x| before computing the sh\n",
    "\n",
    "sh_plus.pow(2).mean()  # should be close to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1585ddf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2821,  0.0076, -0.1719,  0.4573,  0.0159, -0.0060, -0.1983, -0.3597,\n",
       "         0.4784])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sh_plus_rot[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8f02e0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2821,  0.0135,  0.1626,  0.4606,  0.0286,  0.0101, -0.2107,  0.3426,\n",
      "         0.4850])\n",
      "tensor([ 0.2821,  0.0135,  0.1626,  0.4606,  0.0286,  0.0101, -0.2107,  0.3426,\n",
      "         0.4850])\n"
     ]
    }
   ],
   "source": [
    "print(sh_plus[0])\n",
    "\n",
    "print(sh_plus_of_rot_rot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f5912c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage_0(data, i):\n",
    "    \n",
    "\n",
    "    from nequip.data import AtomicDataDict, AtomicDataset\n",
    "    from nequip.nn.embedding import (\n",
    "        OneHotAtomEncoding,\n",
    "        SphericalHarmonicEdgeAttrs,\n",
    "        RadialBasisEdgeEncoding,\n",
    "    )\n",
    "    from e3nn import o3\n",
    "\n",
    "    \n",
    "    #torch.manual_seed(32)\n",
    "    \n",
    "    L = 2\n",
    "\n",
    "    irreps_edge_sh = o3.Irreps.spherical_harmonics(L)\n",
    "    print(irreps_edge_sh)\n",
    "    \n",
    "    rbe = RadialBasisEdgeEncoding(basis_kwargs={'r_max': config['r_max'], \n",
    "                                                'num_basis': 8},\n",
    "                                  cutoff_kwargs={'r_max': config['r_max']},\n",
    "                                  out_field=AtomicDataDict.EDGE_EMBEDDING_KEY,\n",
    "                                  )\n",
    "\n",
    "    sh = SphericalHarmonicEdgeAttrs(irreps_edge_sh=irreps_edge_sh)\n",
    "\n",
    "    data = [rbe(data[i]) for i in range(len(data))]\n",
    "\n",
    "    data = [sh(data[i]) for i in range(len(data))]\n",
    "\n",
    "\n",
    "    #print(data[i]['edge_embedding'].shape, data[i]['edge_attrs'].shape)\n",
    "    \n",
    "    \n",
    "    from torch_runstats.scatter import scatter\n",
    "\n",
    "    N_rad = 8\n",
    "\n",
    "    N_spec_rank = 4\n",
    "    N_rad_rank = 4\n",
    "\n",
    "    Q = data[i]['edge_embedding']\n",
    "\n",
    "    A = torch.randn(L + 1, N_spec_rank, num_types**2)\n",
    "    B = torch.randn(L + 1, N_rad_rank, N_rad, N_spec_rank)\n",
    "\n",
    "\n",
    "    a = A[:, :, atom_types_embed].squeeze(-1)\n",
    "\n",
    "    b = torch.einsum('Lrnk,LkE,En->ELr', B, a, Q)\n",
    "\n",
    "    #print(data[i]['pos'][2])\n",
    "    Y = data[i]['edge_attrs']\n",
    "    #print(Y[2])\n",
    "    #print(data[i]['edge_attrs'][:, slices])\n",
    "    F = torch.concat([torch.einsum('Em,En->Emn', Y[:, slices],\n",
    "                                   b[:, l]) for l, slices in enumerate(irreps_edge_sh.slices())], dim = -2)\n",
    "    \n",
    "    print(F[2, :, 0])\n",
    "    #F = Y.unsqueeze(-1)\n",
    "    #print(a.shape, b.shape, F.shape)\n",
    "\n",
    "\n",
    "    species = data[i][AtomicDataDict.ATOM_TYPE_KEY].squeeze(-1)\n",
    "    edge_center = data[i][AtomicDataDict.EDGE_INDEX_KEY][0]\n",
    "    edge_neighbor = data[i][AtomicDataDict.EDGE_INDEX_KEY][1]\n",
    "\n",
    "    center_species = species[edge_center]\n",
    "    neighbor_species = species[edge_neighbor]\n",
    "\n",
    "    F = scatter(F, edge_center, dim=0, dim_size=len(species))\n",
    "\n",
    "    #return F\n",
    "    \n",
    "    return data[i]['edge_attrs'].unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "65864472",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "from nequip.data import AtomicData, AtomicDataDict\n",
    "from torch.nn.functional import one_hot\n",
    "from e3nn.nn import FullyConnectedNet\n",
    "from allegro import with_edge_spin_length\n",
    "from allegro import _keys\n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "data = [AtomicData.to_AtomicDataDict(dataset[i]) for i in range(10)]\n",
    "\n",
    "\n",
    "import copy\n",
    "\n",
    "data_new = [{key: torch.clone(el[key]) for key in el} for el in data]\n",
    "\n",
    "irreps_sh = o3.Irreps('1x0e + 1x1o + 1x2e') #o3.Irreps.spherical_harmonics(lmax=2)\n",
    "irreps_sh_r = o3.Irreps('1x1o')\n",
    "\n",
    "alpha, beta, gamma = o3.rand_angles(100)\n",
    "\n",
    "rot_matrix = irreps_sh.D_from_angles(alpha[0], beta[0], gamma[0])\n",
    "rot_matrix_r = irreps_sh_r.D_from_angles(alpha[0], beta[0], gamma[0])\n",
    "\n",
    "\n",
    "for i, el in enumerate(data_new):\n",
    "    data_new[i]['pos'] = data_new[i]['pos'] @ rot_matrix_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b08f7af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edge_index': tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "           3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,\n",
       "           4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,\n",
       "           5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,\n",
       "           6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "           6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "           7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "           8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "           9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "          10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "          11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "          12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "          13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "          14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "          15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "          16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19,\n",
       "          19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20,\n",
       "          20, 20, 20, 20, 20, 20, 20, 20],\n",
       "         [ 9,  1,  2,  3,  4,  5,  6,  7,  8, 20, 11, 12, 13, 14, 15, 16, 17, 10,\n",
       "           7,  6,  5,  3,  2, 10,  4, 19, 15, 12, 13, 14, 16, 17, 18,  0,  9, 11,\n",
       "          20,  8,  8,  9,  1,  3,  5,  6, 17, 10, 11, 12, 13, 14,  7, 15,  0, 16,\n",
       "          16, 15, 14, 13, 12, 11,  9,  7,  6,  5,  4,  2,  1,  8, 10, 17,  0,  0,\n",
       "           9,  1,  5,  6,  7,  8, 10, 11, 12, 13, 15, 18, 19, 20,  3,  0,  9,  1,\n",
       "           2,  3,  4,  6,  7,  8, 10, 19, 11, 12, 13, 14, 15, 16, 20, 17, 18,  1,\n",
       "           0, 18, 17, 16, 15, 13, 12, 11, 19, 10,  8,  7,  5,  4,  3,  2,  9, 20,\n",
       "          14,  0,  9,  1,  2,  3,  4,  5,  6, 20,  8, 19, 11, 12, 13, 14, 15, 16,\n",
       "          10, 18,  9, 17,  1,  2,  3,  4,  5,  6,  7, 10, 19, 11, 12, 13, 14, 20,\n",
       "          15, 16, 18,  0, 18, 20, 16, 15, 14,  0, 12, 11, 19, 10, 13,  7,  6,  5,\n",
       "           4,  3,  2,  1,  8,  6,  5,  4,  3, 20,  1,  9,  7,  2,  8, 19, 18, 17,\n",
       "          16, 15,  0, 13, 12, 11, 14,  8,  1,  2,  3,  4,  5,  6,  7, 10, 15, 12,\n",
       "          13,  9, 17, 18,  0, 19, 20, 14,  8, 20,  9,  1,  2,  3,  4,  5, 18,  6,\n",
       "          17, 10, 19, 11, 13, 14,  7, 15,  0, 16, 15, 14, 12, 11, 19, 20,  9,  7,\n",
       "           6,  5,  4,  3,  2,  1,  8, 10, 18,  0,  0,  9,  1,  2,  3,  5,  6,  7,\n",
       "          10, 11, 12, 13, 15, 16, 17,  8,  0,  9,  1,  2,  3,  4,  5,  6,  7,  8,\n",
       "          10, 19, 11, 12, 13, 14, 16, 20, 17, 18,  1, 17, 15, 14, 12, 10,  8,  7,\n",
       "           6,  5,  3,  2,  9,  0,  0,  1,  2,  3,  5,  6,  8, 11, 12, 14, 15, 16,\n",
       "          10,  9,  1,  4,  5,  6,  7,  8, 10, 19, 11, 12, 13, 15, 20, 18, 20, 15,\n",
       "          13, 11, 10, 12,  7,  9,  8,  1,  4,  5,  6,  8,  4,  5,  6,  7,  1, 10,\n",
       "           0, 11, 12, 13, 15, 18,  9, 19]]),\n",
       " 'pos': tensor([[ 1.9154, -1.2302, -0.3816],\n",
       "         [ 0.9305,  0.9650, -1.7978],\n",
       "         [ 2.7054, -0.6370, -1.4384],\n",
       "         [ 2.1748,  0.3697, -2.1482],\n",
       "         [-2.8419,  1.7294,  0.6986],\n",
       "         [ 0.6455, -0.7562, -0.0252],\n",
       "         [ 0.1731,  0.3612, -0.8728],\n",
       "         [ 0.1703, -2.1059,  2.1038],\n",
       "         [-0.5276,  1.9325,  1.3262],\n",
       "         [-1.4904, -1.5085,  0.6270],\n",
       "         [-0.1907, -1.5261,  1.0662],\n",
       "         [-1.3820,  1.5618,  0.5864],\n",
       "         [-1.1038,  0.8720, -0.6164],\n",
       "         [-1.9576, -2.1665,  1.2322],\n",
       "         [ 2.3202, -2.0441,  0.2615],\n",
       "         [ 0.5343,  1.8654, -2.2618],\n",
       "         [ 3.7197, -0.9690, -1.6403],\n",
       "         [ 2.7620,  0.8259, -3.0011],\n",
       "         [-3.0542,  2.4442,  1.4588],\n",
       "         [-3.3211,  2.1190, -0.2630],\n",
       "         [-3.3397,  0.8074,  0.9594]]),\n",
       " 'edge_cell_shift': tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]),\n",
       " 'total_energy': tensor([-405699.8125]),\n",
       " 'cell': tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]),\n",
       " 'pbc': tensor([False, False, False]),\n",
       " 'forces': tensor([[  9.3356,  -4.9061,  20.7937],\n",
       "         [ 25.2673,   2.4576, -32.4000],\n",
       "         [ -3.6458, -46.8649,  46.0424],\n",
       "         [  0.9795,  66.0964, -52.2977],\n",
       "         [-30.6188,  19.7417, -37.5008],\n",
       "         [  6.8460,   4.4354, -19.4998],\n",
       "         [-44.7398, -34.7910,  93.4330],\n",
       "         [-10.8809,  35.0064, -67.2046],\n",
       "         [ 12.8598,   4.8943,  16.9048],\n",
       "         [ -3.1056, -34.1756,  36.3184],\n",
       "         [  9.3639,  -0.7578,   8.1105],\n",
       "         [ 20.5017, -25.9187, -45.1921],\n",
       "         [ -7.8607,   9.2037,   5.5482],\n",
       "         [ 14.5363,  26.6802, -19.0376],\n",
       "         [ -0.2574,   8.1569, -12.2573],\n",
       "         [  1.0795,   0.8474,  -7.7064],\n",
       "         [  2.9056,  -9.1715,  -1.0456],\n",
       "         [-12.3255,  -8.7166,  21.0747],\n",
       "         [ -4.5796,  20.5399,  24.2755],\n",
       "         [ 17.5557, -13.6330,  20.4886],\n",
       "         [ -3.2168, -19.1248,   1.1521]]),\n",
       " 'atom_types': tensor([[1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [1],\n",
       "         [1],\n",
       "         [2],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]])}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0b4bc72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1x0ee+1x1oe+1x2ee\n",
      "tensor([-0.4745, -0.2149, -0.1613,  0.2874, -0.4099,  0.2300, -0.1470, -0.3077,\n",
      "         0.1209], grad_fn=<SelectBackward0>)\n",
      "1x0ee+1x1oe+1x2ee\n",
      "tensor([-0.4563,  1.6473,  0.0662,  0.4577,  0.1852,  0.0268, -0.2067,  0.0074,\n",
      "        -0.3077], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "F = stage_0(data, 2)\n",
    "\n",
    "F_new = stage_0(data_new, 2)\n",
    "\n",
    "#F = data[2]['edge_attrs'].unsqueeze(-1)\n",
    "#F_new = data_new[2]['edge_attrs'].unsqueeze(-1)\n",
    "\n",
    "F_new_rot = torch.einsum('Njn,jk->Nkn', F_new, rot_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a0a722e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(F, F_new_rot, atol=1e-03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1315e1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000, -1.6557, -0.1353,  0.4903, -1.0481,  0.2892, -1.0976, -0.0857,\n",
       "        -1.6143])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "706870e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000, -1.6557, -0.1353,  0.4903, -1.0481,  0.2892, -1.0976, -0.0857,\n",
       "        -1.6143])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_new_rot[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "42f6446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage_1(F):\n",
    "    \n",
    "    #torch.manual_seed(32)\n",
    "    \n",
    "    n1 = 4\n",
    "    n2 = 32\n",
    "    L1 = L2 = range(L + 1)\n",
    "\n",
    "    u_in = F.clone()\n",
    "    T_2 = [order_2_equivariant_tensor()(l, l, n1, n2) for l in L1]\n",
    "\n",
    "\n",
    "    u_out = torch.zeros((u_in.shape[0], u_in.shape[1], n2))\n",
    "    for i, slices in enumerate(irreps_edge_sh.slices()):\n",
    "        u_out[:, slices, :] = torch.einsum('ij,Nmi->Nmj', T_2[i], u_in[:, slices, :])\n",
    "        \n",
    "    return u_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "18aefcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_out = stage_1(F)\n",
    "\n",
    "u_out_new = stage_1(F_new)\n",
    "\n",
    "u_out_new_rot = torch.einsum('Njn,jk->Nkn', u_out_new, rot_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9d5f76f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(u_out, u_out_new_rot, atol=1e-03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1889bfc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(3 - 2, 0, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "08375d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage_2(u_in, F):\n",
    "    \n",
    "    torch.manual_seed(32)\n",
    "    \n",
    "    n1 = 4\n",
    "    n2 = 32\n",
    "    L1 = L2 = range(L + 1)\n",
    "    \n",
    "    n3 = 32\n",
    "    L3 = range(L + 1)\n",
    "\n",
    "    T_3 = [[[order_3_equvariant_tensor()(l3, l1, l2, n3, n1, n2) for l2 in L2] for l1 in L1] for l3 in L3]\n",
    "\n",
    "    #T_2_tmp = torch.zeros((u_in.shape[0], u_in.shape[1], n2))\n",
    "\n",
    "    T_2_tmp = [[None for l1 in L1] for l3 in L3]\n",
    "\n",
    "    u_out = torch.zeros((u_in.shape[0], u_in.shape[1], n3))\n",
    "\n",
    "\n",
    "    v = F.clone()\n",
    "    for l2, slices in enumerate(irreps_edge_sh.slices()):\n",
    "        if l2 == 0:\n",
    "            for l3 in L3:\n",
    "                for l1 in L1:\n",
    "                    T_2_tmp[l3][l1] = torch.einsum('abcijk,Nck->Nabij', T_3[l3][l1][l2], u_in[:, slices, :])\n",
    "        else:\n",
    "            for l3 in L3:\n",
    "                for l1 in L1:\n",
    "                    T_2_tmp[l3][l1] += torch.einsum('abcijk,Nck->Nabij', T_3[l3][l1][l2], u_in[:, slices, :])\n",
    "\n",
    "\n",
    "    for l3 in L3:    \n",
    "        for l1, slices in enumerate(irreps_edge_sh.slices()):\n",
    "            u_out[:, irreps_edge_sh.slices()[l3], :] += torch.einsum('Nabij,Nbj->Nai', T_2_tmp[l3][l1], v[:, slices, :])\n",
    "\n",
    "            \n",
    "    return u_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c3d8fe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_out_2 = stage_2(u_out, F)\n",
    "\n",
    "u_out_2_new = stage_2(u_out_new, F_new)\n",
    "\n",
    "u_out_2_new_rot = torch.einsum('Njn,jk->Nkn', u_out_2_new, rot_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0e979ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(u_out_2, u_out_2_new_rot, atol=1e-03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a7b4a2",
   "metadata": {},
   "source": [
    "### Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "73216f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tri_ineq(l1, l2, l3):\n",
    "    #print(max([l1, l2, l3]), min([l1 + l2, l2 + l3, l1 + l3]))\n",
    "    return max([l1, l2, l3]) <= min([l1 + l2, l2 + l3, l1 + l3])\n",
    "\n",
    "class order_3_equvariant_tensor():\n",
    "    \n",
    "    def __init__(self, l1, l2, l3, n1, n2, n3):\n",
    "        \"\"\" Basically transformation using\n",
    "            C (l1 l2 l3)\n",
    "              (m1 m2 m3)\"\"\"\n",
    "        self.l1 = l1; self.l2 = l2; self.l3 = l3\n",
    "        self.n1 = n1; self.n2 = n2; self.n3 = n3\n",
    "    \n",
    "        weight = torch.zeros([n1, n2, n3])\n",
    "        self.weight = nn.Parameter(nn.init.kaiming_uniform_(weight))\n",
    "        \n",
    "        \n",
    "        self.symbol_3j = wigner_3j(l1, l2, l3)\n",
    "        \n",
    "        \n",
    "    def __call__(self):\n",
    "        \n",
    "        if tri_ineq(l1, l2, l3):\n",
    "            return self.symbol_3j.view(*symbol_3j.shape, 1, 1, 1)*self.weight.view(1, 1, 1, *weight.shape)\n",
    "        else:\n",
    "            return torch.zeros((2*l1 + 1, 2*l2 + 1, 2*l3 + 1, n1, n2, n3))\n",
    "        \n",
    "        \n",
    "def contract_2_tensors(tensor_1, tensor_2):\n",
    "    weight_new = (tensor_1.weight.flatten(end_dim = -2) @ tensor_2.weight.flatten(start_dim = 1)).view(tensor_1.n1, tensor_1.n2, tensor_2.n2,\n",
    "                                                                                                       tensor_2.n3)\n",
    "    \n",
    "    \n",
    "    return weight_new, tensor_1.symbol_3j, tensor_2.symbol_3j\n",
    "    \n",
    "        \n",
    "class order_2_equivariant_tensor():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Makes the 2nd order tensor in a way that\n",
    "           each lm is multiplied by coefficient c, no angular momentum mixing\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, l1, l2, n1, n2):\n",
    "        self.l1 = l1; self.l2 = l2\n",
    "        self.n1 = n1; self.n2 = n2\n",
    "        \n",
    "        weight = torch.zeros([n1, n2])\n",
    "        if l1 == l2: # same as tri_ineq(l1, l2, 0)\n",
    "            W = nn.Parameter(nn.init.kaiming_uniform_(weight))\n",
    "            return W.view(*weight.shape)\n",
    "        else:\n",
    "            return torch.zeros((n1, n2))\n",
    "\n",
    "        \n",
    "class order_1_equivariant_tensor():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Makes the 1nd order tensor in a way that\n",
    "           each lm is multiplied by coefficient c, no angular momentum mixing\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, l1, n1):\n",
    "        self.l1 = l1;\n",
    "        self.n1 = n1;\n",
    "        \n",
    "        weight = torch.zeros([n1])\n",
    "        W = nn.Parameter(nn.init.uniform(weight))\n",
    "        return torch.ones((2*l1 + 1, 1))*W.view(1, *weight.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a5ab629f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 8, 8])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_1 = order_3_equvariant_tensor(0, 0, 0, 4, 8, 32)\n",
    "tensor_2 = order_3_equvariant_tensor(0, 0, 0, 32, 8, 8)\n",
    "\n",
    "tensor_4th_order_weight = contract_2_tensors(tensor_1, tensor_2)[0]\n",
    "\n",
    "tensor_4th_order_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "af401041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([max([l1, l2, l3]) <= min([l1 + l2, l2 + l3, l1 + l3]) for l1 in range(10) for l2 in range(10) for l3 in range(10)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "id": "6d3f8929",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(32)\n",
    "\n",
    "class order_3_equvariant_tensor_free_params():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\" Basically transformation using\n",
    "            C (l1 l2 l3)\n",
    "              (m1 m2 m3)\"\"\"\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def __call__(self, l1, l2, l3, n1, n2, n3):\n",
    "        self.l1 = l1; self.l2 = l2; self.l3 = l3\n",
    "        self.n1 = n1; self.n2 = n2; self.n3 = n3\n",
    "        \n",
    "        weight = torch.zeros([n1, n2, n3])\n",
    "        if tri_ineq(l1, l2, l3):\n",
    "            nn.Parameter(nn.init.normal_(weight))\n",
    "            #symbol_3j = wigner_3j(l1, l2, l3)\n",
    "            return weight\n",
    "        else:\n",
    "            return torch.zeros((n1, n2, n3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "id": "f0c0f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(32)\n",
    "\n",
    "d = 5\n",
    "lmax = 2\n",
    "N_rank_ett = [4 for i in range(d-1)]\n",
    "Nc = [10]*d\n",
    "cores = [torch.zeros(lmax+1, N_rank_ett[i], lmax+1, Nc[i], lmax+1, N_rank_ett[i+1]) for i in range(d-2)]\n",
    "\n",
    "for dd in range(d-2):\n",
    "    for l1 in range(lmax + 1):\n",
    "        for l2 in range(lmax + 1):\n",
    "            for l3 in range(lmax + 1):\n",
    "                cores[dd][l1, :, l2, :, l3, :] = order_3_equvariant_tensor_free_params()(l1,l2,l3, N_rank_ett[dd], Nc[dd], N_rank_ett[dd+1])\n",
    "                \n",
    "cores0 = torch.zeros(lmax+1, Nc[0], lmax+1, N_rank_ett[0])\n",
    "coresd = torch.zeros(lmax+1, N_rank_ett[0], lmax+1, Nc[-1])\n",
    "\n",
    "for i in range(lmax + 1):\n",
    "    weight = torch.empty([Nc[0], N_rank_ett[0]])\n",
    "    nn.Parameter(nn.init.normal_(weight))\n",
    "    cores0[i, :, i, :] =  weight\n",
    "    \n",
    "    weight = torch.empty([N_rank_ett[-1], Nc[-1]])\n",
    "    nn.Parameter(nn.init.normal_(weight))\n",
    "    coresd[i, :, i, :] =  weight\n",
    "\n",
    "cores = [cores0] + cores + [coresd]\n",
    "\n",
    "N_rank_ett = [1] + N_rank_ett + [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "id": "d664d4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 784,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_rank_ett[d-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "id": "44aeef68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 4, 4, 4, 1]"
      ]
     },
     "execution_count": 785,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_rank_ett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "id": "04350117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 3, 10, 3, 4])\n",
      "4 4\n",
      "torch.Size([3, 4, 3, 10, 3, 4])\n",
      "4 4\n",
      "torch.Size([3, 4, 3, 10, 3, 4])\n",
      "4 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(d - 2, 0, -1):\n",
    "    print(cores[i].shape)\n",
    "    print(N_rank_ett[i], N_rank_ett[i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "id": "bc8fcba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage_0(data, i):\n",
    "    \n",
    "\n",
    "    from nequip.data import AtomicDataDict, AtomicDataset\n",
    "    from nequip.nn.embedding import (\n",
    "        OneHotAtomEncoding,\n",
    "        SphericalHarmonicEdgeAttrs,\n",
    "        RadialBasisEdgeEncoding,\n",
    "    )\n",
    "    from e3nn import o3\n",
    "\n",
    "    \n",
    "    torch.manual_seed(32)\n",
    "    \n",
    "    L = 2\n",
    "\n",
    "    irreps_edge_sh = o3.Irreps.spherical_harmonics(L, p = 1)\n",
    "    print(irreps_edge_sh)\n",
    "    \n",
    "    rbe = RadialBasisEdgeEncoding(basis_kwargs={'r_max': config['r_max'], \n",
    "                                                'num_basis': 8},\n",
    "                                  cutoff_kwargs={'r_max': config['r_max']},\n",
    "                                  out_field=AtomicDataDict.EDGE_EMBEDDING_KEY,\n",
    "                                  )\n",
    "\n",
    "    sh = SphericalHarmonicEdgeAttrs(irreps_edge_sh=irreps_edge_sh)\n",
    "\n",
    "    data = [rbe(data[i]) for i in range(len(data))]\n",
    "\n",
    "    data = [sh(data[i]) for i in range(len(data))]\n",
    "\n",
    "\n",
    "    #print(data[i]['edge_embedding'].shape, data[i]['edge_attrs'].shape)\n",
    "    \n",
    "    \n",
    "    from torch_runstats.scatter import scatter\n",
    "\n",
    "    N_rad = 8\n",
    "\n",
    "    N_spec_rank = 4\n",
    "    N_rad_rank = 4\n",
    "\n",
    "    Q = data[i]['edge_embedding']\n",
    "\n",
    "    A = torch.randn(L + 1, N_spec_rank, num_types**2)\n",
    "    B = torch.randn(L + 1, N_rad_rank, N_rad, N_spec_rank)\n",
    "\n",
    "\n",
    "    a = A[:, :, atom_types_embed].squeeze(-1)\n",
    "\n",
    "    b = torch.einsum('Lrnk,LkE,En->ELr', B, a, Q)\n",
    "\n",
    "    #print(data[i]['pos'][2])\n",
    "    Y = data[i]['edge_attrs']\n",
    "    #print(Y[2])\n",
    "    #print(data[i]['edge_attrs'][:, slices])\n",
    "    F = torch.concat([torch.einsum('Em,En->Emn', Y[:, slices],\n",
    "                                   b[:, l]) for l, slices in enumerate(irreps_edge_sh.slices())], dim = -2)\n",
    "    \n",
    "    #print(F[2, :, 0])\n",
    "    #F = Y.unsqueeze(-1)\n",
    "    #print(a.shape, b.shape, F.shape)\n",
    "\n",
    "\n",
    "    species = data[i][AtomicDataDict.ATOM_TYPE_KEY].squeeze(-1)\n",
    "    edge_center = data[i][AtomicDataDict.EDGE_INDEX_KEY][0]\n",
    "    edge_neighbor = data[i][AtomicDataDict.EDGE_INDEX_KEY][1]\n",
    "\n",
    "    center_species = species[edge_center]\n",
    "    neighbor_species = species[edge_neighbor]\n",
    "\n",
    "    F = scatter(F, edge_center, dim=0, dim_size=len(species))\n",
    "\n",
    "    #return F\n",
    "    \n",
    "    return data[i]['edge_attrs'].unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "id": "0fa2ae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from e3nn.o3 import wigner_3j\n",
    "\n",
    "def tri_ineq(l1, l2, l3):\n",
    "    #print(max([l1, l2, l3]), min([l1 + l2, l2 + l3, l1 + l3]))\n",
    "    return max([l1, l2, l3]) <= min([l1 + l2, l2 + l3, l1 + l3])\n",
    "\n",
    "\n",
    "def ETN(data, i, cores, ranks, Nc, lmax = 2):\n",
    "\n",
    "    torch.manual_seed(32)\n",
    "    \n",
    "    F = stage_0(data, i)\n",
    "    \n",
    "    # Init irreps\n",
    "    irreps_edge_sh = o3.Irreps.spherical_harmonics(lmax, p = 1)\n",
    "    slices = irreps_edge_sh.slices()\n",
    "    #Init w3j\n",
    "    w3j_big = [[[wigner_3j(l1, l2, l3) if tri_ineq(l1, l2, l3) else None for l3 in range (lmax+1)] for l2 in range(lmax+1)] for l1 in range(lmax+1)]\n",
    "    \n",
    "    \n",
    "    u_out = torch.zeros((F.shape[0], F.shape[1], ranks[-2]))\n",
    "    for i, slice in enumerate(slices):\n",
    "        u_out[:, slice, :] = torch.einsum('ij,Nmj->Nmi', cores[-1][i, :, i, :], F[:, slice, :])    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Series third order tensors\n",
    "    for i in range(d - 2, 0, -1):\n",
    "\n",
    "        # TODO: now define localy, mb define for all, to ensure computational graph\n",
    "        T_2_tmp = [[torch.zeros(F.shape[0], 2*l1+1, ranks[i], 2*l2+1, Nc[i], dtype=F.dtype, device=F.device) for l2 in range(lmax + 1)] for l1 in range(lmax + 1)] # result of first reduction of order 3 tensor\n",
    "\n",
    "        #print(i)\n",
    "        # First contraction with previous feature vector\n",
    "        for l1 in range(lmax + 1):\n",
    "            for l2 in range(lmax + 1):\n",
    "                for l3, slice in enumerate(slices):\n",
    "                    if tri_ineq(l1, l2, l3):\n",
    "                        #T_3 = self.w3j_big[l1][l2][l3][..., None, None, None] * self.cores3[i][(l1, l2, l3)][None, None, None, ...]\n",
    "                        T_2_tmp[l1][l2] += torch.einsum('abc,ijk,Nck->Naibj', w3j_big[l1][l2][l3], cores[i][l1, :, l2, :, l3, :], u_out[:, slice, :])\n",
    "\n",
    "\n",
    "       # Second contraction with F vector\n",
    "        u_out_new = torch.zeros((F.shape[0], F.shape[1], ranks[i]), dtype=F.dtype,\n",
    "                        device=F.device) # temporary verctor output of etn\n",
    "\n",
    "        for l1 in range(lmax + 1):    \n",
    "            for l2, slice in enumerate(slices):\n",
    "                u_out_new[:, slices[l1], :] += torch.einsum('Naibj,Nbj->Nai', T_2_tmp[l1][l2], F[:, slice, :])\n",
    "\n",
    "\n",
    "        u_out = u_out_new\n",
    "\n",
    "    \n",
    "    u_final = torch.zeros((F.shape[0], F.shape[1], Nc[0]))\n",
    "    for i, slices in enumerate(slices):\n",
    "        u_final[:, slices, :] = torch.einsum('ij,Nmj->Nmi', cores[0][i, :, i, :], u_out[:, slices, :])\n",
    "        \n",
    "    \n",
    "    \n",
    "    out = (( u_final * F ).sum(dim = (-2, -1) )).unsqueeze(-1)\n",
    "    \n",
    "    return u_final, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "id": "c8865fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1x0ee+1x1ee+1x2ee\n"
     ]
    }
   ],
   "source": [
    "u_final, out = ETN(data, 2, cores, N_rank_ett, Nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "id": "93fd0a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-17220.9043],\n",
       "        [-17220.9219],\n",
       "        [-17220.9277],\n",
       "        [-17220.9023],\n",
       "        [-17220.9336],\n",
       "        [-17220.9043],\n",
       "        [-17220.8926],\n",
       "        [-17220.9023],\n",
       "        [-17220.9219],\n",
       "        [-17220.9082],\n",
       "        [-17220.9219],\n",
       "        [-17220.8945],\n",
       "        [-17220.9238],\n",
       "        [-17220.9219],\n",
       "        [-17220.9258],\n",
       "        [-17220.8926],\n",
       "        [-17220.9023],\n",
       "        [-17220.9414],\n",
       "        [-17220.9180],\n",
       "        [-17220.9023],\n",
       "        [-17220.9004],\n",
       "        [-17220.9336],\n",
       "        [-17220.9160],\n",
       "        [-17220.9375],\n",
       "        [-17220.8984],\n",
       "        [-17220.9160],\n",
       "        [-17220.9434],\n",
       "        [-17220.9102],\n",
       "        [-17220.9023],\n",
       "        [-17220.9062],\n",
       "        [-17220.9355],\n",
       "        [-17220.9238],\n",
       "        [-17220.9102],\n",
       "        [-17220.9180],\n",
       "        [-17220.9258],\n",
       "        [-17220.9297],\n",
       "        [-17220.9180],\n",
       "        [-17220.9004],\n",
       "        [-17220.9141],\n",
       "        [-17220.9219],\n",
       "        [-17220.9180],\n",
       "        [-17220.9238],\n",
       "        [-17220.9062],\n",
       "        [-17220.9141],\n",
       "        [-17220.9316],\n",
       "        [-17220.9023],\n",
       "        [-17220.9355],\n",
       "        [-17220.9355],\n",
       "        [-17220.9297],\n",
       "        [-17220.9297],\n",
       "        [-17220.8926],\n",
       "        [-17220.9238],\n",
       "        [-17220.9258],\n",
       "        [-17220.9141],\n",
       "        [-17220.9219],\n",
       "        [-17220.9141],\n",
       "        [-17220.9023],\n",
       "        [-17220.9102],\n",
       "        [-17220.9297],\n",
       "        [-17220.8945],\n",
       "        [-17220.8711],\n",
       "        [-17220.9004],\n",
       "        [-17220.9258],\n",
       "        [-17220.9062],\n",
       "        [-17220.9199],\n",
       "        [-17220.9258],\n",
       "        [-17220.9297],\n",
       "        [-17220.9102],\n",
       "        [-17220.9062],\n",
       "        [-17220.8867],\n",
       "        [-17220.9141],\n",
       "        [-17220.9277],\n",
       "        [-17220.9336],\n",
       "        [-17220.8945],\n",
       "        [-17220.9258],\n",
       "        [-17220.9141],\n",
       "        [-17220.9258],\n",
       "        [-17220.9102],\n",
       "        [-17220.8945],\n",
       "        [-17220.9453],\n",
       "        [-17220.9141],\n",
       "        [-17220.9297],\n",
       "        [-17220.9277],\n",
       "        [-17220.9023],\n",
       "        [-17220.9121],\n",
       "        [-17220.9316],\n",
       "        [-17220.9258],\n",
       "        [-17220.9043],\n",
       "        [-17220.9082],\n",
       "        [-17220.8984],\n",
       "        [-17220.9062],\n",
       "        [-17220.9180],\n",
       "        [-17220.9062],\n",
       "        [-17220.9277],\n",
       "        [-17220.8906],\n",
       "        [-17220.9062],\n",
       "        [-17220.9062],\n",
       "        [-17220.8906],\n",
       "        [-17220.9199],\n",
       "        [-17220.9141],\n",
       "        [-17220.9414],\n",
       "        [-17220.9336],\n",
       "        [-17220.9219],\n",
       "        [-17220.9277],\n",
       "        [-17220.9180],\n",
       "        [-17220.9199],\n",
       "        [-17220.8867],\n",
       "        [-17220.9082],\n",
       "        [-17220.8926],\n",
       "        [-17220.8945],\n",
       "        [-17220.8984],\n",
       "        [-17220.9199],\n",
       "        [-17220.9258],\n",
       "        [-17220.9336],\n",
       "        [-17220.9336],\n",
       "        [-17220.9219],\n",
       "        [-17220.8965],\n",
       "        [-17220.9336],\n",
       "        [-17220.9023],\n",
       "        [-17220.8906],\n",
       "        [-17220.9277],\n",
       "        [-17220.9199],\n",
       "        [-17220.9141],\n",
       "        [-17220.9238],\n",
       "        [-17220.8867],\n",
       "        [-17220.9043],\n",
       "        [-17220.8867],\n",
       "        [-17220.9004],\n",
       "        [-17220.9375],\n",
       "        [-17220.9199],\n",
       "        [-17220.8711],\n",
       "        [-17220.8926],\n",
       "        [-17220.9199],\n",
       "        [-17220.8945],\n",
       "        [-17220.8945],\n",
       "        [-17220.9141],\n",
       "        [-17220.9375],\n",
       "        [-17220.9180],\n",
       "        [-17220.9414],\n",
       "        [-17220.9297],\n",
       "        [-17220.9316],\n",
       "        [-17220.9141],\n",
       "        [-17220.9219],\n",
       "        [-17220.9121],\n",
       "        [-17220.9336],\n",
       "        [-17220.9062],\n",
       "        [-17220.9258],\n",
       "        [-17220.9434],\n",
       "        [-17220.9043],\n",
       "        [-17220.9121],\n",
       "        [-17220.9023],\n",
       "        [-17220.9082],\n",
       "        [-17220.9102],\n",
       "        [-17220.8945],\n",
       "        [-17220.9453],\n",
       "        [-17220.9062],\n",
       "        [-17220.9043],\n",
       "        [-17220.9121],\n",
       "        [-17220.9062],\n",
       "        [-17220.8984],\n",
       "        [-17220.8945],\n",
       "        [-17220.9219],\n",
       "        [-17220.9121],\n",
       "        [-17220.9141],\n",
       "        [-17220.9062],\n",
       "        [-17220.9160],\n",
       "        [-17220.9160],\n",
       "        [-17220.9180],\n",
       "        [-17220.9336],\n",
       "        [-17220.9258],\n",
       "        [-17220.9062],\n",
       "        [-17220.9023],\n",
       "        [-17220.9258],\n",
       "        [-17220.9121],\n",
       "        [-17220.9219],\n",
       "        [-17220.9141],\n",
       "        [-17220.9062],\n",
       "        [-17220.9316],\n",
       "        [-17220.8926],\n",
       "        [-17220.9121],\n",
       "        [-17220.9238],\n",
       "        [-17220.8906],\n",
       "        [-17220.9141],\n",
       "        [-17220.9258],\n",
       "        [-17220.9219],\n",
       "        [-17220.9219],\n",
       "        [-17220.9141],\n",
       "        [-17220.8926],\n",
       "        [-17220.9219],\n",
       "        [-17220.9082],\n",
       "        [-17220.9336],\n",
       "        [-17220.9121],\n",
       "        [-17220.9219],\n",
       "        [-17220.9062],\n",
       "        [-17220.8945],\n",
       "        [-17220.9258],\n",
       "        [-17220.9102],\n",
       "        [-17220.9219],\n",
       "        [-17220.9043],\n",
       "        [-17220.9219],\n",
       "        [-17220.9277],\n",
       "        [-17220.8965],\n",
       "        [-17220.9082],\n",
       "        [-17220.8945],\n",
       "        [-17220.9355],\n",
       "        [-17220.9121],\n",
       "        [-17220.9258],\n",
       "        [-17220.9414],\n",
       "        [-17220.9023],\n",
       "        [-17220.9414],\n",
       "        [-17220.9199],\n",
       "        [-17220.9336],\n",
       "        [-17220.9473],\n",
       "        [-17220.9102],\n",
       "        [-17220.8965],\n",
       "        [-17220.9297],\n",
       "        [-17220.8984],\n",
       "        [-17220.9023],\n",
       "        [-17220.9023],\n",
       "        [-17220.9414],\n",
       "        [-17220.9238],\n",
       "        [-17220.9219],\n",
       "        [-17220.8965],\n",
       "        [-17220.9219],\n",
       "        [-17220.9023],\n",
       "        [-17220.9336],\n",
       "        [-17220.9219],\n",
       "        [-17220.9180],\n",
       "        [-17220.9238],\n",
       "        [-17220.9277],\n",
       "        [-17220.9141],\n",
       "        [-17220.9160],\n",
       "        [-17220.9199],\n",
       "        [-17220.9297],\n",
       "        [-17220.9297],\n",
       "        [-17220.9102],\n",
       "        [-17220.9277],\n",
       "        [-17220.9141],\n",
       "        [-17220.9121],\n",
       "        [-17220.8867],\n",
       "        [-17220.9258],\n",
       "        [-17220.9121],\n",
       "        [-17220.9180],\n",
       "        [-17220.9121],\n",
       "        [-17220.9141],\n",
       "        [-17220.9180],\n",
       "        [-17220.9102],\n",
       "        [-17220.9043],\n",
       "        [-17220.8691],\n",
       "        [-17220.9023],\n",
       "        [-17220.9004],\n",
       "        [-17220.9414],\n",
       "        [-17220.9258],\n",
       "        [-17220.9414],\n",
       "        [-17220.9219],\n",
       "        [-17220.9316],\n",
       "        [-17220.9141],\n",
       "        [-17220.9023],\n",
       "        [-17220.8867],\n",
       "        [-17220.9004],\n",
       "        [-17220.9023],\n",
       "        [-17220.9180],\n",
       "        [-17220.9062],\n",
       "        [-17220.9102],\n",
       "        [-17220.9082],\n",
       "        [-17220.9277],\n",
       "        [-17220.8926],\n",
       "        [-17220.9336],\n",
       "        [-17220.8906],\n",
       "        [-17220.9180],\n",
       "        [-17220.9434],\n",
       "        [-17220.9277],\n",
       "        [-17220.8984],\n",
       "        [-17220.9141],\n",
       "        [-17220.9316],\n",
       "        [-17220.8906],\n",
       "        [-17220.9062],\n",
       "        [-17220.9062],\n",
       "        [-17220.9258],\n",
       "        [-17220.9297],\n",
       "        [-17220.9395],\n",
       "        [-17220.9277],\n",
       "        [-17220.9121],\n",
       "        [-17220.9258],\n",
       "        [-17220.9141],\n",
       "        [-17220.9102],\n",
       "        [-17220.9219],\n",
       "        [-17220.9062],\n",
       "        [-17220.9297],\n",
       "        [-17220.9277],\n",
       "        [-17220.8945],\n",
       "        [-17220.9121],\n",
       "        [-17220.9141],\n",
       "        [-17220.9395],\n",
       "        [-17220.9004],\n",
       "        [-17220.8848],\n",
       "        [-17220.9160],\n",
       "        [-17220.9258],\n",
       "        [-17220.9355],\n",
       "        [-17220.9102],\n",
       "        [-17220.8984],\n",
       "        [-17220.8906],\n",
       "        [-17220.9102],\n",
       "        [-17220.9082],\n",
       "        [-17220.9082],\n",
       "        [-17220.9121],\n",
       "        [-17220.9141],\n",
       "        [-17220.9238],\n",
       "        [-17220.9180],\n",
       "        [-17220.9258],\n",
       "        [-17220.9512],\n",
       "        [-17220.8945],\n",
       "        [-17220.9180],\n",
       "        [-17220.9336],\n",
       "        [-17220.9375],\n",
       "        [-17220.8887],\n",
       "        [-17220.9180],\n",
       "        [-17220.9023],\n",
       "        [-17220.9336],\n",
       "        [-17220.9062],\n",
       "        [-17220.9258],\n",
       "        [-17220.9141],\n",
       "        [-17220.9102],\n",
       "        [-17220.9043],\n",
       "        [-17220.9180],\n",
       "        [-17220.9023],\n",
       "        [-17220.9102],\n",
       "        [-17220.8984],\n",
       "        [-17220.8945],\n",
       "        [-17220.8945],\n",
       "        [-17220.9102],\n",
       "        [-17220.9121],\n",
       "        [-17220.9102],\n",
       "        [-17220.9297],\n",
       "        [-17220.9375],\n",
       "        [-17220.9180],\n",
       "        [-17220.9004],\n",
       "        [-17220.9277],\n",
       "        [-17220.9141],\n",
       "        [-17220.9219],\n",
       "        [-17220.9160],\n",
       "        [-17220.9316],\n",
       "        [-17220.8926],\n",
       "        [-17220.9199],\n",
       "        [-17220.9219],\n",
       "        [-17220.9336],\n",
       "        [-17220.9258],\n",
       "        [-17220.9180],\n",
       "        [-17220.9219],\n",
       "        [-17220.9160],\n",
       "        [-17220.9043],\n",
       "        [-17220.8867],\n",
       "        [-17220.8984],\n",
       "        [-17220.9180],\n",
       "        [-17220.9219],\n",
       "        [-17220.9219],\n",
       "        [-17220.9141],\n",
       "        [-17220.9023],\n",
       "        [-17220.9160],\n",
       "        [-17220.9141],\n",
       "        [-17220.8906],\n",
       "        [-17220.8926],\n",
       "        [-17220.9297],\n",
       "        [-17220.9219],\n",
       "        [-17220.8867],\n",
       "        [-17220.9082],\n",
       "        [-17220.9141],\n",
       "        [-17220.9121]])"
      ]
     },
     "execution_count": 790,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "id": "1b1e0174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as tn\n",
    "\n",
    "def QR(mat):\n",
    "    \"\"\"\n",
    "    Compute the QR decomposition. Backend can be changed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mat : tn array\n",
    "        DESCRIPTION.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Q : the Q matrix\n",
    "    R : the R matrix\n",
    "\n",
    "    \"\"\"\n",
    "    Q,R = tn.linalg.qr(mat)\n",
    "    return Q, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "id": "86a15830",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(32)\n",
    "\n",
    "\n",
    "d = 5\n",
    "lmax = 2\n",
    "N_rank_ett = [4 for i in range(d-1)]\n",
    "Nc = [10]*d\n",
    "cores = [torch.zeros(lmax+1, N_rank_ett[i], lmax+1, Nc[i], lmax+1, N_rank_ett[i+1]) for i in range(d-2)]\n",
    "\n",
    "for dd in range(d-2):\n",
    "    for l1 in range(lmax + 1):\n",
    "        for l2 in range(lmax + 1):\n",
    "            for l3 in range(lmax + 1):\n",
    "                cores[dd][l1, :, l2, :, l3, :] = order_3_equvariant_tensor_free_params()(l1,l2,l3, N_rank_ett[dd], Nc[dd], N_rank_ett[dd+1])\n",
    "\n",
    "                \n",
    "#for dd in range(d-3):\n",
    "#    cores_cur_tmp = cores[dd].flatten(0, -3)\n",
    "#    cores_next_tmp = cores[dd+1].flatten(2)\n",
    "    \n",
    "#    for l in range(lmax + 1):\n",
    "#        Q, R = QR(cores_cur_tmp[:, l, :])\n",
    "#        cores[dd][..., l, :] = Q.reshape(cores[dd][..., l, :].shape)#/(2*l + 1)\n",
    "#        cores[dd+1][l] = (R @ cores_next_tmp[l]).reshape(cores[dd + 1][l].shape)#/(2*l + 1)\n",
    "                \n",
    "cores0 = torch.zeros(lmax+1, Nc[0], lmax+1, N_rank_ett[0])\n",
    "coresd = torch.zeros(lmax+1, N_rank_ett[0], lmax+1, Nc[-1])\n",
    "\n",
    "\n",
    "for i in range(lmax + 1):\n",
    "    weight = torch.empty([Nc[0], N_rank_ett[0]])\n",
    "    nn.Parameter(nn.init.normal_(weight))\n",
    "    cores0[i, :, i, :] =  weight\n",
    "    \n",
    "    weight = torch.empty([N_rank_ett[-1], Nc[-1]])\n",
    "    nn.Parameter(nn.init.normal_(weight))\n",
    "    coresd[i, :, i, :] =  weight\n",
    "\n",
    "cores = [cores0] + cores + [coresd]\n",
    "\n",
    "N_rank_ett = [1] + N_rank_ett + [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "id": "3efa784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ortho_simple(cores):\n",
    "    \"\"\"Simple orthogonalization for cores\n",
    "       works like in the paper\"\"\"\n",
    "    \n",
    "    d = len(cores)\n",
    "    lmax = cores[0].shape[0] - 1\n",
    "    \n",
    "    # Core 0\n",
    "    cores_cur_tmp = cores[0]\n",
    "    cores_next_tmp = cores[1].flatten(2)\n",
    "    \n",
    "    for l in range(lmax + 1):\n",
    "        Q, R = QR(cores_cur_tmp[l, :, l, :])\n",
    "        cores[0][l, :, l, :] = Q.reshape(cores[0][l, :, l, :].shape)#/(2*l + 1)\n",
    "        cores[1][l] = (R @ cores_next_tmp[l]).reshape(cores[1][l].shape)#/(2*l + 1)\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Cores triple\n",
    "    for dd in range(1, d-2):\n",
    "        cores_cur_tmp = cores[dd].flatten(0, -3)\n",
    "        cores_next_tmp = cores[dd+1].flatten(2)\n",
    "\n",
    "        for l in range(lmax + 1):\n",
    "            Q, R = QR(cores_cur_tmp[:, l, :])\n",
    "            cores[dd][..., l, :] = Q.reshape(cores[dd][..., l, :].shape)#/(2*l + 1)\n",
    "            cores[dd+1][l] = (R @ cores_next_tmp[l]).reshape(cores[dd + 1][l].shape)#/(2*l + 1)\n",
    "   \n",
    "\n",
    "    # Core d\n",
    "    cores_cur_tmp = cores[-2].flatten(0, -3)\n",
    "    cores_next_tmp = cores[-1]\n",
    "    \n",
    "    for l in range(lmax + 1):\n",
    "        Q, R = QR(cores_cur_tmp[:, l, :])\n",
    "        cores[-2][..., l, :] = Q.reshape(cores[-2][..., l, :].shape)#/(2*l + 1)\n",
    "        cores[-1][l, :, l, :] = (R @ cores_next_tmp[l, :, l, :]).reshape(cores[-1][l, :, l, :].shape)#/(2*l + 1)\n",
    "    \n",
    "    return cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "57b508a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = ortho_simple(cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "id": "a0549d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00,  3.7253e-09,  1.4901e-08, -7.4506e-09],\n",
       "        [ 3.7253e-09,  1.0000e+00, -1.8626e-09,  2.2352e-08],\n",
       "        [ 1.4901e-08, -1.8626e-09,  1.0000e+00, -3.7253e-09],\n",
       "        [-7.4506e-09,  2.2352e-08, -3.7253e-09,  1.0000e+00]])"
      ]
     },
     "execution_count": 795,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cores[3].flatten(0, -3)[:, 2].T @ cores[3].flatten(0, -3)[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "f5b98963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1x0ee+1x1ee+1x2ee\n"
     ]
    }
   ],
   "source": [
    "u_final_new, out_new = ETN(data, 2, cores, N_rank_ett, Nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "id": "89c25ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(out, out_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "id": "c62822c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 803,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_final[1, :, 0] / u_final_new[1, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af54ad5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "8b3e2397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(u_final, u_final_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "id": "fd50fb8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-6337296.5000)"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "id": "905afe66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-6337292.5000)"
      ]
     },
     "execution_count": 806,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_new.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "id": "cbd4c385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-17220.9023]), tensor([-17220.9043]))"
      ]
     },
     "execution_count": 807,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_new[0], out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "86afa722",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(32)\n",
    "\n",
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "from nequip.data import AtomicData, AtomicDataDict\n",
    "from torch.nn.functional import one_hot\n",
    "from e3nn.nn import FullyConnectedNet\n",
    "from allegro import with_edge_spin_length\n",
    "from allegro import _keys\n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "data = [AtomicData.to_AtomicDataDict(dataset[i]) for i in range(10)]\n",
    "\n",
    "\n",
    "import copy\n",
    "\n",
    "data_new = [{key: torch.clone(el[key]) for key in el} for el in data]\n",
    "\n",
    "irreps_sh = o3.Irreps.spherical_harmonics(lmax=2, p = 1)\n",
    "irreps_sh_r = o3.Irreps('1x1o')\n",
    "\n",
    "alpha, beta, gamma = o3.rand_angles(100)\n",
    "\n",
    "rot_matrix = irreps_sh.D_from_angles(alpha[0], beta[0], gamma[0])\n",
    "rot_matrix_r = irreps_sh_r.D_from_angles(alpha[0], beta[0], gamma[0])\n",
    "\n",
    "\n",
    "for i, el in enumerate(data_new):\n",
    "    data_new[i]['pos'] = data_new[i]['pos'] @ rot_matrix_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "f641352c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1x0ee+1x1ee+1x2ee\n"
     ]
    }
   ],
   "source": [
    "u_final_rot, out_new_rot = ETN(data_new, 2, cores, N_rank_ett, Nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "87478502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-17220.9258],\n",
       "        [-17220.9023],\n",
       "        [-17220.9062],\n",
       "        [-17220.9160],\n",
       "        [-17220.8984],\n",
       "        [-17220.8984],\n",
       "        [-17220.9023],\n",
       "        [-17220.8965],\n",
       "        [-17220.9043],\n",
       "        [-17220.9297],\n",
       "        [-17220.9141],\n",
       "        [-17220.9297],\n",
       "        [-17220.9258],\n",
       "        [-17220.9023],\n",
       "        [-17220.9277],\n",
       "        [-17220.8867],\n",
       "        [-17220.9238],\n",
       "        [-17220.9004],\n",
       "        [-17220.9082],\n",
       "        [-17220.9258],\n",
       "        [-17220.9102],\n",
       "        [-17220.9004],\n",
       "        [-17220.9082],\n",
       "        [-17220.9023],\n",
       "        [-17220.9336],\n",
       "        [-17220.8867],\n",
       "        [-17220.9258],\n",
       "        [-17220.9023],\n",
       "        [-17220.8984],\n",
       "        [-17220.9102],\n",
       "        [-17220.9453],\n",
       "        [-17220.8984],\n",
       "        [-17220.9277],\n",
       "        [-17220.9121],\n",
       "        [-17220.9336],\n",
       "        [-17220.9316],\n",
       "        [-17220.9023],\n",
       "        [-17220.9336],\n",
       "        [-17220.9219],\n",
       "        [-17220.9043],\n",
       "        [-17220.8984],\n",
       "        [-17220.9062],\n",
       "        [-17220.8867],\n",
       "        [-17220.9160],\n",
       "        [-17220.8867],\n",
       "        [-17220.8945],\n",
       "        [-17220.8984],\n",
       "        [-17220.9219],\n",
       "        [-17220.9062],\n",
       "        [-17220.9258],\n",
       "        [-17220.9121],\n",
       "        [-17220.9199],\n",
       "        [-17220.9199],\n",
       "        [-17220.8926],\n",
       "        [-17220.9023],\n",
       "        [-17220.9043],\n",
       "        [-17220.9297],\n",
       "        [-17220.9102],\n",
       "        [-17220.9023],\n",
       "        [-17220.9219],\n",
       "        [-17220.8906],\n",
       "        [-17220.9102],\n",
       "        [-17220.9082],\n",
       "        [-17220.9219],\n",
       "        [-17220.9141],\n",
       "        [-17220.8984],\n",
       "        [-17220.8945],\n",
       "        [-17220.9258],\n",
       "        [-17220.9004],\n",
       "        [-17220.9062],\n",
       "        [-17220.9160],\n",
       "        [-17220.8867],\n",
       "        [-17220.9277],\n",
       "        [-17220.9336],\n",
       "        [-17220.9336],\n",
       "        [-17220.9102],\n",
       "        [-17220.9004],\n",
       "        [-17220.9062],\n",
       "        [-17220.9238],\n",
       "        [-17220.9121],\n",
       "        [-17220.9180],\n",
       "        [-17220.9414],\n",
       "        [-17220.8672],\n",
       "        [-17220.9121],\n",
       "        [-17220.8867],\n",
       "        [-17220.9121],\n",
       "        [-17220.9160],\n",
       "        [-17220.8906],\n",
       "        [-17220.9414],\n",
       "        [-17220.9219],\n",
       "        [-17220.9102],\n",
       "        [-17220.9219],\n",
       "        [-17220.9297],\n",
       "        [-17220.9121],\n",
       "        [-17220.9141],\n",
       "        [-17220.9238],\n",
       "        [-17220.9043],\n",
       "        [-17220.9199],\n",
       "        [-17220.8887],\n",
       "        [-17220.9316],\n",
       "        [-17220.9102],\n",
       "        [-17220.9355],\n",
       "        [-17220.9219],\n",
       "        [-17220.9062],\n",
       "        [-17220.9199],\n",
       "        [-17220.9180],\n",
       "        [-17220.9160],\n",
       "        [-17220.9258],\n",
       "        [-17220.8945],\n",
       "        [-17220.9219],\n",
       "        [-17220.9395],\n",
       "        [-17220.9277],\n",
       "        [-17220.9102],\n",
       "        [-17220.9062],\n",
       "        [-17220.8984],\n",
       "        [-17220.8984],\n",
       "        [-17220.9180],\n",
       "        [-17220.9180],\n",
       "        [-17220.9141],\n",
       "        [-17220.9297],\n",
       "        [-17220.9062],\n",
       "        [-17220.9219],\n",
       "        [-17220.9180],\n",
       "        [-17220.9160],\n",
       "        [-17220.9453],\n",
       "        [-17220.9258],\n",
       "        [-17220.9062],\n",
       "        [-17220.8984],\n",
       "        [-17220.8984],\n",
       "        [-17220.9102],\n",
       "        [-17220.9258],\n",
       "        [-17220.9062],\n",
       "        [-17220.8945],\n",
       "        [-17220.9102],\n",
       "        [-17220.9336],\n",
       "        [-17220.9082],\n",
       "        [-17220.8906],\n",
       "        [-17220.8945],\n",
       "        [-17220.8809],\n",
       "        [-17220.9355],\n",
       "        [-17220.9102],\n",
       "        [-17220.9062],\n",
       "        [-17220.9102],\n",
       "        [-17220.8945],\n",
       "        [-17220.9102],\n",
       "        [-17220.9102],\n",
       "        [-17220.9004],\n",
       "        [-17220.9141],\n",
       "        [-17220.9258],\n",
       "        [-17220.9277],\n",
       "        [-17220.9199],\n",
       "        [-17220.9043],\n",
       "        [-17220.9180],\n",
       "        [-17220.9004],\n",
       "        [-17220.8945],\n",
       "        [-17220.9336],\n",
       "        [-17220.9004],\n",
       "        [-17220.9160],\n",
       "        [-17220.9375],\n",
       "        [-17220.9121],\n",
       "        [-17220.9141],\n",
       "        [-17220.9082],\n",
       "        [-17220.9004],\n",
       "        [-17220.8906],\n",
       "        [-17220.9062],\n",
       "        [-17220.9141],\n",
       "        [-17220.9180],\n",
       "        [-17220.8809],\n",
       "        [-17220.9121],\n",
       "        [-17220.8965],\n",
       "        [-17220.8984],\n",
       "        [-17220.9258],\n",
       "        [-17220.9023],\n",
       "        [-17220.9062],\n",
       "        [-17220.9102],\n",
       "        [-17220.8965],\n",
       "        [-17220.8848],\n",
       "        [-17220.8984],\n",
       "        [-17220.9531],\n",
       "        [-17220.9453],\n",
       "        [-17220.9180],\n",
       "        [-17220.8906],\n",
       "        [-17220.9102],\n",
       "        [-17220.9277],\n",
       "        [-17220.9121],\n",
       "        [-17220.9043],\n",
       "        [-17220.9121],\n",
       "        [-17220.9180],\n",
       "        [-17220.9062],\n",
       "        [-17220.9062],\n",
       "        [-17220.8945],\n",
       "        [-17220.9023],\n",
       "        [-17220.9102],\n",
       "        [-17220.8984],\n",
       "        [-17220.9219],\n",
       "        [-17220.9062],\n",
       "        [-17220.9336],\n",
       "        [-17220.9141],\n",
       "        [-17220.9062],\n",
       "        [-17220.9316],\n",
       "        [-17220.9043],\n",
       "        [-17220.9082],\n",
       "        [-17220.9219],\n",
       "        [-17220.9160],\n",
       "        [-17220.8848],\n",
       "        [-17220.9180],\n",
       "        [-17220.9160],\n",
       "        [-17220.9062],\n",
       "        [-17220.9258],\n",
       "        [-17220.9219],\n",
       "        [-17220.8926],\n",
       "        [-17220.8906],\n",
       "        [-17220.8633],\n",
       "        [-17220.9199],\n",
       "        [-17220.9238],\n",
       "        [-17220.9121],\n",
       "        [-17220.9258],\n",
       "        [-17220.9004],\n",
       "        [-17220.9062],\n",
       "        [-17220.8984],\n",
       "        [-17220.9062],\n",
       "        [-17220.9023],\n",
       "        [-17220.8965],\n",
       "        [-17220.9043],\n",
       "        [-17220.9316],\n",
       "        [-17220.9297],\n",
       "        [-17220.8945],\n",
       "        [-17220.8945],\n",
       "        [-17220.9297],\n",
       "        [-17220.9141],\n",
       "        [-17220.9141],\n",
       "        [-17220.9258],\n",
       "        [-17220.9238],\n",
       "        [-17220.9062],\n",
       "        [-17220.8945],\n",
       "        [-17220.9297],\n",
       "        [-17220.9121],\n",
       "        [-17220.9062],\n",
       "        [-17220.9082],\n",
       "        [-17220.9297],\n",
       "        [-17220.9277],\n",
       "        [-17220.9238],\n",
       "        [-17220.9277],\n",
       "        [-17220.9180],\n",
       "        [-17220.9238],\n",
       "        [-17220.8945],\n",
       "        [-17220.9102],\n",
       "        [-17220.9277],\n",
       "        [-17220.9102],\n",
       "        [-17220.9199],\n",
       "        [-17220.8965],\n",
       "        [-17220.9160],\n",
       "        [-17220.9102],\n",
       "        [-17220.9102],\n",
       "        [-17220.9297],\n",
       "        [-17220.9102],\n",
       "        [-17220.9043],\n",
       "        [-17220.9102],\n",
       "        [-17220.9141],\n",
       "        [-17220.9121],\n",
       "        [-17220.9160],\n",
       "        [-17220.9160],\n",
       "        [-17220.8848],\n",
       "        [-17220.9062],\n",
       "        [-17220.9102],\n",
       "        [-17220.9297],\n",
       "        [-17220.9297],\n",
       "        [-17220.9375],\n",
       "        [-17220.9082],\n",
       "        [-17220.9062],\n",
       "        [-17220.9023],\n",
       "        [-17220.9180],\n",
       "        [-17220.9316],\n",
       "        [-17220.8906],\n",
       "        [-17220.9258],\n",
       "        [-17220.9180],\n",
       "        [-17220.8984],\n",
       "        [-17220.9102],\n",
       "        [-17220.9082],\n",
       "        [-17220.8926],\n",
       "        [-17220.9219],\n",
       "        [-17220.9219],\n",
       "        [-17220.9062],\n",
       "        [-17220.8828],\n",
       "        [-17220.9238],\n",
       "        [-17220.9023],\n",
       "        [-17220.9102],\n",
       "        [-17220.8867],\n",
       "        [-17220.9219],\n",
       "        [-17220.9082],\n",
       "        [-17220.9355],\n",
       "        [-17220.9141],\n",
       "        [-17220.9141],\n",
       "        [-17220.9258],\n",
       "        [-17220.9238],\n",
       "        [-17220.8887],\n",
       "        [-17220.9121],\n",
       "        [-17220.9141],\n",
       "        [-17220.9277],\n",
       "        [-17220.8906],\n",
       "        [-17220.9160],\n",
       "        [-17220.9219],\n",
       "        [-17220.9082],\n",
       "        [-17220.9199],\n",
       "        [-17220.8906],\n",
       "        [-17220.9102],\n",
       "        [-17220.9238],\n",
       "        [-17220.8984],\n",
       "        [-17220.9102],\n",
       "        [-17220.8906],\n",
       "        [-17220.9004],\n",
       "        [-17220.8828],\n",
       "        [-17220.9160],\n",
       "        [-17220.9023],\n",
       "        [-17220.8828],\n",
       "        [-17220.9141],\n",
       "        [-17220.8984],\n",
       "        [-17220.9297],\n",
       "        [-17220.9141],\n",
       "        [-17220.9141],\n",
       "        [-17220.8906],\n",
       "        [-17220.8984],\n",
       "        [-17220.9199],\n",
       "        [-17220.8965],\n",
       "        [-17220.9102],\n",
       "        [-17220.9082],\n",
       "        [-17220.9199],\n",
       "        [-17220.9023],\n",
       "        [-17220.9141],\n",
       "        [-17220.9141],\n",
       "        [-17220.9102],\n",
       "        [-17220.8965],\n",
       "        [-17220.9219],\n",
       "        [-17220.9023],\n",
       "        [-17220.8867],\n",
       "        [-17220.9297],\n",
       "        [-17220.9062],\n",
       "        [-17220.9102],\n",
       "        [-17220.9199],\n",
       "        [-17220.9199],\n",
       "        [-17220.9023],\n",
       "        [-17220.9141],\n",
       "        [-17220.9062],\n",
       "        [-17220.9004],\n",
       "        [-17220.9023],\n",
       "        [-17220.9180],\n",
       "        [-17220.9023],\n",
       "        [-17220.9219],\n",
       "        [-17220.9180],\n",
       "        [-17220.9062],\n",
       "        [-17220.9004],\n",
       "        [-17220.9102],\n",
       "        [-17220.9219],\n",
       "        [-17220.9023],\n",
       "        [-17220.9023],\n",
       "        [-17220.9180],\n",
       "        [-17220.9297],\n",
       "        [-17220.9062],\n",
       "        [-17220.8867],\n",
       "        [-17220.9023],\n",
       "        [-17220.9043],\n",
       "        [-17220.8926],\n",
       "        [-17220.9238],\n",
       "        [-17220.9180],\n",
       "        [-17220.8887],\n",
       "        [-17220.9121],\n",
       "        [-17220.8867],\n",
       "        [-17220.9062]])"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_new_rot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "1a8b37c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-6337295.), tensor(-6337295.))"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_new.sum(), out_new_rot.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "8e0f44f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(out_new_rot, out_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "412ce99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  227.6372,  3350.7109, -7468.5576,  4818.2109,    34.0287,   -52.7466,\n",
       "           46.9218,   -75.8481,    12.6338])"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_final[1, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "d64d2db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  227.6365, -1593.0637, -8149.4727,  4611.9434,   -15.4862,    27.3645,\n",
       "           66.3346,   -79.2211,    19.7419])"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_final_rot[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "a9d53b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETN_out_rot_rot = torch.einsum('Njn,jk->Nkn', u_final_rot, rot_matrix.T) # rotated ETN out features from rotated positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "3b969b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(ETN_out_rot_rot, u_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "3ae1c084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  227.6384,  3350.7002, -7468.5659,  4818.1924,    34.0282,   -52.7467,\n",
       "           46.9226,   -75.8486,    12.6338])"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ETN_out_rot_rot[1, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "04a72ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "L1 = range(3)\n",
    "L2 = range(3)\n",
    "L3 = range(3)\n",
    "\n",
    "instr = []\n",
    "for l3, l1, l2 in product(L3, L1, L2):\n",
    "    if tri_ineq(l1, l2, l3):\n",
    "        instr.append((l1, l2, l3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "3445b7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(instr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "d6734373",
   "metadata": {},
   "outputs": [],
   "source": [
    "irreps_edge_sh = o3.Irreps.spherical_harmonics(2, p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "deed6aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1x0ee+1x1ee+1x2ee\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, List, Tuple\n",
    "\n",
    "# Assume irreps does not change \n",
    "print(irreps_edge_sh)\n",
    "base_in1 = o3.Irreps([el[1] for el in irreps_edge_sh])\n",
    "base_in2 = o3.Irreps([el[1] for el in irreps_edge_sh])\n",
    "base_out = o3.Irreps([el[1] for el in irreps_edge_sh])\n",
    "\n",
    "\n",
    "# Building instructions\n",
    "instructions: List[Tuple[int, int, int]] = []\n",
    "tmp_i_out: int = 0\n",
    "for i_out, (_, ir_out) in enumerate(base_out):\n",
    "    for i_1, (_, ir_in1) in enumerate(base_in1):\n",
    "        for i_2, (_, ir_in2) in enumerate(base_in2):\n",
    "            if ir_out in ir_in1 * ir_in2:\n",
    "                instructions.append((i_1, i_2, i_out))\n",
    "\n",
    "                tmp_i_out += 1\n",
    "                \n",
    "                \n",
    "instructions_1 = [(0, l, l) for l in range(irreps_edge_sh.lmax + 1)]\n",
    "instructions_d = [(l, l, 0) for l in range(irreps_edge_sh.lmax + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "dd63fc18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions == instr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "id": "c6224373",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(40)\n",
    "\n",
    "from torch.nn import Parameter, ParameterList\n",
    "\n",
    "d = 5\n",
    "lmax = 2\n",
    "N_rank_ett = [4 for i in range(d-1)]\n",
    "Nc = [10]*d\n",
    "\n",
    "instruction_list = [instructions_1] + [instructions for i in range(d - 2)] + [instructions_d]\n",
    "\n",
    "num_paths = len(instr)\n",
    "\n",
    "cores = [torch.zeros(lmax+1, N_rank_ett[i], lmax+1, Nc[i], lmax+1, N_rank_ett[i+1]) for i in range(d-2)]\n",
    "\n",
    "cores0 = Parameter(torch.empty(lmax+1, 1, Nc[0], N_rank_ett[0]).normal_())\n",
    "coresd = Parameter(torch.empty(lmax+1, N_rank_ett[-1], Nc[-1], 1).normal_())\n",
    "\n",
    "cores = ParameterList([cores0] \n",
    "                      + [Parameter(torch.empty(num_paths, N_rank_ett[r], Nc[r+1], N_rank_ett[r+1]).normal_()) for r in range(d - 2)] \n",
    "                      + [coresd]) \n",
    "\n",
    "N_rank_ett = [1] + N_rank_ett + [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "id": "3d1ad927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dense(cores_old, instruction_list):\n",
    "    \"\"\"Converts the path matrix to dense format \n",
    "       indexed as l1, :,l2, :, l3, :\"\"\"\n",
    "    \n",
    "    lmax = cores_old[0].shape[0] - 1\n",
    "    d = len(cores_old)\n",
    "    \n",
    "    cores0 = torch.zeros(lmax + 1, cores_old[0].shape[2], \n",
    "                         lmax + 1, cores_old[0].shape[-1])\n",
    "    \n",
    "    coresd = torch.zeros(lmax + 1, cores_old[-1].shape[1],\n",
    "                         lmax + 1, cores_old[-1].shape[2])\n",
    "\n",
    "    for i in range(lmax + 1):\n",
    "        cores0[i, :, i, :] =  cores_old[0][i, 0]\n",
    "\n",
    "        coresd[i, :, i, :] =  cores_old[-1][i, :, :, 0]\n",
    "    \n",
    "    cores = [torch.zeros(lmax+1, cores_old[i+1].shape[1], \n",
    "                         lmax+1, cores_old[i+1].shape[2],\n",
    "                         lmax+1, cores_old[i+1].shape[3]) for i in range(d-2)]\n",
    "\n",
    "    for dd in range(d-2):\n",
    "        for i, (l1, l2, l3) in enumerate(instruction_list[dd + 1]):\n",
    "            cores[dd][l1, :, l2, :, l3, :] = cores_old[dd + 1][i]\n",
    "    \n",
    "    cores = [cores0] + cores + [coresd] \n",
    "    return cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "id": "3515ea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from e3nn.o3 import wigner_3j\n",
    "\n",
    "def tri_ineq(l1, l2, l3):\n",
    "    #print(max([l1, l2, l3]), min([l1 + l2, l2 + l3, l1 + l3]))\n",
    "    return max([l1, l2, l3]) <= min([l1 + l2, l2 + l3, l1 + l3])\n",
    "\n",
    "\n",
    "def ETN(data, i, cores, ranks, Nc, instruction_list, lmax = 2):\n",
    "\n",
    "    torch.manual_seed(40)\n",
    "    \n",
    "    F = stage_0(data, i)\n",
    "    \n",
    "    print(F[10, :, 0])\n",
    "    # Init irreps\n",
    "    irreps_edge_sh = o3.Irreps.spherical_harmonics(lmax, p = 1)\n",
    "    slices = irreps_edge_sh.slices()\n",
    "    #Init w3j\n",
    "    w3j_big = [[[wigner_3j(l1, l2, l3) if tri_ineq(l1, l2, l3) else None for l3 in range (lmax+1)] for l2 in range(lmax+1)] for l1 in range(lmax+1)]\n",
    "    \n",
    "    cores = convert_to_dense(cores, instruction_list)\n",
    "    \n",
    "    u_out = torch.zeros((F.shape[0], F.shape[1], ranks[-2]))\n",
    "    for i, slice in enumerate(slices):\n",
    "        u_out[:, slice, :] = torch.einsum('ij,Nmj->Nmi', cores[-1][i, :, i, :], F[:, slice, :])    \n",
    "    \n",
    "    \n",
    "    # Series third order tensors\n",
    "    for i in range(d - 2, 0, -1):\n",
    "\n",
    "        # TODO: now define localy, mb define for all, to ensure computational graph\n",
    "        T_2_tmp = [[torch.zeros(F.shape[0], 2*l1+1, ranks[i], 2*l2+1, Nc[i], dtype=F.dtype, device=F.device) for l2 in range(lmax + 1)] for l1 in range(lmax + 1)] # result of first reduction of order 3 tensor\n",
    "\n",
    "        #print(i)\n",
    "        # First contraction with previous feature vector\n",
    "        for l1 in range(lmax + 1):\n",
    "            for l2 in range(lmax + 1):\n",
    "                for l3, slice in enumerate(slices):\n",
    "                    if tri_ineq(l1, l2, l3):\n",
    "                        #T_3 = self.w3j_big[l1][l2][l3][..., None, None, None] * self.cores3[i][(l1, l2, l3)][None, None, None, ...]\n",
    "                        T_2_tmp[l1][l2] += torch.einsum('abc,ijk,Nck->Naibj', w3j_big[l1][l2][l3], cores[i][l1, :, l2, :, l3, :], u_out[:, slice, :])\n",
    "\n",
    "\n",
    "       # Second contraction with F vector\n",
    "        u_out_new = torch.zeros((F.shape[0], F.shape[1], ranks[i]), dtype=F.dtype,\n",
    "                        device=F.device) # temporary verctor output of etn\n",
    "\n",
    "        for l1 in range(lmax + 1):    \n",
    "            for l2, slice in enumerate(slices):\n",
    "                u_out_new[:, slices[l1], :] += torch.einsum('Naibj,Nbj->Nai', T_2_tmp[l1][l2], F[:, slice, :])\n",
    "\n",
    "\n",
    "        u_out = u_out_new\n",
    "\n",
    "    \n",
    "    u_final = torch.zeros((F.shape[0], F.shape[1], Nc[0]))\n",
    "    for i, slices in enumerate(slices):\n",
    "        u_final[:, slices, :] = torch.einsum('ij,Nmj->Nmi', cores[0][i, :, i, :], u_out[:, slices, :])\n",
    "        \n",
    "    \n",
    "    \n",
    "    out = (( u_final * F ).sum(dim = (-2, -1) )).unsqueeze(-1)\n",
    "    \n",
    "    return u_final, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "id": "ca6d0195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1x0ee+1x1ee+1x2ee\n",
      "tensor([ 1.0000, -1.2899,  1.0922,  0.3787, -0.6306, -1.8187,  0.2156,  0.5339,\n",
      "        -0.9814])\n"
     ]
    }
   ],
   "source": [
    "u_final, out = ETN(data, 2, cores, N_rank_ett, Nc, instruction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "id": "3fc16227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-548798.9375, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "80cecf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from allegro import lr_orthogonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "id": "23e3233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cores, _ = lr_orthogonal(cores, N_rank_ett, instruction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "503c1cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(list(map(lambda a, b: torch.allclose(a, b), cores_new_new, cores_new)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "id": "e345364f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1x0ee+1x1ee+1x2ee\n",
      "tensor([ 1.0000, -1.2899,  1.0922,  0.3787, -0.6306, -1.8187,  0.2156,  0.5339,\n",
      "        -0.9814])\n"
     ]
    }
   ],
   "source": [
    "u_final_ortho, out_ortho = ETN(data, 2, cores, N_rank_ett, Nc, instruction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "id": "c3884777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-548793., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_ortho.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "id": "825fcbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1491.3076], grad_fn=<SelectBackward0>),\n",
       " tensor([-1491.2832], grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0], out_ortho[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "id": "1cc54992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5111.2969,  4467.6646, -3891.8503,  5520.1807,  6226.9316,  1672.3468,\n",
       "        -4797.0845,  5222.7334, -4501.8105, -5394.5918],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_final_ortho[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "id": "d3dfeca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5111.2969,  4467.6636, -3891.8525,  5520.1831,  6226.9321,  1672.3439,\n",
       "        -4797.0864,  5222.7334, -4501.8081, -5394.5894],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_final[0, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0727d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_mkl",
   "language": "python",
   "name": "torch_mkl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
