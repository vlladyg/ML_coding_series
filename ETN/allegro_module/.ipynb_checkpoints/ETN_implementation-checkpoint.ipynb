{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "263721c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference example\n",
    "from nequip.data import dataset_from_config\n",
    "from nequip.utils import Config\n",
    "#from nequip.utils.misc import get_default_device_name\n",
    "#from nequip.utils.config import _GLOBAL_ALL_ASKED_FOR_KEYS\n",
    "\n",
    "from nequip.model import model_from_config\n",
    "\n",
    "\n",
    "default_config = dict(\n",
    "    root=\"./\",\n",
    "    tensorboard=False,\n",
    "    wandb=False,\n",
    "    model_builders=[\n",
    "        \"SimpleIrrepsConfig\",\n",
    "        \"EnergyModel\",\n",
    "        \"PerSpeciesRescale\",\n",
    "        \"StressForceOutput\",\n",
    "        \"RescaleEnergyEtc\",\n",
    "    ],\n",
    "    dataset_statistics_stride=1,\n",
    "    device='cuda',\n",
    "    default_dtype=\"float64\",\n",
    "    model_dtype=\"float32\",\n",
    "    allow_tf32=True,\n",
    "    verbose=\"INFO\",\n",
    "    model_debug_mode=False,\n",
    "    equivariance_test=False,\n",
    "    grad_anomaly_mode=False,\n",
    "    gpu_oom_offload=False,\n",
    "    append=False,\n",
    "    warn_unused=False,\n",
    "    _jit_bailout_depth=2,  # avoid 20 iters of pain, see https://github.com/pytorch/pytorch/issues/52286\n",
    "    # Quote from eelison in PyTorch slack:\n",
    "    # https://pytorch.slack.com/archives/CDZD1FANA/p1644259272007529?thread_ts=1644064449.039479&cid=CDZD1FANA\n",
    "    # > Right now the default behavior is to specialize twice on static shapes and then on dynamic shapes.\n",
    "    # > To reduce warmup time you can do something like setFusionStrartegy({{FusionBehavior::DYNAMIC, 3}})\n",
    "    # > ... Although we would wouldn't really expect to recompile a dynamic shape fusion in a model,\n",
    "    # > provided broadcasting patterns remain fixed\n",
    "    # We default to DYNAMIC alone because the number of edges is always dynamic,\n",
    "    # even if the number of atoms is fixed:\n",
    "    _jit_fusion_strategy=[(\"DYNAMIC\", 3)],\n",
    "    # Due to what appear to be ongoing bugs with nvFuser, we default to NNC (fuser1) for now:\n",
    "    # TODO: still default to NNC on CPU regardless even if change this for GPU\n",
    "    # TODO: default for ROCm?\n",
    "    _jit_fuser=\"fuser1\",\n",
    ")\n",
    "\n",
    "# All default_config keys are valid / requested\n",
    "#_GLOBAL_ALL_ASKED_FOR_KEYS.update(default_config.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80c5ce97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtomicData(atom_types=[21, 1], cell=[3, 3], edge_cell_shift=[364, 3], edge_index=[2, 364], forces=[21, 3], pbc=[3], pos=[21, 3], total_energy=[1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config.from_file('./configs/example_ETN.yaml', defaults=default_config)\n",
    "    \n",
    "\n",
    "dataset = dataset_from_config(config, prefix=\"dataset\")\n",
    "\n",
    "validation_dataset = None\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fb86723",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:* Initialize Output\n",
      "  ...generate file name results/aspirin/example/log\n",
      "  ...open log file results/aspirin/example/log\n",
      "  ...generate file name results/aspirin/example/metrics_epoch.csv\n",
      "  ...open log file results/aspirin/example/metrics_epoch.csv\n",
      "  ...generate file name results/aspirin/example/metrics_initialization.csv\n",
      "  ...open log file results/aspirin/example/metrics_initialization.csv\n",
      "  ...generate file name results/aspirin/example/metrics_batch_train.csv\n",
      "  ...open log file results/aspirin/example/metrics_batch_train.csv\n",
      "  ...generate file name results/aspirin/example/metrics_batch_val.csv\n",
      "  ...open log file results/aspirin/example/metrics_batch_val.csv\n",
      "  ...generate file name results/aspirin/example/best_model.pth\n",
      "  ...generate file name results/aspirin/example/last_model.pth\n",
      "  ...generate file name results/aspirin/example/trainer.pth\n",
      "  ...generate file name results/aspirin/example/config.yaml\n",
      "Torch device: cuda\n",
      "instantiate Loss\n",
      "...Loss_param = dict(\n",
      "...   optional_args = {'coeff_schedule': 'constant'},\n",
      "...   positional_args = {'coeffs': {'forces': 1.0, 'total_energy': [1.0, 'PerAtomMSELoss']}})\n",
      "instantiate MSELoss\n",
      "...MSELoss_param = dict(\n",
      "...   optional_args = {'size_average': None, 'reduce': None},\n",
      "...   positional_args = {'reduction': 'none'})\n",
      " parsing forces 1.0\n",
      " parsing 1.0 MSELoss\n",
      "instantiate MSELoss\n",
      "...MSELoss_param = dict(\n",
      "...   optional_args = {'size_average': None, 'reduce': None},\n",
      "...   positional_args = {'reduction': 'none'})\n",
      " parsing total_energy [1.0, 'PerAtomMSELoss']\n",
      " parsing 1.0 PerAtomMSELoss\n",
      "create loss instance <class 'nequip.train._loss.PerAtomLoss'>\n",
      "instantiate MSELoss\n",
      "...MSELoss_param = dict(\n",
      "...   optional_args = {'size_average': None, 'reduce': None},\n",
      "...   positional_args = {'reduction': 'none'})\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (_ETN.py, line 90)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/torch_mkl/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3577\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[3], line 17\u001b[0m\n    final_model = model_from_config(\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/torch_mkl/lib/python3.10/site-packages/nequip/model/_build.py:88\u001b[0m in \u001b[1;35mmodel_from_config\u001b[0m\n    builders = [\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/torch_mkl/lib/python3.10/site-packages/nequip/model/_build.py:89\u001b[0m in \u001b[1;35m<listcomp>\u001b[0m\n    load_callable(b, prefix=\"nequip.model\")\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/torch_mkl/lib/python3.10/site-packages/nequip/utils/savenload.py:302\u001b[0m in \u001b[1;35mload_callable\u001b[0m\n    obj = yaml.load(f\"!!python/name:{obj}\", Loader=yaml.Loader)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/torch_mkl/lib/python3.10/site-packages/yaml/__init__.py:81\u001b[0m in \u001b[1;35mload\u001b[0m\n    return loader.get_single_data()\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/torch_mkl/lib/python3.10/site-packages/yaml/constructor.py:51\u001b[0m in \u001b[1;35mget_single_data\u001b[0m\n    return self.construct_document(node)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/torch_mkl/lib/python3.10/site-packages/yaml/constructor.py:55\u001b[0m in \u001b[1;35mconstruct_document\u001b[0m\n    data = self.construct_object(node)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/torch_mkl/lib/python3.10/site-packages/yaml/constructor.py:102\u001b[0m in \u001b[1;35mconstruct_object\u001b[0m\n    data = constructor(self, tag_suffix, node)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/torch_mkl/lib/python3.10/site-packages/yaml/constructor.py:570\u001b[0m in \u001b[1;35mconstruct_python_name\u001b[0m\n    return self.find_python_name(suffix, node.start_mark)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/torch_mkl/lib/python3.10/site-packages/yaml/constructor.py:719\u001b[0m in \u001b[1;35mfind_python_name\u001b[0m\n    return super(UnsafeConstructor, self).find_python_name(name, mark, unsafe=True)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/torch_mkl/lib/python3.10/site-packages/yaml/constructor.py:551\u001b[0m in \u001b[1;35mfind_python_name\u001b[0m\n    __import__(module_name)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/anaconda3/envs/torch_mkl/lib/python3.10/site-packages/allegro/model/__init__.py:3\u001b[0;36m\n\u001b[0;31m    from ._ETN import ETN\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/anaconda3/envs/torch_mkl/lib/python3.10/site-packages/allegro/model/_ETN.py:90\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"edge_features_F\": (\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "# Trainer\n",
    "from nequip.train.trainer import Trainer\n",
    "from e3nn import o3\n",
    "\n",
    "trainer = Trainer(model=None, **Config.as_dict(config))\n",
    "\n",
    "# what is this\n",
    "# to update wandb data?\n",
    "config.update(trainer.params)\n",
    "\n",
    "# = Train/test split =\n",
    "trainer.set_dataset(dataset, validation_dataset)\n",
    "\n",
    "#config['model_input_fields'] = {'node_spin': o3.Irreps('1x1e')}\n",
    "Nc = 6\n",
    "N_rank_spec = 4\n",
    "config['Nc'] = Nc\n",
    "config['N_rank_spec'] = N_rank_spec\n",
    "\n",
    "# = Build model =\n",
    "final_model = model_from_config(\n",
    "    config=config, initialize=True, dataset=trainer.dataset_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e29def5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "from nequip.data import AtomicData, AtomicDataDict\n",
    "from torch.nn.functional import one_hot\n",
    "from e3nn.nn import FullyConnectedNet\n",
    "from allegro import with_edge_spin_length\n",
    "from allegro import _keys\n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "trainer.model = final_model\n",
    "data0 = AtomicData.to_AtomicDataDict(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "233bcdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "from nequip.data import AtomicData, AtomicDataDict\n",
    "from torch.nn.functional import one_hot\n",
    "from e3nn.nn import FullyConnectedNet\n",
    "    \n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "data_new = final_model(data0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ee3345e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5],\n",
       "        [4],\n",
       "        [4],\n",
       "        [4],\n",
       "        [4],\n",
       "        [4],\n",
       "        [4],\n",
       "        [5],\n",
       "        [5],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [4],\n",
       "        [4],\n",
       "        [4],\n",
       "        [4],\n",
       "        [4],\n",
       "        [4],\n",
       "        [3],\n",
       "        [3],\n",
       "        [5],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [4],\n",
       "        [3],\n",
       "        [5],\n",
       "        [5],\n",
       "        [5],\n",
       "        [4],\n",
       "        [4],\n",
       "        [4],\n",
       "        [4],\n",
       "        [3],\n",
       "        [4],\n",
       "        [4],\n",
       "        [5],\n",
       "        [3],\n",
       "        [3],\n",
       "        [5],\n",
       "        [3],\n",
       "        [4],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [5],\n",
       "        [4],\n",
       "        [5],\n",
       "        [5],\n",
       "        [4],\n",
       "        [4],\n",
       "        [4],\n",
       "        [4],\n",
       "        [4],\n",
       "        [5],\n",
       "        [4],\n",
       "        [3],\n",
       "        [3],\n",
       "        [4],\n",
       "        [4],\n",
       "        [5],\n",
       "        [4],\n",
       "        [4],\n",
       "        [4],\n",
       "        [5],\n",
       "        [5],\n",
       "        [4],\n",
       "        [4],\n",
       "        [5],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [4],\n",
       "        [4],\n",
       "        [5],\n",
       "        [4],\n",
       "        [4],\n",
       "        [4],\n",
       "        [4],\n",
       "        [4],\n",
       "        [5],\n",
       "        [5],\n",
       "        [4],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [4],\n",
       "        [4],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [5],\n",
       "        [4],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [5],\n",
       "        [4],\n",
       "        [4],\n",
       "        [4],\n",
       "        [4],\n",
       "        [5],\n",
       "        [3],\n",
       "        [3],\n",
       "        [7],\n",
       "        [8],\n",
       "        [7],\n",
       "        [7],\n",
       "        [7],\n",
       "        [7],\n",
       "        [7],\n",
       "        [7],\n",
       "        [6],\n",
       "        [8],\n",
       "        [7],\n",
       "        [8],\n",
       "        [6],\n",
       "        [6],\n",
       "        [6],\n",
       "        [6],\n",
       "        [6],\n",
       "        [7],\n",
       "        [8],\n",
       "        [6],\n",
       "        [7],\n",
       "        [7],\n",
       "        [7],\n",
       "        [7],\n",
       "        [7],\n",
       "        [7],\n",
       "        [8],\n",
       "        [7],\n",
       "        [6],\n",
       "        [7],\n",
       "        [8],\n",
       "        [6],\n",
       "        [6],\n",
       "        [6],\n",
       "        [6],\n",
       "        [6],\n",
       "        [7],\n",
       "        [6],\n",
       "        [6],\n",
       "        [6],\n",
       "        [6],\n",
       "        [6],\n",
       "        [7],\n",
       "        [8],\n",
       "        [7],\n",
       "        [6],\n",
       "        [7],\n",
       "        [6],\n",
       "        [8],\n",
       "        [7],\n",
       "        [7],\n",
       "        [7],\n",
       "        [7],\n",
       "        [7],\n",
       "        [7],\n",
       "        [8],\n",
       "        [4],\n",
       "        [4],\n",
       "        [4],\n",
       "        [4],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [5],\n",
       "        [4],\n",
       "        [5],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [4],\n",
       "        [3],\n",
       "        [5],\n",
       "        [4],\n",
       "        [3],\n",
       "        [5],\n",
       "        [4],\n",
       "        [4],\n",
       "        [4],\n",
       "        [4],\n",
       "        [4],\n",
       "        [4],\n",
       "        [5],\n",
       "        [4],\n",
       "        [3],\n",
       "        [5],\n",
       "        [3],\n",
       "        [5],\n",
       "        [3],\n",
       "        [3],\n",
       "        [4],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [8],\n",
       "        [6],\n",
       "        [8],\n",
       "        [7],\n",
       "        [7],\n",
       "        [7],\n",
       "        [7],\n",
       "        [7],\n",
       "        [6],\n",
       "        [7],\n",
       "        [6],\n",
       "        [7],\n",
       "        [6],\n",
       "        [7],\n",
       "        [6],\n",
       "        [6],\n",
       "        [8],\n",
       "        [6],\n",
       "        [7],\n",
       "        [6],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [2],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [2],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [2],\n",
       "        [1],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [2],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [2],\n",
       "        [2],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [2],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [2],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [2],\n",
       "        [2],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [2],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [2],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [2],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new['edge_types']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d74f4af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['edge_index', 'pos', 'cell', 'edge_cell_shift', 'atom_types', 'batch', 'ptr', 'edge_vectors', 'node_attrs', 'edge_type', 'node_features', 'edge_lengths', 'edge_embedding', 'edge_cutoff', 'edge_attrs', 'edge_features', 'edge_energy', 'atomic_energy', 'total_energy', 'forces', 'stress', 'virial', 'atom_virial'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40138b95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_mkl",
   "language": "python",
   "name": "torch_mkl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
