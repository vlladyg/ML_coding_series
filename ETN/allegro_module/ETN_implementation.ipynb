{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "864e791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference example\n",
    "from nequip.data import dataset_from_config\n",
    "from nequip.utils import Config\n",
    "#from nequip.utils.misc import get_default_device_name\n",
    "#from nequip.utils.config import _GLOBAL_ALL_ASKED_FOR_KEYS\n",
    "\n",
    "from nequip.model import model_from_config\n",
    "\n",
    "\n",
    "default_config = dict(\n",
    "    root=\"./\",\n",
    "    tensorboard=False,\n",
    "    wandb=False,\n",
    "    model_builders=[\n",
    "        \"SimpleIrrepsConfig\",\n",
    "        \"EnergyModel\",\n",
    "        \"PerSpeciesRescale\",\n",
    "        \"StressForceOutput\",\n",
    "        \"RescaleEnergyEtc\",\n",
    "    ],\n",
    "    dataset_statistics_stride=1,\n",
    "    device='cuda',\n",
    "    default_dtype=\"float64\",\n",
    "    model_dtype=\"float32\",\n",
    "    allow_tf32=True,\n",
    "    verbose=\"INFO\",\n",
    "    model_debug_mode=False,\n",
    "    equivariance_test=False,\n",
    "    grad_anomaly_mode=False,\n",
    "    gpu_oom_offload=False,\n",
    "    append=False,\n",
    "    warn_unused=False,\n",
    "    _jit_bailout_depth=2,  # avoid 20 iters of pain, see https://github.com/pytorch/pytorch/issues/52286\n",
    "    # Quote from eelison in PyTorch slack:\n",
    "    # https://pytorch.slack.com/archives/CDZD1FANA/p1644259272007529?thread_ts=1644064449.039479&cid=CDZD1FANA\n",
    "    # > Right now the default behavior is to specialize twice on static shapes and then on dynamic shapes.\n",
    "    # > To reduce warmup time you can do something like setFusionStrartegy({{FusionBehavior::DYNAMIC, 3}})\n",
    "    # > ... Although we would wouldn't really expect to recompile a dynamic shape fusion in a model,\n",
    "    # > provided broadcasting patterns remain fixed\n",
    "    # We default to DYNAMIC alone because the number of edges is always dynamic,\n",
    "    # even if the number of atoms is fixed:\n",
    "    _jit_fusion_strategy=[(\"DYNAMIC\", 3)],\n",
    "    # Due to what appear to be ongoing bugs with nvFuser, we default to NNC (fuser1) for now:\n",
    "    # TODO: still default to NNC on CPU regardless even if change this for GPU\n",
    "    # TODO: default for ROCm?\n",
    "    _jit_fuser=\"fuser1\",\n",
    ")\n",
    "\n",
    "# All default_config keys are valid / requested\n",
    "#_GLOBAL_ALL_ASKED_FOR_KEYS.update(default_config.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaca74cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available objects for config:\n",
      "    AliasManager\n",
      "    DisplayFormatter\n",
      "    HistoryManager\n",
      "    IPCompleter\n",
      "    IPKernelApp\n",
      "    LoggingMagics\n",
      "    MagicsManager\n",
      "    OSMagics\n",
      "    PrefilterManager\n",
      "    ScriptMagics\n",
      "    StoreMagics\n",
      "    ZMQInteractiveShell\n"
     ]
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd21ac18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtomicData(atom_types=[21, 1], cell=[3, 3], edge_cell_shift=[364, 3], edge_index=[2, 364], forces=[21, 3], pbc=[3], pos=[21, 3], total_energy=[1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config.from_file('./configs/example_ETN.yaml', defaults=default_config)\n",
    "    \n",
    "\n",
    "dataset = dataset_from_config(config, prefix=\"dataset\")\n",
    "\n",
    "validation_dataset = None\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5c072c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:* Initialize Output\n",
      "  ...generate file name results/aspirin/example/log\n",
      "  ...open log file results/aspirin/example/log\n",
      "  ...generate file name results/aspirin/example/metrics_epoch.csv\n",
      "  ...open log file results/aspirin/example/metrics_epoch.csv\n",
      "  ...generate file name results/aspirin/example/metrics_initialization.csv\n",
      "  ...open log file results/aspirin/example/metrics_initialization.csv\n",
      "  ...generate file name results/aspirin/example/metrics_batch_train.csv\n",
      "  ...open log file results/aspirin/example/metrics_batch_train.csv\n",
      "  ...generate file name results/aspirin/example/metrics_batch_val.csv\n",
      "  ...open log file results/aspirin/example/metrics_batch_val.csv\n",
      "  ...generate file name results/aspirin/example/best_model.pth\n",
      "  ...generate file name results/aspirin/example/last_model.pth\n",
      "  ...generate file name results/aspirin/example/trainer.pth\n",
      "  ...generate file name results/aspirin/example/config.yaml\n",
      "Torch device: cuda\n",
      "instantiate Loss\n",
      "...Loss_param = dict(\n",
      "...   optional_args = {'coeff_schedule': 'constant'},\n",
      "...   positional_args = {'coeffs': {'forces': 1.0, 'total_energy': [1.0, 'PerAtomMSELoss']}})\n",
      "instantiate MSELoss\n",
      "...MSELoss_param = dict(\n",
      "...   optional_args = {'size_average': None, 'reduce': None},\n",
      "...   positional_args = {'reduction': 'none'})\n",
      " parsing forces 1.0\n",
      " parsing 1.0 MSELoss\n",
      "instantiate MSELoss\n",
      "...MSELoss_param = dict(\n",
      "...   optional_args = {'size_average': None, 'reduce': None},\n",
      "...   positional_args = {'reduction': 'none'})\n",
      " parsing total_energy [1.0, 'PerAtomMSELoss']\n",
      " parsing 1.0 PerAtomMSELoss\n",
      "create loss instance <class 'nequip.train._loss.PerAtomLoss'>\n",
      "instantiate MSELoss\n",
      "...MSELoss_param = dict(\n",
      "...   optional_args = {'size_average': None, 'reduce': None},\n",
      "...   positional_args = {'reduction': 'none'})\n",
      "Building ETN model...\n",
      "instantiate PairTypeEmbedding\n",
      "        all_args :                                           num_types\n",
      "...PairTypeEmbedding_param = dict(\n",
      "...   optional_args = {'num_types': 3},\n",
      "...   positional_args = {'irreps_in': None})\n",
      "instantiate OneHotAtomEncoding\n",
      "        all_args :                                           num_types\n",
      "...OneHotAtomEncoding_param = dict(\n",
      "...   optional_args = {'set_features': True, 'num_types': 3},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1oe, 'edge_index': None, 'edge_types': 1x0ee}})\n",
      "instantiate RadialBasisEdgeEncoding\n",
      "        all_args :                                  basis_kwargs.r_max <-                                              r_max\n",
      "        all_args :            basis_kwargs.original_basis_kwargs.r_max <-                                              r_max\n",
      "        all_args :        basis_kwargs.original_basis_kwargs.trainable <-                              BesselBasis_trainable\n",
      "        all_args :                                 cutoff_kwargs.r_max <-                                              r_max\n",
      "        all_args :                                     cutoff_kwargs.p <-                                 PolynomialCutoff_p\n",
      "   optional_args :                                           out_field\n",
      "   optional_args :                                               basis\n",
      "...RadialBasisEdgeEncoding_param = dict(\n",
      "...   optional_args = {'basis': <class 'allegro.nn._norm_basis.NormalizedBasis'>, 'cutoff': <class 'nequip.nn.cutoffs.PolynomialCutoff'>, 'basis_kwargs': {'r_min': 0.0, 'original_basis': <class 'nequip.nn.radial_basis.BesselBasis'>, 'original_basis_kwargs': {'num_basis': 8, 'trainable': True, 'r_max': 6.0}, 'n': 4000, 'norm_basis_mean_shift': True, 'r_max': 6.0}, 'cutoff_kwargs': {'p': 6, 'r_max': 6.0}, 'out_field': 'edge_embedding'},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1oe, 'edge_index': None, 'edge_types': 1x0ee, 'node_attrs': 3x0ee, 'node_features': 3x0ee}})\n",
      "instantiate SphericalHarmonicEdgeAttrs\n",
      "        all_args :                                      irreps_edge_sh\n",
      "...SphericalHarmonicEdgeAttrs_param = dict(\n",
      "...   optional_args = {'edge_sh_normalization': 'component', 'edge_sh_normalize': True, 'out_field': 'edge_attrs', 'irreps_edge_sh': '1x0ee+1x1oe+1x2ee'},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1oe, 'edge_index': None, 'edge_types': 1x0ee, 'node_attrs': 3x0ee, 'node_features': 3x0ee, 'edge_embedding': 8x0ee, 'edge_cutoff': 1x0ee}})\n",
      "instantiate EdgeFeatures_F\n",
      "        all_args :                                           num_types\n",
      "   optional_args :                                           out_field\n",
      "   optional_args :                                         N_rank_spec\n",
      "   optional_args :                                                  Nc\n",
      "...EdgeFeatures_F_param = dict(\n",
      "...   optional_args = {'num_basis': 8, 'N_rank_spec': 4, 'out_field': 'edge_features_F', 'Nc': 10, 'num_types': 3},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1oe, 'edge_index': None, 'edge_types': 1x0ee, 'node_attrs': 3x0ee, 'node_features': 3x0ee, 'edge_embedding': 8x0ee, 'edge_cutoff': 1x0ee, 'edge_attrs': 1x0ee+1x1oe+1x2ee}})\n",
      "instantiate EdgewiseFSum\n",
      "        all_args :                                   avg_num_neighbors\n",
      "        all_args :                                           num_types\n",
      "...EdgewiseFSum_param = dict(\n",
      "...   optional_args = {'avg_num_neighbors': 17.211328506469727, 'normalize_edge_features_f': True, 'per_edge_species_scale': False, 'num_types': 3},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1oe, 'edge_index': None, 'edge_types': 1x0ee, 'node_attrs': 3x0ee, 'node_features': 3x0ee, 'edge_embedding': 8x0ee, 'edge_cutoff': 1x0ee, 'edge_attrs': 1x0ee+1x1oe+1x2ee, 'edge_features_F': 10x0ee+10x1oe+10x2ee}})\n",
      "instantiate Allegro_Module\n",
      "        all_args :                                               r_max\n",
      "        all_args :                                  embed_initial_edge\n",
      "        all_args :                              env_embed_multiplicity\n",
      "        all_args :                                   avg_num_neighbors\n",
      "        all_args :                                       latent_resnet\n",
      "        all_args :                                  PolynomialCutoff_p\n",
      "        all_args :                                          num_layers\n",
      "        all_args :                           nonscalars_include_parity\n",
      "        all_args :                                           num_types\n",
      "        all_args :        two_body_latent_kwargs.mlp_latent_dimensions <-              two_body_latent_mlp_latent_dimensions\n",
      "        all_args :             two_body_latent_kwargs.mlp_nonlinearity <-                   two_body_latent_mlp_nonlinearity\n",
      "        all_args :           two_body_latent_kwargs.mlp_initialization <-                 two_body_latent_mlp_initialization\n",
      "        all_args :              env_embed_kwargs.mlp_latent_dimensions <-                    env_embed_mlp_latent_dimensions\n",
      "        all_args :                   env_embed_kwargs.mlp_nonlinearity <-                         env_embed_mlp_nonlinearity\n",
      "        all_args :                 env_embed_kwargs.mlp_initialization <-                       env_embed_mlp_initialization\n",
      "        all_args :                 latent_kwargs.mlp_latent_dimensions <-                       latent_mlp_latent_dimensions\n",
      "        all_args :                      latent_kwargs.mlp_nonlinearity <-                            latent_mlp_nonlinearity\n",
      "        all_args :                    latent_kwargs.mlp_initialization <-                          latent_mlp_initialization\n",
      "   optional_args :                                edge_invariant_field\n",
      "   optional_args :                                node_invariant_field\n",
      "   optional_args :                                               field\n",
      "...Allegro_Module_param = dict(\n",
      "...   optional_args = {'avg_num_neighbors': 17.211328506469727, 'r_start_cos_ratio': 0.8, 'PolynomialCutoff_p': 6, 'per_layer_cutoffs': None, 'cutoff_type': 'polynomial', 'field': 'edge_attrs', 'edge_invariant_field': 'edge_embedding', 'node_invariant_field': 'node_attrs', 'env_embed_multiplicity': 64, 'embed_initial_edge': True, 'linear_after_env_embed': False, 'nonscalars_include_parity': True, 'two_body_latent': <class 'allegro.nn._fc.ScalarMLPFunction'>, 'two_body_latent_kwargs': {'mlp_nonlinearity': 'silu', 'mlp_initialization': 'uniform', 'mlp_dropout_p': 0.0, 'mlp_batchnorm': False, 'mlp_latent_dimensions': [128, 256, 512, 1024]}, 'env_embed': <class 'allegro.nn._fc.ScalarMLPFunction'>, 'env_embed_kwargs': {'mlp_nonlinearity': None, 'mlp_initialization': 'uniform', 'mlp_dropout_p': 0.0, 'mlp_batchnorm': False, 'mlp_latent_dimensions': []}, 'latent': <class 'allegro.nn._fc.ScalarMLPFunction'>, 'latent_kwargs': {'mlp_nonlinearity': 'silu', 'mlp_initialization': 'uniform', 'mlp_dropout_p': 0.0, 'mlp_batchnorm': False, 'mlp_latent_dimensions': [1024, 1024, 1024]}, 'latent_resnet': True, 'latent_resnet_update_ratios': None, 'latent_resnet_update_ratios_learnable': False, 'latent_out_field': 'edge_features', 'pad_to_alignment': 1, 'sparse_mode': None, 'r_max': 6.0, 'num_layers': 2, 'num_types': 3},\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...   positional_args = {'irreps_in': {'pos': 1x1oe, 'edge_index': None, 'edge_types': 1x0ee, 'node_attrs': 3x0ee, 'node_features': 3x0ee, 'edge_embedding': 8x0ee, 'edge_cutoff': 1x0ee, 'edge_attrs': 1x0ee+1x1oe+1x2ee, 'edge_features_F': 10x0ee+10x1oe+10x2ee, 'node_features_F': 10x0ee+10x1oe+10x2ee}})\n",
      "/Users/temporary/Documents/GitHub/pytorch-intel-mps/torch/jit/_check.py:172: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\"The TorchScript type system doesn't support \"\n",
      "instantiate ScalarMLP\n",
      "        all_args :                               mlp_latent_dimensions <-                     edge_eng_mlp_latent_dimensions\n",
      "        all_args :                                    mlp_nonlinearity <-                          edge_eng_mlp_nonlinearity\n",
      "        all_args :                                  mlp_initialization <-                        edge_eng_mlp_initialization\n",
      "   optional_args :                                           out_field\n",
      "   optional_args :                                mlp_output_dimension\n",
      "   optional_args :                                               field\n",
      "...ScalarMLP_param = dict(\n",
      "...   optional_args = {'mlp_nonlinearity': None, 'mlp_initialization': 'uniform', 'mlp_dropout_p': 0.0, 'mlp_batchnorm': False, 'field': 'edge_features', 'out_field': 'edge_energy', 'mlp_latent_dimensions': [128], 'mlp_output_dimension': 1},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1oe, 'edge_index': None, 'edge_types': 1x0ee, 'node_attrs': 3x0ee, 'node_features': 3x0ee, 'edge_embedding': 8x0ee, 'edge_cutoff': 1x0ee, 'edge_attrs': 1x0ee+1x1oe+1x2ee, 'edge_features_F': 10x0ee+10x1oe+10x2ee, 'node_features_F': 10x0ee+10x1oe+10x2ee, 'edge_features': 1024x0ee}})\n",
      "instantiate EdgewiseEnergySum\n",
      "        all_args :                                   avg_num_neighbors\n",
      "        all_args :                                           num_types\n",
      "...EdgewiseEnergySum_param = dict(\n",
      "...   optional_args = {'avg_num_neighbors': 17.211328506469727, 'normalize_edge_energy_sum': True, 'per_edge_species_scale': False, 'num_types': 3},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1oe, 'edge_index': None, 'edge_types': 1x0ee, 'node_attrs': 3x0ee, 'node_features': 3x0ee, 'edge_embedding': 8x0ee, 'edge_cutoff': 1x0ee, 'edge_attrs': 1x0ee+1x1oe+1x2ee, 'edge_features_F': 10x0ee+10x1oe+10x2ee, 'node_features_F': 10x0ee+10x1oe+10x2ee, 'edge_features': 1024x0ee, 'edge_energy': 1x0ee}})\n",
      "instantiate AtomwiseReduce\n",
      "   optional_args :                                           out_field\n",
      "   optional_args :                                              reduce\n",
      "   optional_args :                                               field\n",
      "...AtomwiseReduce_param = dict(\n",
      "...   optional_args = {'out_field': 'total_energy', 'reduce': 'sum', 'avg_num_atoms': None, 'field': 'atomic_energy'},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1oe, 'edge_index': None, 'edge_types': 1x0ee, 'node_attrs': 3x0ee, 'node_features': 3x0ee, 'edge_embedding': 8x0ee, 'edge_cutoff': 1x0ee, 'edge_attrs': 1x0ee+1x1oe+1x2ee, 'edge_features_F': 10x0ee+10x1oe+10x2ee, 'node_features_F': 10x0ee+10x1oe+10x2ee, 'edge_features': 1024x0ee, 'edge_energy': 1x0ee, 'atomic_energy': 1x0ee}})\n",
      "Replace string dataset_forces_rms to 31.252248764038086\n",
      "Replace string dataset_per_atom_total_energy_mean to -19318.35546875\n",
      "Atomic outputs are scaled by: [H, C, O: 31.252249], shifted by [H, C, O: -19318.355469].\n",
      "instantiate PerSpeciesScaleShift\n",
      "        all_args :                                       default_dtype\n",
      "        all_args :                                           num_types\n",
      "        all_args :                                          type_names\n",
      "   optional_args :                                              scales\n",
      "   optional_args :                          arguments_in_dataset_units\n",
      "   optional_args :                                               field\n",
      "   optional_args :                                           out_field\n",
      "   optional_args :                                              shifts\n",
      "...PerSpeciesScaleShift_param = dict(\n",
      "...   optional_args = {'out_field': 'atomic_energy', 'scales_trainable': False, 'shifts_trainable': False, 'default_dtype': 'float32', 'num_types': 3, 'type_names': ['H', 'C', 'O'], 'field': 'atomic_energy', 'shifts': tensor(-19318.3555), 'scales': tensor(31.2522), 'arguments_in_dataset_units': True},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1oe, 'edge_index': None, 'edge_types': 1x0ee, 'node_attrs': 3x0ee, 'node_features': 3x0ee, 'edge_embedding': 8x0ee, 'edge_cutoff': 1x0ee, 'edge_attrs': 1x0ee+1x1oe+1x2ee, 'edge_features_F': 10x0ee+10x1oe+10x2ee, 'node_features_F': 10x0ee+10x1oe+10x2ee, 'edge_features': 1024x0ee, 'edge_energy': 1x0ee, 'atomic_energy': 1x0ee}})\n",
      "Replace string dataset_forces_rms to 31.252248764038086\n",
      "Initially outputs are globally scaled by: 31.252248764038086, total_energy are globally shifted by None.\n",
      "PerSpeciesScaleShift's arguments were in dataset units; rescaling:\n",
      "  Original scales: [H: 31.252249, C: 31.252249, O: 31.252249] shifts: [H: -19318.355469, C: -19318.355469, O: -19318.355469]\n",
      "  New scales: [H: 1.000000, C: 1.000000, O: 1.000000] shifts: [H: -618.142883, C: -618.142883, O: -618.142883]\n"
     ]
    }
   ],
   "source": [
    "# Trainer\n",
    "from nequip.train.trainer import Trainer\n",
    "from e3nn import o3\n",
    "\n",
    "trainer = Trainer(model=None, **Config.as_dict(config))\n",
    "\n",
    "# what is this\n",
    "# to update wandb data?\n",
    "config.update(trainer.params)\n",
    "\n",
    "# = Train/test split =\n",
    "trainer.set_dataset(dataset, validation_dataset)\n",
    "\n",
    "#config['model_input_fields'] = {'node_spin': o3.Irreps('1x1e')}\n",
    "Nc = 10\n",
    "N_rank_spec = 4\n",
    "config['Nc'] = Nc\n",
    "config['N_rank_spec'] = N_rank_spec\n",
    "\n",
    "# = Build model =\n",
    "final_model = model_from_config(\n",
    "    config=config, initialize=True, dataset=trainer.dataset_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44fab7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "from nequip.data import AtomicData, AtomicDataDict\n",
    "from torch.nn.functional import one_hot\n",
    "from e3nn.nn import FullyConnectedNet\n",
    "from allegro import with_edge_spin_length\n",
    "from allegro import _keys\n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "trainer.model = final_model\n",
    "data0 = AtomicData.to_AtomicDataDict(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a0a8e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "from nequip.data import AtomicData, AtomicDataDict\n",
    "from torch.nn.functional import one_hot\n",
    "from e3nn.nn import FullyConnectedNet\n",
    "    \n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "data_new = final_model(data0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93991fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 9, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new['edge_features_F'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d4f8161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 9, 10])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new['node_features_F'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "831e93b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "from nequip.data import AtomicData, AtomicDataDict\n",
    "from torch.nn.functional import one_hot\n",
    "from e3nn.nn import FullyConnectedNet\n",
    "from allegro import with_edge_spin_length\n",
    "from allegro import _keys\n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "data = data0\n",
    "\n",
    "\n",
    "import copy\n",
    "\n",
    "data_rot = {key: torch.clone(data0[key]) for key in data0}\n",
    "\n",
    "irreps_sh = o3.Irreps('1x0e + 1x1o + 1x2e') #o3.Irreps.spherical_harmonics(lmax=2)\n",
    "irreps_sh_r = o3.Irreps('1x1o')\n",
    "\n",
    "alpha, beta, gamma = o3.rand_angles(100)\n",
    "\n",
    "rot_matrix = irreps_sh.D_from_angles(alpha[0], beta[0], gamma[0])\n",
    "rot_matrix_r = irreps_sh_r.D_from_angles(alpha[0], beta[0], gamma[0])\n",
    "\n",
    "\n",
    "data_rot['pos'] = data_rot['pos'] @ rot_matrix_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0cf26cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F is equivariant\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(32)\n",
    "\n",
    "F = final_model(data)['node_features_F']\n",
    "\n",
    "torch.manual_seed(32)\n",
    "\n",
    "F_rot =final_model(data_rot)['node_features_F']\n",
    "\n",
    "\n",
    "F_rot_rot = torch.einsum('Njn,jk->Nkn', F_rot, rot_matrix.T)\n",
    "\n",
    "if torch.allclose(F, F_rot_rot, atol=1e-05):\n",
    "    print('F is equivariant')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_mkl",
   "language": "python",
   "name": "torch_mkl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
