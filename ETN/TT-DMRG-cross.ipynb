{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f36d0aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.22044605e-16])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ttml.tt_cross import estimator_to_tt_cross\n",
    "import numpy as np\n",
    "\n",
    "def f(x):\n",
    "    return np.sin(np.sum(x, axis=1))\n",
    "\n",
    "# Same thresholds for every feature: [0,0.2,0.4,0.6,0.8]\n",
    "thresholds = [np.linspace(0, 1, 11)] * 5\n",
    "\n",
    "tt = estimator_to_tt_cross(f, thresholds)\n",
    "tt.gather(np.array([[2, 2, 2, 2, 2]])) - np.sin(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4894656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2.62706082e+02, 1.10057236e+02, 3.44454083e-14, 2.92500273e-14,\n",
       "        1.65493103e-14]),\n",
       " array([2.50489642e+02, 1.35580309e+02, 2.52231635e-14, 2.05148678e-14,\n",
       "        1.85802312e-14]),\n",
       " array([2.50489642e+02, 1.35580309e+02, 5.33891215e-14, 4.60613535e-14,\n",
       "        1.70711918e-14]),\n",
       " array([2.62706082e+02, 1.10057236e+02, 3.69537765e-14, 2.35796145e-14,\n",
       "        1.16403851e-14])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.sing_vals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dc880b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorTrain of order 5 with outer dimensions (11, 11, 11, 11, 11), TT-rank (2, 2, 2, 2), and orthogonalized at mode 4>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt2 = estimator_to_tt_cross(f, thresholds, max_rank=2)\n",
    "\n",
    "tt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b6ea261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4.67820154468367e-13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tt - tt2).norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5fe8d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorTrain of order 5 with outer dimensions (11, 11, 11, 11, 11), TT-rank (2, 2, 2, 2), and orthogonalized at mode 4>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X = np.random.normal(size=(1000, 5))\n",
    "y = np.exp(np.sum(X, axis=1))\n",
    "\n",
    "forest = RandomForestRegressor()\n",
    "forest.fit(X, y)\n",
    "\n",
    "thresholds = [np.linspace(0, 1, 11)] * 5\n",
    "\n",
    "tt = estimator_to_tt_cross(forest.predict, thresholds, max_rank=2)\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "897683ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = estimator_to_tt_cross(forest.predict, thresholds, method='dmrg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bea86fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorly as tl\n",
    "from tensorly.contrib.decomposition import tensor_train_cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05fb9324-d27f-4467-97cc-a083b2c547e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tl.tensor(np.arange(5**3).reshape(5,5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a26d379e-46a9-4b0c-858f-060a56d39b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = [1, 3, 3, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1986c33-5563-43e3-906c-ffbdac36eeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = tensor_train_cross(tensor, rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b03cbdf-3bbd-4762-b72f-8ff07a2b9033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  1  19   0]\n",
      "  [ 26  44  25]\n",
      "  [ 51  69  50]\n",
      "  [ 76  94  75]\n",
      "  [101 119 100]]]\n"
     ]
    }
   ],
   "source": [
    "print(factors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "717a81bf-367b-4337-bd2b-f95da9dc2ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorly as tl\n",
    "from tensorly import tt_to_tensor\n",
    "import numpy as np\n",
    "\n",
    "def tensor_train_cross(input_tensor, rank, tol=1e-4, n_iter_max=100, random_state=None):\n",
    "    \"\"\"TT (tensor-train) decomposition via cross-approximation (TTcross) [1]\n",
    "\n",
    "    Decomposes `input_tensor` into a sequence of order-3 tensors of given rank. (factors/cores)\n",
    "    Rather than directly decompose the whole tensor, we sample fibers based on skeleton decomposition.\n",
    "    We initialize a random tensor-train and sweep from left to right and right to left.\n",
    "    On each core, we shape the core as a matrix and choose the fibers indices by finding maximum-volume submatrix and update the core.\n",
    "\n",
    "    * Advantage: faster\n",
    "        The main advantage of TTcross is that it doesn't need to evaluate all the entries of the tensor.\n",
    "        For a tensor_shape^tensor_order tensor, SVD needs O(tensor_shape^tensor_order) runtime, but TTcross' runtime is linear in tensor_shape and tensor_order, which makes it feasible in high dimension.\n",
    "    * Disadvantage: less accurate\n",
    "        TTcross may underestimate the error, since it only evaluates partial entries of the tensor.\n",
    "        Besides, in contrast to its practical fast performance, there is no theoretical guarantee of it convergence.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_tensor : tensorly.tensor\n",
    "            The tensor to decompose.\n",
    "    rank : {int, int list}\n",
    "            maximum allowable TT rank of the factors\n",
    "            if int, then this is the same for all the factors\n",
    "            if int list, then rank[k] is the rank of the kth factor\n",
    "    tol : float\n",
    "            accuracy threshold for outer while-loop\n",
    "    n_iter_max : int\n",
    "            maximum iterations of outer while-loop (the 'crosses' or 'sweeps' sampled)\n",
    "    random_state : {None, int, np.random.RandomState}\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    factors : TT factors\n",
    "              order-3 tensors of the TT decomposition\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    Generate a 5^3 tensor, and decompose it into tensor-train of 3 factors, with rank = [1,3,3,1]\n",
    "\n",
    "    >>> tensor = tl.tensor(np.arange(5**3).reshape(5,5,5))\n",
    "    >>> rank = [1, 3, 3, 1]\n",
    "    >>> factors = tensor_train_cross(tensor, rank)\n",
    "    >>> # print the first core:\n",
    "    >>> print(factors[0])\n",
    "    [[[ 24.   0.   4.]\n",
    "      [ 49.  25.  29.]\n",
    "      [ 74.  50.  54.]\n",
    "      [ 99.  75.  79.]\n",
    "      [124. 100. 104.]]]\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Pseudo-code [2]:\n",
    "\n",
    "    1. Initialization tensor_order cores and column indices\n",
    "\n",
    "    2. while (error > tol)\n",
    "\n",
    "    3. update the tensor-train from left to right:\n",
    "\n",
    "       .. code:: python\n",
    "\n",
    "           for Core 1 to Core tensor_order:\n",
    "           approximate the skeleton-decomposition by QR and maxvol\n",
    "\n",
    "    4. update the tensor-train from right to left:\n",
    "\n",
    "       .. code:: python\n",
    "\n",
    "            for Core tensor_order to Core 1\n",
    "                approximate the skeleton-decomposition by QR and maxvol\n",
    "\n",
    "    5. end while\n",
    "\n",
    "    Acknowledgement: the main body of the code is modified based on TensorToolbox by Daniele Bigoni.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Ivan Oseledets and Eugene Tyrtyshnikov.  Tt-cross approximation for multidimensional arrays.\n",
    "            LinearAlgebra and its Applications, 432(1):70–88, 2010.\n",
    "    .. [2] Sergey Dolgov and Robert Scheichl. A hybrid alternating least squares–tt cross algorithm for parametricpdes.\n",
    "            arXiv preprint arXiv:1707.04562, 2017.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check user input for errors\n",
    "    tensor_shape = tl.shape(input_tensor)\n",
    "    tensor_order = tl.ndim(input_tensor)\n",
    "\n",
    "    if isinstance(rank, int):\n",
    "        rank = [rank] * (tensor_order + 1)\n",
    "    elif tensor_order + 1 != len(rank):\n",
    "        message = (\n",
    "            \"Provided incorrect number of ranks. Should verify \"\n",
    "            + f\"len(rank) == tl.ndim(tensor)+1, but len(rank) = {len(rank)} \"\n",
    "            + f\"while tl.ndim(tensor) + 1  = {tensor_order}\"\n",
    "        )\n",
    "        raise (ValueError(message))\n",
    "\n",
    "    # Make sure iter's not a tuple but a list\n",
    "    rank = list(rank)\n",
    "\n",
    "    # Initialize rank\n",
    "    if rank[0] != 1:\n",
    "        message = f\"Provided rank[0] == {rank[0]} but boundary conditions dictate rank[0] == rank[-1] == 1.\"\n",
    "        raise ValueError(message)\n",
    "    if rank[-1] != 1:\n",
    "        message = f\"Provided rank[-1] == {rank[-1]} but boundary conditions dictate rank[0] == rank[-1] == 1.\"\n",
    "        raise ValueError(message)\n",
    "\n",
    "    # list col_idx: column indices (right indices) for skeleton-decomposition: indicate which columns used in each core.\n",
    "    # list row_idx: row indices    (left indices)  for skeleton-decomposition: indicate which rows used in each core.\n",
    "\n",
    "    # Initialize indice: random selection of column indices\n",
    "    rng = tl.check_random_state(random_state)\n",
    "\n",
    "    col_idx = [None] * tensor_order\n",
    "    for k_col_idx in range(tensor_order - 1):\n",
    "        col_idx[k_col_idx] = []\n",
    "        for i in range(rank[k_col_idx + 1]):\n",
    "            newidx = tuple(\n",
    "                [\n",
    "                    rng.randint(tensor_shape[j])\n",
    "                    for j in range(k_col_idx + 1, tensor_order)\n",
    "                ]\n",
    "            )\n",
    "            while newidx in col_idx[k_col_idx]:\n",
    "                newidx = tuple(\n",
    "                    [\n",
    "                        rng.randint(tensor_shape[j])\n",
    "                        for j in range(k_col_idx + 1, tensor_order)\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            col_idx[k_col_idx].append(newidx)\n",
    "\n",
    "    # Initialize the cores of tensor-train\n",
    "    factor_old = [\n",
    "        tl.zeros((rank[k], tensor_shape[k], rank[k + 1]), **tl.context(input_tensor))\n",
    "        for k in range(tensor_order)\n",
    "    ]\n",
    "    factor_new = [\n",
    "        tl.tensor(\n",
    "            rng.random_sample((rank[k], tensor_shape[k], rank[k + 1])),\n",
    "            **tl.context(input_tensor),\n",
    "        )\n",
    "        for k in range(tensor_order)\n",
    "    ]\n",
    "\n",
    "    iter = 0\n",
    "\n",
    "    error = tl.norm(tt_to_tensor(factor_old) - tt_to_tensor(factor_new), 2)\n",
    "    threshold = tol * tl.norm(tt_to_tensor(factor_new), 2)\n",
    "    for iter in range(n_iter_max):\n",
    "        if error < threshold:\n",
    "            break\n",
    "\n",
    "        factor_old = factor_new\n",
    "        factor_new = [None for i in range(tensor_order)]\n",
    "\n",
    "        ######################################\n",
    "        # left-to-right step\n",
    "        left_to_right_fiberlist = []\n",
    "        # list row_idx: list of (tensor_order-1) of lists of left indices\n",
    "        row_idx = [[()]]\n",
    "        if iter == 0:\n",
    "            print(row_idx)\n",
    "            print(col_idx)\n",
    "        for k in range(tensor_order - 1):\n",
    "            (next_row_idx, fibers_list) = left_right_ttcross_step(\n",
    "                input_tensor, k, rank, row_idx, col_idx\n",
    "            )\n",
    "            # update row indices\n",
    "            left_to_right_fiberlist.extend(fibers_list)\n",
    "            row_idx.append(next_row_idx)\n",
    "\n",
    "        # end left-to-right step\n",
    "        ###############################################\n",
    "\n",
    "        ###############################################\n",
    "        # right-to-left step\n",
    "        right_to_left_fiberlist = []\n",
    "        # list col_idx: list (tensor_order-1) of lists of right indices\n",
    "        col_idx = [None] * tensor_order\n",
    "        col_idx[-1] = [()]\n",
    "        for k in range(tensor_order, 1, -1):\n",
    "            (next_col_idx, fibers_list, Q_skeleton) = right_left_ttcross_step(\n",
    "                input_tensor, k, rank, row_idx, col_idx\n",
    "            )\n",
    "            # update col indices\n",
    "            right_to_left_fiberlist.extend(fibers_list)\n",
    "            col_idx[k - 2] = next_col_idx\n",
    "\n",
    "            # Compute cores\n",
    "            try:\n",
    "                factor_new[k - 1] = tl.transpose(Q_skeleton)\n",
    "                factor_new[k - 1] = tl.reshape(\n",
    "                    factor_new[k - 1], (rank[k - 1], tensor_shape[k - 1], rank[k])\n",
    "                )\n",
    "            except:\n",
    "                # The rank should not be larger than the input tensor's size\n",
    "                raise (\n",
    "                    ValueError(\n",
    "                        \"The rank is too large compared to the size of the tensor. Try with small rank.\"\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        # Add the last core\n",
    "        idx = (slice(None, None, None),) + tuple(zip(*col_idx[0]))\n",
    "\n",
    "        core = input_tensor[idx]\n",
    "        core = tl.reshape(core, (tensor_shape[0], 1, rank[1]))\n",
    "        core = tl.transpose(core, (1, 0, 2))\n",
    "\n",
    "        factor_new[0] = core\n",
    "\n",
    "        # end right-to-left step\n",
    "        ################################################\n",
    "\n",
    "        # check the error for while-loop\n",
    "        error = tl.norm(tt_to_tensor(factor_old) - tt_to_tensor(factor_new), 2)\n",
    "        threshold = tol * tl.norm(tt_to_tensor(factor_new), 2)\n",
    "\n",
    "    # check convergence\n",
    "    if iter >= n_iter_max:\n",
    "        raise ValueError(\"Maximum number of iterations reached.\")\n",
    "    if tl.norm(tt_to_tensor(factor_old) - tt_to_tensor(factor_new), 2) > tol * tl.norm(\n",
    "        tt_to_tensor(factor_new), 2\n",
    "    ):\n",
    "        raise ValueError(\"Low Rank Approximation algorithm did not converge.\")\n",
    "\n",
    "    return factor_new\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def left_right_ttcross_step(input_tensor, k, rank, row_idx, col_idx):\n",
    "    \"\"\"Compute the next (right) core's row indices by QR decomposition.\n",
    "\n",
    "    For the current Tensor train core, we use the row indices and col indices to extract the entries from the input tensor\n",
    "    and compute the next core's row indices by QR and max volume algorithm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    k: int\n",
    "            the actual sweep iteration\n",
    "    rank: list of int\n",
    "            list of upper ranks (tensor_order)\n",
    "    row_idx: list of list of int\n",
    "            list of (tensor_order-1) of lists of left indices\n",
    "    col_idx: list of list of int\n",
    "            list of (tensor_order-1) of lists of right indices\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    next_row_idx : list of int\n",
    "            the list of new row indices,\n",
    "    fibers_list : list of slice\n",
    "            the used fibers,\n",
    "    Q_skeleton : matrix\n",
    "            approximation of Q as product of Q and inverse of its maximum volume submatrix\n",
    "    \"\"\"\n",
    "\n",
    "    tensor_shape = tl.shape(input_tensor)\n",
    "    tensor_order = tl.ndim(input_tensor)\n",
    "    fibers_list = []\n",
    "\n",
    "    # Extract fibers according to the row and col indices\n",
    "    for i in range(rank[k]):\n",
    "        for j in range(rank[k + 1]):\n",
    "            fiber = row_idx[k][i] + (slice(None, None, None),) + col_idx[k][j]\n",
    "            fibers_list.append(fiber)\n",
    "    if k == 0:  # Is[k] will be empty\n",
    "        idx = (slice(None, None, None),) + tuple(zip(*col_idx[k]))\n",
    "    else:\n",
    "        idx = [[] for i in range(tensor_order)]\n",
    "        for lidx in row_idx[k]:\n",
    "            for ridx in col_idx[k]:\n",
    "                for j, jj in enumerate(lidx):\n",
    "                    idx[j].append(jj)\n",
    "                for j, jj in enumerate(ridx):\n",
    "                    idx[len(lidx) + 1 + j].append(jj)\n",
    "        idx[k] = slice(None, None, None)\n",
    "        idx = tuple(idx)\n",
    "\n",
    "    # Extract the core\n",
    "    core = input_tensor[idx]\n",
    "    # shape the core as a 3-tensor_order cube\n",
    "    if k == 0:\n",
    "        core = tl.reshape(core, (tensor_shape[k], rank[k], rank[k + 1]))\n",
    "        core = tl.transpose(core, (1, 0, 2))\n",
    "    else:\n",
    "        core = tl.reshape(core, (rank[k], rank[k + 1], tensor_shape[k]))\n",
    "        core = tl.transpose(core, (0, 2, 1))\n",
    "\n",
    "    # merge r_k and n_k, get a matrix\n",
    "    core = tl.reshape(core, (rank[k] * tensor_shape[k], rank[k + 1]))\n",
    "\n",
    "    # Compute QR decomposition\n",
    "    (Q, R) = tl.qr(core)\n",
    "\n",
    "    # Maxvol\n",
    "    (I, _) = maxvol(Q)\n",
    "\n",
    "    # Retrive indices in folded tensor\n",
    "    new_idx = [\n",
    "        np.unravel_index(idx, [rank[k], tensor_shape[k]]) for idx in I\n",
    "    ]  # First retrive idx in folded core\n",
    "    next_row_idx = [\n",
    "        row_idx[k][ic[0]] + (ic[1],) for ic in new_idx\n",
    "    ]  # Then reconstruct the idx in the tensor\n",
    "\n",
    "    return (next_row_idx, fibers_list)\n",
    "\n",
    "\n",
    "def right_left_ttcross_step(input_tensor, k, rank, row_idx, col_idx):\n",
    "    \"\"\"Compute the next (left) core's col indices by QR decomposition.\n",
    "\n",
    "    For the current Tensor train core, we use the row indices and col indices to extract the entries from the input tensor\n",
    "    and compute the next core's col indices by QR and max volume algorithm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    k: int\n",
    "            the actual sweep iteration\n",
    "    rank: list of int\n",
    "            list of upper rank (tensor_order)\n",
    "    row_idx: list of list of int\n",
    "            list of (tensor_order-1) of lists of left indices\n",
    "    col_idx: list of list of int\n",
    "            list of (tensor_order-1) of lists of right indices\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    next_col_idx : list of int\n",
    "            the list of new col indices,\n",
    "    fibers_list : list of slice\n",
    "            the used fibers,\n",
    "    Q_skeleton : matrix\n",
    "            approximation of Q as product of Q and inverse of its maximum volume submatrix\n",
    "    \"\"\"\n",
    "\n",
    "    tensor_shape = tl.shape(input_tensor)\n",
    "    tensor_order = tl.ndim(input_tensor)\n",
    "    fibers_list = []\n",
    "\n",
    "    # Extract fibers\n",
    "    for i in range(rank[k - 1]):\n",
    "        for j in range(rank[k]):\n",
    "            fiber = row_idx[k - 1][i] + (slice(None, None, None),) + col_idx[k - 1][j]\n",
    "            fibers_list.append(fiber)\n",
    "\n",
    "    if k == tensor_order:  # Is[k] will be empty\n",
    "        idx = tuple(zip(*row_idx[k - 1])) + (slice(None, None, None),)\n",
    "    else:\n",
    "        idx = [[] for i in range(tensor_order)]\n",
    "        for lidx in row_idx[k - 1]:\n",
    "            for ridx in col_idx[k - 1]:\n",
    "                for j, jj in enumerate(lidx):\n",
    "                    idx[j].append(jj)\n",
    "                for j, jj in enumerate(ridx):\n",
    "                    idx[len(lidx) + 1 + j].append(jj)\n",
    "        idx[k - 1] = slice(None, None, None)\n",
    "        idx = tuple(idx)\n",
    "\n",
    "    core = input_tensor[idx]\n",
    "    # shape the core as a 3-tensor_order cube\n",
    "    core = tl.reshape(core, (rank[k - 1], rank[k], tensor_shape[k - 1]))\n",
    "    core = tl.transpose(core, (0, 2, 1))\n",
    "    # merge n_{k-1} and r_k, get a matrix\n",
    "    core = tl.reshape(core, (rank[k - 1], tensor_shape[k - 1] * rank[k]))\n",
    "    core = tl.transpose(core)\n",
    "\n",
    "    # Compute QR decomposition\n",
    "    (Q, R) = tl.qr(core)\n",
    "    # Maxvol\n",
    "    (J, Q_inv) = maxvol(Q)\n",
    "    Q_inv = tl.tensor(Q_inv)\n",
    "    Q_skeleton = tl.dot(Q, Q_inv)\n",
    "\n",
    "    # Retrive indices in folded tensor\n",
    "    new_idx = [\n",
    "        np.unravel_index(idx, [tensor_shape[k - 1], rank[k]]) for idx in J\n",
    "    ]  # First retrive idx in folded core\n",
    "    next_col_idx = [\n",
    "        (jc[0],) + col_idx[k - 1][jc[1]] for jc in new_idx\n",
    "    ]  # Then reconstruct the idx in the tensor\n",
    "\n",
    "    return (next_col_idx, fibers_list, Q_skeleton)\n",
    "\n",
    "\n",
    "def maxvol(A):\n",
    "    \"\"\"Find the rxr submatrix of maximal volume in A(nxr), n>=r\n",
    "\n",
    "    We want to decompose matrix A as `A = A[:,J] * (A[I,J])^-1 * A[I,:]`.\n",
    "    This algorithm helps us find this submatrix A[I,J] from A, which has the largest determinant.\n",
    "    We greedily find vector of max norm, and subtract its projection from the rest of rows.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    A: matrix\n",
    "        The matrix to find maximal volume\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    row_idx: list of int\n",
    "        is the list or rows of A forming the matrix with maximal volume,\n",
    "    A_inv: matrix\n",
    "        is the inverse of the matrix with maximal volume.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    S. A. Goreinov, I. V. Oseledets, D. V. Savostyanov, E. E. Tyrtyshnikov, N. L. Zamarashkin.\n",
    "    How to find a good submatrix.Goreinov, S. A., et al.\n",
    "    Matrix Methods: Theory, Algorithms and Applications: Dedicated to the Memory of Gene Golub. 2010. 247-256.\n",
    "\n",
    "    Ali Çivril, Malik Magdon-Ismail\n",
    "    On selecting a maximum volume sub-matrix of a matrix and related problems\n",
    "    Theoretical Computer Science. Volume 410, Issues 47–49, 6 November 2009, Pages 4801-4811\n",
    "    \"\"\"\n",
    "\n",
    "    (n, r) = tl.shape(A)\n",
    "\n",
    "    # The index of row of the submatrix\n",
    "    row_idx = tl.zeros(r, dtype=tl.int64)\n",
    "\n",
    "    # Rest of rows / unselected rows\n",
    "    rest_of_rows = tl.tensor(list(range(n)), dtype=tl.int64)\n",
    "\n",
    "    # Find r rows iteratively\n",
    "    i = 0\n",
    "    A_new = A\n",
    "    while i < r:\n",
    "        mask = list(range(tl.shape(A_new)[0]))\n",
    "        # Compute the square of norm of each row\n",
    "        rows_norms = tl.sum(A_new**2, axis=1)\n",
    "\n",
    "        # If there is only one row of A left, let's just return it.\n",
    "        if tl.shape(rows_norms) == ():\n",
    "            row_idx[i] = rest_of_rows\n",
    "            break\n",
    "\n",
    "        # If a row is 0, we delete it.\n",
    "        if any(rows_norms == 0):\n",
    "            zero_idx = tl.argmin(rows_norms, axis=0)\n",
    "            mask.pop(zero_idx)\n",
    "            rest_of_rows = rest_of_rows[mask]\n",
    "            A_new = A_new[mask, :]\n",
    "            continue\n",
    "\n",
    "        # Find the row of max norm\n",
    "        max_row_idx = tl.argmax(rows_norms, axis=0)\n",
    "        max_row = A[rest_of_rows[max_row_idx], :]\n",
    "\n",
    "        # Compute the projection of max_row to other rows\n",
    "        # projection a to b is computed as: <a,b> / sqrt(|a|*|b|)\n",
    "        projection = tl.dot(A_new, tl.transpose(max_row))\n",
    "        normalization = tl.sqrt(rows_norms[max_row_idx] * rows_norms)\n",
    "        # make sure normalization vector is of the same shape of projection\n",
    "        normalization = tl.reshape(normalization, tl.shape(projection))\n",
    "        projection = projection / normalization\n",
    "\n",
    "        # Subtract the projection from A_new:  b <- b - a * projection\n",
    "        A_new = A_new - A_new * tl.reshape(projection, (tl.shape(A_new)[0], 1))\n",
    "\n",
    "        # Delete the selected row\n",
    "        mask.pop(tl.to_numpy(max_row_idx))\n",
    "        A_new = A_new[mask, :]\n",
    "\n",
    "        # update the row_idx and rest_of_rows\n",
    "        row_idx = tl.index_update(row_idx, i, rest_of_rows[max_row_idx])\n",
    "        rest_of_rows = rest_of_rows[tl.tensor(mask, dtype=tl.int64)]\n",
    "        i = i + 1\n",
    "\n",
    "    row_idx = tl.tensor(row_idx, dtype=tl.int64)\n",
    "    inverse = tl.solve(\n",
    "        A[row_idx, :], tl.eye(tl.shape(A[row_idx, :])[0], **tl.context(A))\n",
    "    )\n",
    "    row_idx = tl.to_numpy(row_idx)\n",
    "\n",
    "    return row_idx, inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "200bcb48-8b49-4998-a10c-1acbdde45fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, slice(None, None, None), 20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(10,) + (slice(None, None, None),) + (20,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "728b945a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[()]]\n",
      "[[(2, 1), (3, 2), (4, 4)], [(1,), (2,), (0,)], None]\n"
     ]
    }
   ],
   "source": [
    "tensor = tl.tensor(np.arange(5**3).reshape(5,5,5))\n",
    "rank = [1, 3, 3, 1]\n",
    "factors = tensor_train_cross(tensor, rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aefccf62-65e6-46f6-97a6-55a1db9dd871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 5, 3), (3, 5, 3), (3, 5, 1))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors[0].shape, factors[1].shape, factors[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaf3ce16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   1,   2,   3,   4],\n",
       "        [  5,   6,   7,   8,   9],\n",
       "        [ 10,  11,  12,  13,  14],\n",
       "        [ 15,  16,  17,  18,  19],\n",
       "        [ 20,  21,  22,  23,  24]],\n",
       "\n",
       "       [[ 25,  26,  27,  28,  29],\n",
       "        [ 30,  31,  32,  33,  34],\n",
       "        [ 35,  36,  37,  38,  39],\n",
       "        [ 40,  41,  42,  43,  44],\n",
       "        [ 45,  46,  47,  48,  49]],\n",
       "\n",
       "       [[ 50,  51,  52,  53,  54],\n",
       "        [ 55,  56,  57,  58,  59],\n",
       "        [ 60,  61,  62,  63,  64],\n",
       "        [ 65,  66,  67,  68,  69],\n",
       "        [ 70,  71,  72,  73,  74]],\n",
       "\n",
       "       [[ 75,  76,  77,  78,  79],\n",
       "        [ 80,  81,  82,  83,  84],\n",
       "        [ 85,  86,  87,  88,  89],\n",
       "        [ 90,  91,  92,  93,  94],\n",
       "        [ 95,  96,  97,  98,  99]],\n",
       "\n",
       "       [[100, 101, 102, 103, 104],\n",
       "        [105, 106, 107, 108, 109],\n",
       "        [110, 111, 112, 113, 114],\n",
       "        [115, 116, 117, 118, 119],\n",
       "        [120, 121, 122, 123, 124]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b8da7030-4bde-46da-a415-a33a819de312",
   "metadata": {},
   "source": [
    "row_idx = [[()]]\n",
    "col_idx = [[(4, 2), (4, 3), (4, 0)], [(0,), (3,), (1,)], None]\n",
    "tensor_order = 2\n",
    "k = 0\n",
    "idx = (slice(None, None, None),) + tuple(zip(*col_idx[k]))\n",
    "\n",
    "idx = tuple(idx)\n",
    "print(idx)\n",
    "tensor[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed1b5660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   1,   2,   3,   4],\n",
       "        [  5,   6,   7,   8,   9],\n",
       "        [ 10,  11,  12,  13,  14],\n",
       "        [ 15,  16,  17,  18,  19],\n",
       "        [ 20,  21,  22,  23,  24]],\n",
       "\n",
       "       [[ 25,  26,  27,  28,  29],\n",
       "        [ 30,  31,  32,  33,  34],\n",
       "        [ 35,  36,  37,  38,  39],\n",
       "        [ 40,  41,  42,  43,  44],\n",
       "        [ 45,  46,  47,  48,  49]],\n",
       "\n",
       "       [[ 50,  51,  52,  53,  54],\n",
       "        [ 55,  56,  57,  58,  59],\n",
       "        [ 60,  61,  62,  63,  64],\n",
       "        [ 65,  66,  67,  68,  69],\n",
       "        [ 70,  71,  72,  73,  74]],\n",
       "\n",
       "       [[ 75,  76,  77,  78,  79],\n",
       "        [ 80,  81,  82,  83,  84],\n",
       "        [ 85,  86,  87,  88,  89],\n",
       "        [ 90,  91,  92,  93,  94],\n",
       "        [ 95,  96,  97,  98,  99]],\n",
       "\n",
       "       [[100, 101, 102, 103, 104],\n",
       "        [105, 106, 107, 108, 109],\n",
       "        [110, 111, 112, 113, 114],\n",
       "        [115, 116, 117, 118, 119],\n",
       "        [120, 121, 122, 123, 124]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430e993e-c837-411d-a8f4-c6e35031a8b9",
   "metadata": {},
   "source": [
    "### Trying to implement the paper one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55fbe6fa-874a-4b75-9a06-0edfe971fcbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 10), (10, 20))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q, R = np.linalg.qr(np.random.randn(10, 20))\n",
    "\n",
    "Q.shape, R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "516385f0-9f27-4c7e-bab4-313feaf9590f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "order must be str, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m B \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m np\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124majb,bd->ajd\u001b[39m\u001b[38;5;124m'\u001b[39m, B, [[\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m----> 5\u001b[0m \u001b[43mB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mTypeError\u001b[0m: order must be str, not int"
     ]
    }
   ],
   "source": [
    "B = np.random.randn(3, 5, 1)\n",
    "\n",
    "np.einsum('ajb,bd->ajd', B, [[1]]).shape\n",
    "\n",
    "B.res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1bbdd3b6-7710-4548-a864-239e7f360ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def TT_RC(A, ranks):\n",
    "    B = [np.random.randn(ranks[i], A.shape[i], ranks[i + 1]) for i in range(len(A.shape))]\n",
    "    R = np.array([[1]])\n",
    "    n = A.shape\n",
    "    d = len(A.shape)\n",
    "    P = [None]*(d + 1)\n",
    "    P[0] = [[1]]; P[-1] = np.array([[1]])\n",
    "\n",
    "    J = [None] * (d+1) # need for tracing of later extraction\n",
    "    J[-1] = 0\n",
    "    \n",
    "    for k in range(d-1, 0, -1):\n",
    "        print(k)\n",
    "        print(B[k].shape, R.shape)\n",
    "        B[k] = np.einsum('...b,bd->...d', B[k], R)\n",
    "        C = np.reshape(B[k], (ranks[k], n[k]*ranks[k+1]))\n",
    "        R, Q = scipy.linalg.qr(C)\n",
    "        print(C.shape, Q.shape, R.shape)\n",
    "        B[k] = np.reshape(Q, (ranks[k], n[k], ranks[k+1]))\n",
    "\n",
    "        Q = np.reshape(Q, (ranks[k]*n[k], ranks[k+1]))\n",
    "        print(Q.shape, P[k + 1].shape)\n",
    "        \n",
    "        Q = Q.dot(P[k+1]); Q = np.reshape(Q, (ranks[k], n[k]*ranks[k+1]))\n",
    "\n",
    "        JJ = maxvol(Q.T)[0]\n",
    "        print('JJ', JJ)\n",
    "        J[k] = np.array([[el // ranks[k + 1], el % ranks[k +1]] for el in JJ], dtype = np.int32)[:, J[k+1]]\n",
    "        print(J[k])\n",
    "        \n",
    "        P[k] = Q[:, JJ]\n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4a578c78-d070-4cad-959e-892ac9db001e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(3, 5, 1) (1, 1)\n",
      "(3, 5) (3, 5) (3, 3)\n",
      "(15, 1) (1, 1)\n",
      "JJ [0 3 4]\n",
      "[0 3 4]\n",
      "1\n",
      "(3, 5, 3) (3, 3)\n",
      "(3, 15) (3, 15) (3, 3)\n",
      "(15, 3) (3, 3)\n",
      "JJ [5 4 0]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m A \u001b[38;5;241m=\u001b[39m tl\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m5\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      2\u001b[0m ranks \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m \u001b[43mTT_RC\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranks\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[108], line 30\u001b[0m, in \u001b[0;36mTT_RC\u001b[0;34m(A, ranks)\u001b[0m\n\u001b[1;32m     28\u001b[0m JJ \u001b[38;5;241m=\u001b[39m maxvol(Q\u001b[38;5;241m.\u001b[39mT)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJJ\u001b[39m\u001b[38;5;124m'\u001b[39m, JJ)\n\u001b[0;32m---> 30\u001b[0m J[k] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mranks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mranks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mJJ\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mJ\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(J[k])\n\u001b[1;32m     33\u001b[0m P[k] \u001b[38;5;241m=\u001b[39m Q[:, J[k]]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 1 with size 2"
     ]
    }
   ],
   "source": [
    "A = tl.tensor(np.arange(5**3).reshape(5,5,5))\n",
    "ranks = [1, 3, 3, 1]\n",
    "\n",
    "TT_RC(A, ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb8ee91-42e4-411d-b3ce-8dc7efc41caa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spingnn",
   "language": "python",
   "name": "spingnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
